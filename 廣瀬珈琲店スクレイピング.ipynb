{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536d3226-d7a2-48e1-9f94-0f0c966270f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Supabaseから既存のunique_keyを取得中...\n",
      "✅ 既存のunique_keyを 287 件取得しました。\n",
      "\n",
      "=== Google Maps レビュー取得開始 ===\n",
      "✅ Google Maps クチコミタブをクリック完了\n",
      "🧭 Google Maps 並び替え『新しい順』クリック結果: not found\n",
      "🔎 Google Maps スクロール対象を探索中...\n",
      "✅ Google Maps スクロール対象のレビューセクションを発見\n",
      "↘️ Google Maps レビューをスクロール中 (目標: 200件)...\n",
      "✅ Google Maps 200件のレビューに到達 → スクロール終了\n",
      "👁️‍🗨️ Google Maps 『もっと見る』ボタン 122 個を検出、クリック中...\n",
      "✅ Google Maps 『もっと見る』ボタンクリック完了\n",
      "⚙️ Google Maps ページから 208 件のレビューブロックを抽出中...\n",
      "📦 Google Mapsから 203 件のレビューを抽出完了\n",
      "=== Google Maps レビュー取得完了 ===\n",
      "\n",
      "\n",
      "=== Tabelog (https://tabelog.com/kyoto/A2601/A260403/26001303/dtlrvwlst/)からレビュー取得開始 ===\n",
      "➡️ Tabelog 次ページボタンが見つかりませんでした。スクレイピング終了。\n",
      "📦 Tabelogから 20 件のレビューを抽出完了\n",
      "\n",
      "=== Retty (https://retty.me/area/PRE26/ARE114/SUB11401/100000295754/reports/)からレビュー取得開始 ===\n",
      "➡️ Retty 次ページボタンが見つかりませんでした。スクレイピング終了。\n",
      "📦 Rettyから 2 件のレビューを抽出完了\n",
      "\n",
      "--- 全サイト合計取得レビュー数: 225 ---\n",
      "\n",
      "☁️ Supabaseにレビューデータを挿入中（合計 225 件）...\n",
      "✅ 保存成功: googlemaps - ケイゆうすけ  (2025-02-26)\n",
      "✅ 保存成功: googlemaps - とうふちゃん  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Sasaki george  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - 天野一  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Shiho Horie (紫)  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - ぺるしゃねこ  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - TAKASHI OKUNO  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - rin rin  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - mitsutaka minami  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - 七面鳥放浪記  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - ねこ  (2022-05-28)\n",
      "✅ 保存成功: googlemaps - 元松  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - イケダ“ねこと (2019-05-29)\n",
      "✅ 保存成功: googlemaps - babs  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - 中津佳之  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Jun Sakai  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - にとうへい  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - きよ (2020-05-28)\n",
      "✅ 保存成功: googlemaps - 安藤いづみ  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - すけ  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - なーおお  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - Yu mi  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - やまかわ  (2021-05-28)\n",
      "✅ 保存成功: googlemaps - Keai ymd  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - たかしオデッセイ  (2021-05-28)\n",
      "✅ 保存成功: googlemaps - K H  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - Yeh Annie  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - 園田哲郎  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - tominger official  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - レッサー風太  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - 吉田美奈子  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - koyatama tamago  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - 松尾明美  (2021-05-28)\n",
      "✅ 保存成功: googlemaps - Daiki Aminaka  (2021-05-28)\n",
      "✅ 保存成功: googlemaps - みかさ  (2022-05-28)\n",
      "✅ 保存成功: googlemaps - katsumi onitsuka  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - パワーズ“オースティン”オースティン  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - きむらさとし  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - 大粒まろん  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - N S  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - 河野喜明  (2022-05-28)\n",
      "✅ 保存成功: googlemaps - K K  (2021-05-28)\n",
      "✅ 保存成功: googlemaps - luna tan (もちはん)  (2021-05-28)\n",
      "✅ 保存成功: googlemaps - RX78NORIRIN  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - i  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - 浅田博一  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - - pon  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - tabi 874  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - toshiaki  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - わ  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - 花村勇太朗  (2025-05-26)\n",
      "✅ 保存成功: googlemaps - Er Hauzhi  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Maggie Wang  (2025-02-18)\n",
      "✅ 保存成功: googlemaps - 吳靜芬  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Edoardo Toffano  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Gi Pal  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Monica NA  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - nu gu  (2025-01-27)\n",
      "✅ 保存成功: googlemaps - Ariane  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Michael Watts  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - 서혜린  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Ts T  (2025-01-27)\n",
      "✅ 保存成功: googlemaps - 梁嘉菱  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Brooks n Jasmine  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - Philip Wolfe  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Borriraks Rattanawangcharoen (吳子牙)  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - pauli  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Yanisa Ratanakosit  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - 백지숙  (2025-02-26)\n",
      "✅ 保存成功: googlemaps - Melissa  (2024-08-30)\n",
      "✅ 保存成功: googlemaps - Ken Graham  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Chris  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Spencer Kok  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Mike Lee  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Skye Cai  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Vibhu Dhawan  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - MF MF  (2025-02-18)\n",
      "✅ 保存成功: googlemaps - Min Li  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Shreyamsa Manjunath  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Trisha Pereira  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Alan Tang  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Antonio Cutrona  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - SEO  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - 許書嫚  (2025-01-27)\n",
      "✅ 保存成功: googlemaps - Tracey Buskes  (2025-02-26)\n",
      "✅ 保存成功: googlemaps - 봉미선마요  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Wayne See  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - William Huang  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Tom Chien  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - H Park  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Bob Slob  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Juei-En Su  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Nhi Nguyen  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Yuval Gorchover  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Safa Yavuzdoğan  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - YNWA LIVE  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Tom Werner  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - Rory Mannion  (2024-08-30)\n",
      "✅ 保存成功: googlemaps - Katie Tung  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Masa Wu  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Stijn Floren  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - 莊育婷  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - 許祐瑄  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Diogo Santo  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Jihun Kim  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Daniel Kestenholz  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Shaochen T  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Elif Ç.  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - Romane Laurent  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Gracey Gowler  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - Victor Fernandez  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - krista Elem  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Tina Lam  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Love Wise  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Borja TP  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Shani Cohen Shitrit  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - May Hsia Ng  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Eu  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Sunil Gill  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Sam Wong  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Yiduo Xiao  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - Tim Lo  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - Kourtney Elbag  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Alex MC  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - 한재홍  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - K Kang  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - lu an  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - 陈一一  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Roshan Lakmal  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Shawn Clifford  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - vivi su  (2017-05-29)\n",
      "✅ 保存成功: googlemaps - 范博傑  (2025-01-27)\n",
      "✅ 保存成功: googlemaps - Konrad Swierblewski  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Vittoria S  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Aidan Ferguson  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Grace Ding  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Robert Beal  (2014-05-30)\n",
      "✅ 保存成功: googlemaps - Abbie Baggett  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Iulia Andreea Marcu  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - Hee Hee  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - doktorfred  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Amanda McCalla  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - ling Yu  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - S Duan  (2024-08-30)\n",
      "✅ 保存成功: googlemaps - 天羽亮  (2017-05-29)\n",
      "✅ 保存成功: googlemaps - dancer huge  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Zula Stricker  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - ERIN SLAGERMAN  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Yuki  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Allison Lemke  (2017-05-29)\n",
      "✅ 保存成功: googlemaps - Wiam Hanania  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - Carolyn S.  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Giwrrhs theos  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Samantha Taylor  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Danica Mitchell  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Sunkyung Park  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Warren Bitner  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - V  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - kristina wulandari  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Fernando Burgés  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Respina Vaezian  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Kiyono Gray  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Siang Chin Lim  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Kasia Daniec  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Andrew Staheli  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Julia Bowry  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - Rafael Alvarez  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Jake Prior  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Rui Shi  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Best Nittayapron  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - N CHIN  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Kurt Jensen  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Lori Lewis  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - 吳可  (2017-05-29)\n",
      "✅ 保存成功: googlemaps - 박영수  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Andrea Lattanzio  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - George Chu  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Justyna S  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Nathan  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Cate Chang  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - jay malby  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Hameed Chughtai  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - 손국진  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Watcher Sky  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - L  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Natalie  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Yvette Chang  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Lauren Lysko  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - fireytale  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Ginny LU  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - Eylem Akyurek  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Water Loco  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Gabriel Gabe  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Moneer M  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - Matteo Zambon  (2025-02-18)\n",
      "✅ 保存成功: googlemaps - Chia Keegan  (2018-05-29)\n",
      "✅ 保存成功: googlemaps - Bob Binärfeld  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Esteban Beltran  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - Kevin Lee  (2019-05-29)\n",
      "✅ 保存成功: googlemaps - Victor Inocentes  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Benjamin Ferrara  (2020-05-28)\n",
      "✅ 保存成功: googlemaps - doodoo00166 Liu  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Susan E  (2019-05-29)\n",
      "✅ 保存成功: tabelog - Mm39 (2025-02-01)\n",
      "✅ 保存成功: tabelog - 84d5653082 (2024-11-01)\n",
      "✅ 保存成功: tabelog - グルメゆうちゃん (2024-10-01)\n",
      "✅ 保存成功: tabelog - たちこ4153 (2024-06-01)\n",
      "✅ 保存成功: tabelog - 京きのこ (2024-05-01)\n",
      "✅ 保存成功: tabelog - jboy0927 (2024-05-01)\n",
      "✅ 保存成功: tabelog - fyama13 (2023-12-01)\n",
      "✅ 保存成功: tabelog - mashirokun (2020-11-01)\n",
      "✅ 保存成功: tabelog - キャラメリゼ碧 (2019-03-01)\n",
      "✅ 保存成功: tabelog - opall (2016-12-01)\n",
      "✅ 保存成功: tabelog - もしもし眠い (2015-11-01)\n",
      "✅ 保存成功: tabelog - 蕨もち (2015-05-01)\n",
      "✅ 保存成功: tabelog - 下町グルメの達ちゃん (2014-10-01)\n",
      "✅ 保存成功: tabelog - nao&シエル (2014-01-01)\n",
      "✅ 保存成功: tabelog - KAママ (2011-10-01)\n",
      "✅ 保存成功: tabelog - ひいふうみい (2009-09-01)\n",
      "✅ 保存成功: tabelog - 大臣。 (2007-04-01)\n",
      "✅ 保存成功: tabelog - いねる (2018-11-01)\n",
      "✅ 保存成功: tabelog - aozora0007 (2017-11-01)\n",
      "✅ 保存成功: tabelog - くいしんbouu (2024-07-01)\n",
      "✅ 保存成功: retty - かつらしょう (2019-12-28)\n",
      "✅ 保存成功: retty - imai s (2017-07-18)\n",
      "📦 Supabaseに新規レビューを 225 件保存しました。\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pytz # タイムゾーン対応のため\n",
    "\n",
    "# --- 環境設定 ---\n",
    "# Supabase URLとAPIキー。セキュリティのため、本番環境では環境変数を使用することを強く推奨します。\n",
    "SUPABASE_URL = \"https://oahnmyfalnhdkoihrswh.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9haG5teWZhbG5oZGtvaWhyc3doIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0NDIzNzE0MiwiZXhwIjoyMDU5ODEzMTQyfQ.yPx_tsCwoLmTZ3qRBIdifYfBBxLaElsaVR55P0lWQec\"\n",
    "SUPABASE_TABLE_NAME = \"parking_cafe_reunion_arashiyama_hirose_coffee\" # レビューを保存するSupabaseテーブル名\n",
    "STORE_ID = \"廣瀬珈琲店\" # 対象店舗のID\n",
    "\n",
    "# Supabase APIリクエスト用の共通ヘッダー\n",
    "HEADERS = {\n",
    "    \"apikey\": SUPABASE_API_KEY,\n",
    "    \"Authorization\": f\"Bearer {SUPABASE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- 補助関数 ---\n",
    "\n",
    "# 現在時刻をJSTのISO形式で取得 (inserted_at用)\n",
    "def jst_now():\n",
    "    return datetime.now(pytz.timezone(\"Asia/Tokyo\")).isoformat()\n",
    "\n",
    "# テキストを安全にfloatに変換。変換できない場合はNoneを返す\n",
    "def safe_float(text):\n",
    "    try:\n",
    "        # 空文字列、ハイフン、全角ハイフンはNoneに\n",
    "        return float(text) if text not in [\"\", \"-\", \"ー\"] else None\n",
    "    except (ValueError, TypeError):\n",
    "        # 変換できない場合はNone\n",
    "        return None\n",
    "\n",
    "# レビューの一意なキーを生成 (SHA256ハッシュ)\n",
    "# レビューテキストの冒頭50文字を使用し、スペースなどを除去してハッシュの安定性を高める\n",
    "def safe_generate_unique_key(channel, store_id, visit_date, name, review_text):\n",
    "    cleaned_review = re.sub(r\"\\s+\", \"\", (review_text or \"\").strip().lower())[:50]\n",
    "    cleaned_name = (name or \"\").strip().lower()\n",
    "    cleaned_date = (visit_date or \"\").strip() # visit_dateがNoneの場合に空文字列になるように\n",
    "    \n",
    "    base = f\"{channel}_{store_id}_{cleaned_date}_{cleaned_name}_{cleaned_review}\"\n",
    "    return hashlib.sha256(base.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# --- WebDriver設定 ---\n",
    "\n",
    "# WebDriverの初期設定（ヘッドレスモード、自動制御回避など）\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\") # 最新のヘッドレスモードを使用\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\") # 自動制御を検知させないようにする\n",
    "    options.add_argument(\"--no-sandbox\") # DockerやCI/CD環境で必要になる場合がある\n",
    "    options.add_argument(\"--disable-dev-shm-usage\") # DockerやCI/CD環境で必要になる場合がある\n",
    "    options.add_argument(\"--window-size=1920,1080\") # ウィンドウサイズを設定\n",
    "    options.add_argument(\"--incognito\") # シークレットモードで起動\n",
    "    \n",
    "    # WebDriverManagerでChromeDriverを自動ダウンロード・設定\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# --- Supabase 関連関数 ---\n",
    "\n",
    "# 既存のunique_keyをSupabaseから一括取得し、セットで返す\n",
    "def fetch_existing_unique_keys():\n",
    "    print(\"🔄 Supabaseから既存のunique_keyを取得中...\")\n",
    "    response = requests.get(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}?select=unique_key\", headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        existing_keys = {x[\"unique_key\"] for x in response.json()}\n",
    "        print(f\"✅ 既存のunique_keyを {len(existing_keys)} 件取得しました。\")\n",
    "        return existing_keys\n",
    "    else:\n",
    "        print(f\"❌ 既存キー取得エラー: {response.status_code} - {response.text}\")\n",
    "        return set() # エラー時は空のセットを返す\n",
    "\n",
    "# レビューデータをSupabaseに挿入（重複チェック付き）\n",
    "def insert_reviews_to_supabase(reviews_data, existing_keys_set):\n",
    "    inserted_count = 0\n",
    "    if not reviews_data:\n",
    "        print(\"💡 挿入するレビューデータがありません。\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"☁️ Supabaseにレビューデータを挿入中（合計 {len(reviews_data)} 件）...\")\n",
    "    for r in reviews_data:\n",
    "        unique_key = r.get('unique_key')\n",
    "        if not unique_key:\n",
    "            print(f\"⚠️ unique_keyがありません。スキップします: {r.get('name', 'N/A')}\")\n",
    "            continue\n",
    "\n",
    "        # 既存のキーセットに含まれていればスキップ\n",
    "        if unique_key in existing_keys_set:\n",
    "            # print(f\"⚠️ 重複スキップ: {unique_key} - {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.post(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}\", headers=HEADERS, json=r)\n",
    "            if response.status_code in [200, 201]:\n",
    "                inserted_count += 1\n",
    "                existing_keys_set.add(unique_key) # 新しく挿入されたキーをメモリ上のセットに追加\n",
    "                print(f\"✅ 保存成功: {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            else:\n",
    "                print(f\"❌ Supabase POSTエラー: {response.status_code} - {response.text} - データunique_key: {unique_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 保存エラー: {e} - データunique_key: {unique_key}\")\n",
    "    print(f\"📦 Supabaseに新規レビューを {inserted_count} 件保存しました。\")\n",
    "    return inserted_count\n",
    "\n",
    "# --- Google Maps スクレイピング関数 ---\n",
    "\n",
    "# Google Mapsのクチコミタブをクリック\n",
    "def click_google_review_tab(driver):\n",
    "    try:\n",
    "        review_tab = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label,\"クチコミ\")]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", review_tab) # JavaScriptでクリックを試みる\n",
    "        time.sleep(2) # クリック後の待機時間を長くする\n",
    "        print(\"✅ Google Maps クチコミタブをクリック完了\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps クチコミタブクリック失敗: {e}\")\n",
    "\n",
    "# Google Mapsのレビューを「新しい順」で並び替え\n",
    "def click_google_sort_by_new(driver):\n",
    "    try:\n",
    "        # 「並べ替え」ボタンのXPathをより具体的に\n",
    "        sort_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[.//span[text()=\"並べ替え\"]]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", sort_button)\n",
    "        time.sleep(1) # クリック後の待機\n",
    "\n",
    "        # 「新しい順」をクリックするためのJavaScript\n",
    "        script = '''\n",
    "            const elements = Array.from(document.querySelectorAll('div[role=\"menuitem\"]'));\n",
    "            const target = elements.find(el => el.textContent.trim() === '新しい順');\n",
    "            if (target) { target.click(); return 'clicked'; } else { return 'not found'; }\n",
    "        '''\n",
    "        result = driver.execute_script(script)\n",
    "        print(f\"🧭 Google Maps 並び替え『新しい順』クリック結果: {result}\")\n",
    "        time.sleep(2) # 並び替え適用後の待機時間を長くする\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps 並び替えクリック失敗: {e}\")\n",
    "\n",
    "# Google Mapsのスクロール可能なレビューエリアを見つける\n",
    "def find_google_scrollable_area(driver):\n",
    "    print(\"🔎 Google Maps スクロール対象を探索中...\")\n",
    "    try:\n",
    "        # レビューブロックの最初の要素が存在するまで待機し、その祖先要素からスクロール可能な領域を探す\n",
    "        scrollable_div = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-review-id]:first-of-type'))\n",
    "        ).find_element(By.XPATH, './ancestor::div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]')\n",
    "        print(\"✅ Google Maps スクロール対象のレビューセクションを発見\")\n",
    "        return scrollable_div\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps スクロール対象が見つかりませんでした: {e}\")\n",
    "        return None\n",
    "\n",
    "# Google Mapsのレビューを指定件数または最後までスクロール\n",
    "def scroll_google_reviews(driver, scrollable_div, target_reviews=200, max_scrolls=200, patience_scrolls=10):\n",
    "    prev_count = 0\n",
    "    same_count_times = 0\n",
    "    print(f\"↘️ Google Maps レビューをスクロール中 (目標: {target_reviews}件)...\")\n",
    "    for i in range(max_scrolls):\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", scrollable_div)\n",
    "        time.sleep(0.5) # 短めの待機\n",
    "        reviews = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "        curr_count = len(reviews)\n",
    "        # print(f\"   スクロール {i+1}回目：現在のレビュー数 = {curr_count}\") # デバッグ用\n",
    "\n",
    "        if curr_count >= target_reviews:\n",
    "            print(f\"✅ Google Maps {target_reviews}件のレビューに到達 → スクロール終了\")\n",
    "            break\n",
    "        if curr_count == prev_count:\n",
    "            same_count_times += 1\n",
    "            if same_count_times >= patience_scrolls:\n",
    "                print(f\"⚠️ Google Maps {patience_scrolls}回連続でレビュー数増加なし → スクロール中断\")\n",
    "                break\n",
    "        else:\n",
    "            same_count_times = 0\n",
    "            prev_count = curr_count\n",
    "    \n",
    "    # 全ての「もっと見る」ボタンをクリックして全文を表示\n",
    "    try:\n",
    "        expand_buttons = driver.find_elements(By.CSS_SELECTOR, 'button.w8nwRe')\n",
    "        print(f\"👁️‍🗨️ Google Maps 『もっと見る』ボタン {len(expand_buttons)} 個を検出、クリック中...\")\n",
    "        for btn in expand_buttons:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                # time.sleep(0.05) # 短い待機で負荷を減らす\n",
    "            except Exception as e:\n",
    "                pass # 大量に出力される可能性があるのでエラーメッセージは表示しない\n",
    "        print(\"✅ Google Maps 『もっと見る』ボタンクリック完了\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps 『もっと見る』ボタンクリック処理失敗: {e}\")\n",
    "\n",
    "# Google Mapsからレビュー情報を抽出\n",
    "def extract_google_reviews(driver):\n",
    "    ref_date = datetime.now()  # 基準日（現在日時）\n",
    "    reviews = []\n",
    "\n",
    "    # 完全に展開されたレビューブロックを取得\n",
    "    blocks = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "    print(f\"⚙️ Google Maps ページから {len(blocks)} 件のレビューブロックを抽出中...\")\n",
    "\n",
    "    for block in blocks:\n",
    "        unique_key = block.get_attribute(\"data-review-id\")\n",
    "        if not unique_key:\n",
    "            continue  # IDがないレビューはスキップ\n",
    "\n",
    "        soup = BeautifulSoup(block.get_attribute(\"innerHTML\"), \"html.parser\")\n",
    "\n",
    "        review_text_elem = soup.select_one('.MyEned span.wiI7pd')\n",
    "        review_text = review_text_elem.text.strip() if review_text_elem else \"\"\n",
    "        if not review_text:\n",
    "            continue  # 本文なしはスキップ\n",
    "\n",
    "        # 投稿日（相対表現 or 絶対表現）\n",
    "        visit_date = None\n",
    "        visit_month = None\n",
    "        try:\n",
    "            rating_block = soup.select_one(\"div.DU9Pgb\")\n",
    "            if rating_block:\n",
    "                publish_span = rating_block.select_one(\"span.rsqaWe\")\n",
    "                if publish_span:\n",
    "                    txt = publish_span.get_text(strip=True)\n",
    "                    visit_datetime = None\n",
    "\n",
    "                    if \"時間前\" in txt:\n",
    "                        hours = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(hours=hours)\n",
    "                    elif \"日前\" in txt:\n",
    "                        days = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=days)\n",
    "                    elif \"週間前\" in txt:\n",
    "                        weeks = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(weeks=weeks * 7)\n",
    "                    elif \"か月前\" in txt:\n",
    "                        months = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=30 * months)\n",
    "                    elif \"年前\" in txt:\n",
    "                        years = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=365 * years)\n",
    "                    elif re.match(r\"^\\d{4}年\\d{1,2}月\\d{1,2}日$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Y年%m月%d日\")\n",
    "                    elif re.match(r\"^\\d{4}年\\d{1,2}月$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Y年%m月\")\n",
    "\n",
    "                    if visit_datetime:\n",
    "                        visit_date = visit_datetime.date().isoformat()\n",
    "                        visit_month = visit_datetime.replace(day=1).date().isoformat()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Google Maps visit_date 抽出エラー: {e} (元のテキスト: {txt if 'txt' in locals() else 'N/A'})\")\n",
    "\n",
    "        # 総合スコア\n",
    "        total_score = None\n",
    "        score_elem = soup.select_one('span.kvMYJc[aria-label]')\n",
    "        if score_elem and \"つ星\" in score_elem.get(\"aria-label\", \"\"):\n",
    "            match = re.search(r\"(\\d+) つ星\", score_elem['aria-label'])\n",
    "            if match:\n",
    "                total_score = int(match.group(1))\n",
    "\n",
    "        # サブスコア抽出ヘルパー\n",
    "        def extract_google_sub_score(label):\n",
    "            score = None\n",
    "            score_blocks = soup.select(\"div.PBK6be span.RfDO5c\")\n",
    "            for block in score_blocks:\n",
    "                bold = block.find(\"b\")\n",
    "                if bold and label in bold.text:\n",
    "                    text = block.get_text(strip=True)\n",
    "                    match = re.search(rf\"{label}:\\s*(\\d+)\", text)\n",
    "                    if match:\n",
    "                        score = int(match.group(1))\n",
    "                        break\n",
    "            return score\n",
    "\n",
    "        food_score = extract_google_sub_score(\"食事\")\n",
    "        service_score = extract_google_sub_score(\"サービス\")\n",
    "        atmosphere_score = extract_google_sub_score(\"雰囲気\")\n",
    "\n",
    "        lunch = \"ランチ\" in review_text\n",
    "        dinner = \"ディナー\" in review_text\n",
    "\n",
    "        price_range = None\n",
    "        price_elem = soup.find(\"span\", attrs={\"aria-label\": re.compile(r\"￥\")})\n",
    "        if price_elem:\n",
    "            price_range = price_elem['aria-label']\n",
    "\n",
    "        user_button = soup.select_one('button[aria-label*=\"さんのクチコミ\"]')\n",
    "        user_name = user_button['aria-label'].split('さん')[0] if user_button else \"\"\n",
    "        a_tag = soup.select_one('a')\n",
    "        user_url = \"https://www.google.com\" + a_tag['href'] if a_tag else \"\"\n",
    "\n",
    "        reviews.append({\n",
    "            \"store_id\": STORE_ID,\n",
    "            \"channel\": \"googlemaps\",\n",
    "            \"unique_key\": unique_key,\n",
    "            \"review\": review_text,\n",
    "            \"visit_date\": visit_date,\n",
    "            \"visit_month\": visit_month,\n",
    "            \"name\": user_name,\n",
    "            \"user_url\": user_url,\n",
    "            \"total_score\": total_score,\n",
    "            \"food_score\": food_score,\n",
    "            \"service_score\": service_score,\n",
    "            \"atmosphere_score\": atmosphere_score,\n",
    "            \"lunch\": lunch,\n",
    "            \"dinner\": dinner,\n",
    "            \"price_range\": price_range,\n",
    "            \"inserted_at\": jst_now()\n",
    "        })\n",
    "\n",
    "    print(f\"📦 Google Mapsから {len(reviews)} 件のレビューを抽出完了\")\n",
    "    return reviews\n",
    "\n",
    "# ============ 食べログ スクレイピング関数 ============\n",
    "\n",
    "def scrape_tabelog(url, store_id, driver):\n",
    "    print(f\"\\n=== Tabelog ({url})からレビュー取得開始 ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    reviews_data = []\n",
    "    \n",
    "    while True:\n",
    "        items = driver.find_elements(By.CSS_SELECTOR, \"div.rvw-item\")\n",
    "        if not items:\n",
    "            print(\"➡️ Tabelog レビューアイテムが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "\n",
    "        for idx, e in enumerate(items):\n",
    "            try:\n",
    "                # 「もっと見る」ボタンをクリック (アコーディオン、全文表示)\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"button.js-c-accordion-trigger\").click(); time.sleep(0.2)\n",
    "                except: pass\n",
    "                try: e.find_element(By.CSS_SELECTOR, \".rvw-showall-trigger\").click(); time.sleep(0.2)\n",
    "                except: pass\n",
    "\n",
    "                review_text = None\n",
    "                try: review_text = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__rvw-comment--custom p\").text.strip()\n",
    "                except:\n",
    "                    try: review_text = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__rvw-comment p\").text.strip()\n",
    "                    except: pass # レビュー本文がなければNoneのまま\n",
    "\n",
    "                if not review_text: # レビュー本文が空の場合はスキップ\n",
    "                    continue\n",
    "\n",
    "                name_elem = e.find_element(By.CSS_SELECTOR, \".rvw-item__rvwr-name\")\n",
    "                name = name_elem.text.strip() if name_elem else None\n",
    "                user_url_elem = e.find_element(By.CSS_SELECTOR, \".rvw-item__rvwr-info-left a\")\n",
    "                user_url = user_url_elem.get_attribute(\"href\") if user_url_elem else None\n",
    "\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                try:\n",
    "                    date_elem = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__date span\")\n",
    "                    date_text = date_elem.text.strip().split(\"訪問\")[0].strip()\n",
    "                    # YYYY/MM/DD または YYYY/MM 形式に対応\n",
    "                    if re.match(r\"^\\d{4}/\\d{1,2}/\\d{1,2}$\", date_text):\n",
    "                        dt_obj = datetime.strptime(date_text, \"%Y/%m/%d\")\n",
    "                        visit_date = dt_obj.date().isoformat()\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                    elif re.match(r\"^\\d{4}/\\d{1,2}$\", date_text):\n",
    "                        dt_obj = datetime.strptime(date_text, \"%Y/%m\")\n",
    "                        visit_date = dt_obj.replace(day=1).date().isoformat() # 日付は月初\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                except Exception:\n",
    "                    pass # 日付抽出エラーは無視\n",
    "\n",
    "                total_score = None\n",
    "                try: total_score = safe_float(e.find_element(By.CSS_SELECTOR, \"b.c-rating-v3__val\").text)\n",
    "                except: pass\n",
    "\n",
    "                food_score = service_score = atmosphere_score = None\n",
    "                for li in e.find_elements(By.CSS_SELECTOR, \"ul.c-rating-detail li\"):\n",
    "                    try:\n",
    "                        label_elem = li.find_element(By.TAG_NAME, \"span\")\n",
    "                        val_elem = li.find_element(By.TAG_NAME, \"strong\")\n",
    "                        if label_elem and val_elem:\n",
    "                            label = label_elem.text.strip()\n",
    "                            val = safe_float(val_elem.text)\n",
    "                            if \"料理\" in label: food_score = val\n",
    "                            elif \"サービス\" in label: service_score = val\n",
    "                            elif \"雰囲気\" in label: atmosphere_score = val\n",
    "                    except: pass\n",
    "\n",
    "                lunch = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"i.c-rating-v3__time--lunch\"); lunch = True\n",
    "                except: pass\n",
    "                dinner = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"i.c-rating-v3__time--dinner\"); dinner = True\n",
    "                except: pass\n",
    "\n",
    "                price_range = None\n",
    "                try:\n",
    "                    price_range_elem = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__payment-amount span\")\n",
    "                    price_range_text = price_range_elem.text.strip()\n",
    "                    if price_range_text not in [\"－\", \"-\"]: price_range = price_range_text\n",
    "                except: pass\n",
    "\n",
    "                key = safe_generate_unique_key(\"tabelog\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "                \n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"tabelog\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': total_score, 'food_score': food_score, 'service_score': service_score,\n",
    "                    'atmosphere_score': atmosphere_score, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': price_range, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Tabelog 抽出失敗 (要素 {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"a.c-pagination__arrow--next\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"➡️ Tabelog 次ページボタンが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "    print(f\"📦 Tabelogから {len(reviews_data)} 件のレビューを抽出完了\")\n",
    "    return reviews_data\n",
    "\n",
    "# ============ Retty スクレイピング関数 ============\n",
    "\n",
    "def scrape_retty(url, store_id, driver):\n",
    "    print(f\"\\n=== Retty ({url})からレビュー取得開始 ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    reviews_data = []\n",
    "\n",
    "    while True:\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        items = soup.select(\"article.restaurant-report\")\n",
    "        if not items:\n",
    "            print(\"➡️ Retty レビューアイテムが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "\n",
    "        for idx, item in enumerate(items):\n",
    "            try:\n",
    "                name_tag = item.select_one(\".report-user__name\")\n",
    "                name = name_tag.text.strip() if name_tag else None\n",
    "\n",
    "                user_url_tag = item.select_one(\"a.report-user\")\n",
    "                user_url = user_url_tag[\"href\"] if user_url_tag else None\n",
    "\n",
    "                time_tag = item.select_one(\"div.restaurant-report__date time\")\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                if time_tag and \"datetime\" in time_tag.attrs:\n",
    "                    dt_str = time_tag[\"datetime\"][:10] # YYYY-MM-DD 形式\n",
    "                    try:\n",
    "                        dt_obj = datetime.strptime(dt_str, \"%Y-%m-%d\")\n",
    "                        visit_date = dt_obj.date().isoformat()\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                    except ValueError:\n",
    "                        pass # 日付パースエラーは無視\n",
    "\n",
    "                lunch = \"restaurant-report__hours-icon--lunch\" in str(item)\n",
    "                dinner = \"restaurant-report__hours-icon--dinner\" in str(item)\n",
    "\n",
    "                review_elem = item.select_one(\"p.restaurant-report__text\")\n",
    "                review_text = review_elem.text.strip() if review_elem else None\n",
    "                \n",
    "                if not review_text: # レビュー本文が空の場合はスキップ\n",
    "                    continue\n",
    "                    \n",
    "                key = safe_generate_unique_key(\"retty\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "\n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"retty\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': None, 'food_score': None, 'service_score': None,\n",
    "                    'atmosphere_score': None, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': None, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Retty 抽出失敗 (要素 {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"a.pagination__next\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"➡️ Retty 次ページボタンが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "    print(f\"📦 Rettyから {len(reviews_data)} 件のレビューを抽出完了\")\n",
    "    return reviews_data\n",
    "\n",
    "\n",
    "# ============ メイン処理 ============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 各サイトのURLを設定\n",
    "    # Google Maps URLは、直接Google Mapsの店舗ページURLを使用してください\n",
    "    # 例: \"https://www.google.com/maps/place/店舗名/@緯度,経度,ズームレベルz/data=!3m1!4b1!4m8!3m7!1s...\"\n",
    "    # レビュータブが自動で開くURLは、末尾に /reviews を追加すると良い場合があります。\n",
    "    google_maps_url = \"https://www.google.com/maps/place/%E5%BB%A3%E7%80%AC%E7%8F%88%E7%90%B2%E5%BA%97/@35.0171104,135.6810545,17z/data=!4m8!3m7!1s0x6001a9fe7616d74d:0xc5e2178eaff9044d!8m2!3d35.0171104!4d135.6810545!9m1!1b1!16s%2Fg%2F1wnf0zg2?entry=ttu&g_ep=EgoyMDI1MDUyMS4wIKXMDSoASAFQAw%3D%3D\"\n",
    "    tabelog_url = \"https://tabelog.com/kyoto/A2601/A260403/26001303/dtlrvwlst/\"\n",
    "    retty_url = \"https://retty.me/area/PRE26/ARE114/SUB11401/100000295754/reports/\"\n",
    "\n",
    "    driver = None # driverを初期化\n",
    "    all_reviews = [] # 全サイトから取得したレビューを格納するリスト\n",
    "\n",
    "    try:\n",
    "        driver = setup_driver() # WebDriverを一度だけ初期化\n",
    "\n",
    "        # 既存のunique_keyをSupabaseから一度だけ取得\n",
    "        existing_unique_keys = fetch_existing_unique_keys()\n",
    "\n",
    "        # --- 各サイトからのレビュー取得と結合 ---\n",
    "\n",
    "        # Google Maps\n",
    "        print(\"\\n=== Google Maps レビュー取得開始 ===\")\n",
    "        driver.get(google_maps_url)\n",
    "        time.sleep(5) # ページが完全にロードされるのを待つ\n",
    "        click_google_review_tab(driver)\n",
    "        click_google_sort_by_new(driver)\n",
    "        scroll_target = find_google_scrollable_area(driver)\n",
    "        if scroll_target:\n",
    "            scroll_google_reviews(driver, scroll_target, target_reviews=200, max_scrolls=200) # より多くのレビューを試みる\n",
    "            google_reviews = extract_google_reviews(driver)\n",
    "            all_reviews.extend(google_reviews)\n",
    "        else:\n",
    "            print(\"❌ Google Maps レビューエリアが見つからなかったため、スキップします。\")\n",
    "        print(\"=== Google Maps レビュー取得完了 ===\\n\")\n",
    "\n",
    "        # Tabelog\n",
    "        tabelog_reviews = scrape_tabelog(tabelog_url, STORE_ID, driver)\n",
    "        all_reviews.extend(tabelog_reviews)\n",
    "\n",
    "        # Retty\n",
    "        retty_reviews = scrape_retty(retty_url, STORE_ID, driver)\n",
    "        all_reviews.extend(retty_reviews)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"致命的なエラーが発生しました: {e}\")\n",
    "    finally:\n",
    "        if driver: # driverがNoneでないことを確認してから終了\n",
    "            driver.quit() # 全ての処理が終わったらWebDriverを閉じる\n",
    "\n",
    "    print(f\"\\n--- 全サイト合計取得レビュー数: {len(all_reviews)} ---\\n\")\n",
    "\n",
    "    # --- 取得した全てのレビューをSupabaseに挿入 ---\n",
    "    if all_reviews:\n",
    "        insert_reviews_to_supabase(all_reviews, existing_unique_keys)\n",
    "    else:\n",
    "        print(\"取得したレビューがありませんでした。Supabaseへの挿入はスキップされます。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7af5ab-33b2-4ef7-84ae-c90d4a208abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
