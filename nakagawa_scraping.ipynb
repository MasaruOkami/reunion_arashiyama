{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536d3226-d7a2-48e1-9f94-0f0c966270f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Supabaseから既存のunique_keyを取得中...\n",
      "✅ 既存のunique_keyを 462 件取得しました。\n",
      "\n",
      "=== Google Maps レビュー取得開始 ===\n",
      "✅ Google Maps クチコミタブをクリック完了\n",
      "🧭 Google Maps 並び替え『新しい順』クリック結果: not found\n",
      "🔎 Google Maps スクロール対象を探索中...\n",
      "✅ Google Maps スクロール対象のレビューセクションを発見\n",
      "↘️ Google Maps レビューをスクロール中 (目標: 200件)...\n",
      "⚠️ Google Maps 10回連続でレビュー数増加なし → スクロール中断\n",
      "👁️‍🗨️ Google Maps 『もっと見る』ボタン 152 個を検出、クリック中...\n",
      "✅ Google Maps 『もっと見る』ボタンクリック完了\n",
      "⚙️ Google Maps ページから 173 件のレビューブロックを抽出中...\n",
      "📦 Google Mapsから 142 件のレビューを抽出完了\n",
      "=== Google Maps レビュー取得完了 ===\n",
      "\n",
      "\n",
      "=== Tabelog (https://tabelog.com/kyoto/A2601/A260403/26039266/dtlrvwlst/)からレビュー取得開始 ===\n",
      "➡️ Tabelog 次ページボタンが見つかりませんでした。スクレイピング終了。\n",
      "📦 Tabelogから 10 件のレビューを抽出完了\n",
      "\n",
      "--- 全サイト合計取得レビュー数: 152 ---\n",
      "\n",
      "☁️ Supabaseにレビューデータを挿入中（合計 152 件）...\n",
      "✅ 保存成功: googlemaps - 高橋裕子  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - ケイゆうすけ  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - うっしぃ  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - K A  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - 白兎  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - とらなかむ  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - ごーるどまうす  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - ぽいもおいも  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Risa K  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - りり  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - いっちゃん。  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - k hgs  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - n k  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - 京都のお墨付き!  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - ねずみ  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Brandon Marc Higa  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - 9 ih  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - みーわた（ミー）  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - イガラシノリコ  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - 水本弘子  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Massu Arch  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - na hhi  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Lin  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - ヒデログ Hidero-g  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - 原粹蔬食作  (2025-04-08)\n",
      "✅ 保存成功: googlemaps - Adam Cohen  (2025-01-27)\n",
      "✅ 保存成功: googlemaps - Adrián G  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Sarah Hanneken  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - Michelle Case  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Matthew  (2025-02-26)\n",
      "✅ 保存成功: googlemaps - Andrea Hill  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Ammrutaa Prrashant Kaspale  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Zach Fowler  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Dave Harris  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - 박경원  (2024-08-30)\n",
      "✅ 保存成功: googlemaps - Kathy Tran  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Chalit Padoongcheep  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Po Po  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - T Tangkoskul  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Alessandro Alfonsi  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - XnewbieX123  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Justine Parker  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Olga Ushko  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Pietro Pocek  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Santiago Rodriguez Egaña  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - Lien Claes  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - 狐鸣  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Adrian ponte  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - Shin Jin Ho  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - David Kim  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - Chi “Jez” Lam  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - 봄동이네봄동이네  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - Pablo  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Goonj  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Largo Wils  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - 유태식  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - 이기사  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Vu Duong  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - Rebecca Klor  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - camila medina  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - I-Lee Millward  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - 鄭博文（Powen）  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Corinne Ingalla  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - Dorsa J  (2025-01-27)\n",
      "✅ 保存成功: googlemaps - Keidra  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Joel Kahn  (2025-02-18)\n",
      "✅ 保存成功: googlemaps - Lia X.  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Oz  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Anna Marija Avota  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Sabine Heider  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - PIYUSH BHARDWAJ 23  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Jonathan Calderon-Nurmi  (2024-08-30)\n",
      "✅ 保存成功: googlemaps - Ting Yu Chen  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - Mido Hamzawi  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Marc De Almeida  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Amy Hernandez  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Isabelle Tamburro  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Scott Lawson  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Arthur ABIA  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Karl Hopkinson-Turrell  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Loris Di Giuseppe  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Kate Seddon  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Aline Garcia  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Lioness X  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Theresa  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Vedha Rajan  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Nabil Hussein  (2024-12-31)\n",
      "✅ 保存成功: googlemaps - Cece Verdugo  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - donghyuck park  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Red Sky  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Can Kip  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Tamuz Niv  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Yolanda Johnstone  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - Raphael Miyashiro  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Çağdaş Alagöz  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - PG  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Valley Boy  (2024-08-30)\n",
      "✅ 保存成功: googlemaps - youkyung jung  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Laura Suárez  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Tom Rodenby  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Ignacio Villagra  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Alejandro Palma  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Dove Brooklynn  (2024-11-12)\n",
      "✅ 保存成功: googlemaps - lili lin  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Danielle (dani)  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Chipmungus  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Joe Butler-Pracy  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Thacth  (2024-07-01)\n",
      "✅ 保存成功: googlemaps - Ju dith  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Katya Bogdanova  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Spencer Howell  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Bill Maney  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Leon Kievit  (2024-08-30)\n",
      "✅ 保存成功: googlemaps - Callum Murton  (2025-02-18)\n",
      "✅ 保存成功: googlemaps - Benjamin Muller  (2024-09-29)\n",
      "✅ 保存成功: googlemaps - Natacha W  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - André Fritz  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Omar El Ameri  (2024-10-29)\n",
      "✅ 保存成功: googlemaps - Aman Somal  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Gaby Katten  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Laura Mundell  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Rossouw van der Merwe  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Joey Gan  (2024-12-28)\n",
      "✅ 保存成功: googlemaps - justBodo  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Fotowonderlust T  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Michelle  (2025-01-27)\n",
      "✅ 保存成功: googlemaps - Glifer  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Sophie Rammert  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Léon Ch  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Aldo Beolchini  (2024-08-30)\n",
      "✅ 保存成功: googlemaps - Charles ZH  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Omar Nema  (2024-11-28)\n",
      "✅ 保存成功: googlemaps - Nadia  (2025-04-27)\n",
      "✅ 保存成功: googlemaps - Tim Lewis  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Daniel González  (2024-07-31)\n",
      "✅ 保存成功: googlemaps - Philipp  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Felix Persson  (2025-03-28)\n",
      "✅ 保存成功: googlemaps - Virgil BOTTALICO  (2024-05-27)\n",
      "✅ 保存成功: googlemaps - Moe Sh  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Timothée Jacob  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Pinto Brian  (2023-05-28)\n",
      "✅ 保存成功: googlemaps - Charles Chan  (2025-05-22)\n",
      "✅ 保存成功: tabelog - グルメゆうちゃん (2024-10-01)\n",
      "✅ 保存成功: tabelog - まる12695 (2024-01-01)\n",
      "✅ 保存成功: tabelog - chaos777 (2023-11-01)\n",
      "✅ 保存成功: tabelog - きょむーまうす (2023-11-01)\n",
      "✅ 保存成功: tabelog - ゆうた1996 (2023-11-01)\n",
      "✅ 保存成功: tabelog - c535e3 (2023-07-01)\n",
      "✅ 保存成功: tabelog - 京都の京子 (2023-07-01)\n",
      "✅ 保存成功: tabelog - 太っ腹 (2023-04-01)\n",
      "✅ 保存成功: tabelog - Haruka333888 (2023-06-01)\n",
      "✅ 保存成功: tabelog - みんグルメ☆ (2023-04-01)\n",
      "📦 Supabaseに新規レビューを 152 件保存しました。\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pytz # タイムゾーン対応のため\n",
    "\n",
    "# --- 環境設定 ---\n",
    "# Supabase URLとAPIキー。セキュリティのため、本番環境では環境変数を使用することを強く推奨します。\n",
    "SUPABASE_URL = \"https://oahnmyfalnhdkoihrswh.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9haG5teWZhbG5oZGtvaWhyc3doIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0NDIzNzE0MiwiZXhwIjoyMDU5ODEzMTQyfQ.yPx_tsCwoLmTZ3qRBIdifYfBBxLaElsaVR55P0lWQec\"\n",
    "SUPABASE_TABLE_NAME = \"uomannishiumedatest\" # レビューを保存するSupabaseテーブル名\n",
    "STORE_ID = \"uomannishiumeda\" # 対象店舗のID\n",
    "\n",
    "# Supabase APIリクエスト用の共通ヘッダー\n",
    "HEADERS = {\n",
    "    \"apikey\": SUPABASE_API_KEY,\n",
    "    \"Authorization\": f\"Bearer {SUPABASE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- 補助関数 ---\n",
    "\n",
    "# 現在時刻をJSTのISO形式で取得 (inserted_at用)\n",
    "def jst_now():\n",
    "    return datetime.now(pytz.timezone(\"Asia/Tokyo\")).isoformat()\n",
    "\n",
    "# テキストを安全にfloatに変換。変換できない場合はNoneを返す\n",
    "def safe_float(text):\n",
    "    try:\n",
    "        # 空文字列、ハイフン、全角ハイフンはNoneに\n",
    "        return float(text) if text not in [\"\", \"-\", \"ー\"] else None\n",
    "    except (ValueError, TypeError):\n",
    "        # 変換できない場合はNone\n",
    "        return None\n",
    "\n",
    "# レビューの一意なキーを生成 (SHA256ハッシュ)\n",
    "# レビューテキストの冒頭50文字を使用し、スペースなどを除去してハッシュの安定性を高める\n",
    "def safe_generate_unique_key(channel, store_id, visit_date, name, review_text):\n",
    "    cleaned_review = re.sub(r\"\\s+\", \"\", (review_text or \"\").strip().lower())[:50]\n",
    "    cleaned_name = (name or \"\").strip().lower()\n",
    "    cleaned_date = (visit_date or \"\").strip() # visit_dateがNoneの場合に空文字列になるように\n",
    "    \n",
    "    base = f\"{channel}_{store_id}_{cleaned_date}_{cleaned_name}_{cleaned_review}\"\n",
    "    return hashlib.sha256(base.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# --- WebDriver設定 ---\n",
    "\n",
    "# WebDriverの初期設定（ヘッドレスモード、自動制御回避など）\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\") # 最新のヘッドレスモードを使用\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\") # 自動制御を検知させないようにする\n",
    "    options.add_argument(\"--no-sandbox\") # DockerやCI/CD環境で必要になる場合がある\n",
    "    options.add_argument(\"--disable-dev-shm-usage\") # DockerやCI/CD環境で必要になる場合がある\n",
    "    options.add_argument(\"--window-size=1920,1080\") # ウィンドウサイズを設定\n",
    "    options.add_argument(\"--incognito\") # シークレットモードで起動\n",
    "    \n",
    "    # WebDriverManagerでChromeDriverを自動ダウンロード・設定\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# --- Supabase 関連関数 ---\n",
    "\n",
    "# 既存のunique_keyをSupabaseから一括取得し、セットで返す\n",
    "def fetch_existing_unique_keys():\n",
    "    print(\"🔄 Supabaseから既存のunique_keyを取得中...\")\n",
    "    response = requests.get(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}?select=unique_key\", headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        existing_keys = {x[\"unique_key\"] for x in response.json()}\n",
    "        print(f\"✅ 既存のunique_keyを {len(existing_keys)} 件取得しました。\")\n",
    "        return existing_keys\n",
    "    else:\n",
    "        print(f\"❌ 既存キー取得エラー: {response.status_code} - {response.text}\")\n",
    "        return set() # エラー時は空のセットを返す\n",
    "\n",
    "# レビューデータをSupabaseに挿入（重複チェック付き）\n",
    "def insert_reviews_to_supabase(reviews_data, existing_keys_set):\n",
    "    inserted_count = 0\n",
    "    if not reviews_data:\n",
    "        print(\"💡 挿入するレビューデータがありません。\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"☁️ Supabaseにレビューデータを挿入中（合計 {len(reviews_data)} 件）...\")\n",
    "    for r in reviews_data:\n",
    "        unique_key = r.get('unique_key')\n",
    "        if not unique_key:\n",
    "            print(f\"⚠️ unique_keyがありません。スキップします: {r.get('name', 'N/A')}\")\n",
    "            continue\n",
    "\n",
    "        # 既存のキーセットに含まれていればスキップ\n",
    "        if unique_key in existing_keys_set:\n",
    "            # print(f\"⚠️ 重複スキップ: {unique_key} - {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.post(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}\", headers=HEADERS, json=r)\n",
    "            if response.status_code in [200, 201]:\n",
    "                inserted_count += 1\n",
    "                existing_keys_set.add(unique_key) # 新しく挿入されたキーをメモリ上のセットに追加\n",
    "                print(f\"✅ 保存成功: {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            else:\n",
    "                print(f\"❌ Supabase POSTエラー: {response.status_code} - {response.text} - データunique_key: {unique_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 保存エラー: {e} - データunique_key: {unique_key}\")\n",
    "    print(f\"📦 Supabaseに新規レビューを {inserted_count} 件保存しました。\")\n",
    "    return inserted_count\n",
    "\n",
    "# --- Google Maps スクレイピング関数 ---\n",
    "\n",
    "# Google Mapsのクチコミタブをクリック\n",
    "def click_google_review_tab(driver):\n",
    "    try:\n",
    "        review_tab = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label,\"クチコミ\")]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", review_tab) # JavaScriptでクリックを試みる\n",
    "        time.sleep(2) # クリック後の待機時間を長くする\n",
    "        print(\"✅ Google Maps クチコミタブをクリック完了\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps クチコミタブクリック失敗: {e}\")\n",
    "\n",
    "# Google Mapsのレビューを「新しい順」で並び替え\n",
    "def click_google_sort_by_new(driver):\n",
    "    try:\n",
    "        # 「並べ替え」ボタンのXPathをより具体的に\n",
    "        sort_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[.//span[text()=\"並べ替え\"]]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", sort_button)\n",
    "        time.sleep(1) # クリック後の待機\n",
    "\n",
    "        # 「新しい順」をクリックするためのJavaScript\n",
    "        script = '''\n",
    "            const elements = Array.from(document.querySelectorAll('div[role=\"menuitem\"]'));\n",
    "            const target = elements.find(el => el.textContent.trim() === '新しい順');\n",
    "            if (target) { target.click(); return 'clicked'; } else { return 'not found'; }\n",
    "        '''\n",
    "        result = driver.execute_script(script)\n",
    "        print(f\"🧭 Google Maps 並び替え『新しい順』クリック結果: {result}\")\n",
    "        time.sleep(2) # 並び替え適用後の待機時間を長くする\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps 並び替えクリック失敗: {e}\")\n",
    "\n",
    "# Google Mapsのスクロール可能なレビューエリアを見つける\n",
    "def find_google_scrollable_area(driver):\n",
    "    print(\"🔎 Google Maps スクロール対象を探索中...\")\n",
    "    try:\n",
    "        # レビューブロックの最初の要素が存在するまで待機し、その祖先要素からスクロール可能な領域を探す\n",
    "        scrollable_div = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-review-id]:first-of-type'))\n",
    "        ).find_element(By.XPATH, './ancestor::div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]')\n",
    "        print(\"✅ Google Maps スクロール対象のレビューセクションを発見\")\n",
    "        return scrollable_div\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps スクロール対象が見つかりませんでした: {e}\")\n",
    "        return None\n",
    "\n",
    "# Google Mapsのレビューを指定件数または最後までスクロール\n",
    "def scroll_google_reviews(driver, scrollable_div, target_reviews=200, max_scrolls=200, patience_scrolls=10):\n",
    "    prev_count = 0\n",
    "    same_count_times = 0\n",
    "    print(f\"↘️ Google Maps レビューをスクロール中 (目標: {target_reviews}件)...\")\n",
    "    for i in range(max_scrolls):\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", scrollable_div)\n",
    "        time.sleep(0.5) # 短めの待機\n",
    "        reviews = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "        curr_count = len(reviews)\n",
    "        # print(f\"   スクロール {i+1}回目：現在のレビュー数 = {curr_count}\") # デバッグ用\n",
    "\n",
    "        if curr_count >= target_reviews:\n",
    "            print(f\"✅ Google Maps {target_reviews}件のレビューに到達 → スクロール終了\")\n",
    "            break\n",
    "        if curr_count == prev_count:\n",
    "            same_count_times += 1\n",
    "            if same_count_times >= patience_scrolls:\n",
    "                print(f\"⚠️ Google Maps {patience_scrolls}回連続でレビュー数増加なし → スクロール中断\")\n",
    "                break\n",
    "        else:\n",
    "            same_count_times = 0\n",
    "            prev_count = curr_count\n",
    "    \n",
    "    # 全ての「もっと見る」ボタンをクリックして全文を表示\n",
    "    try:\n",
    "        expand_buttons = driver.find_elements(By.CSS_SELECTOR, 'button.w8nwRe')\n",
    "        print(f\"👁️‍🗨️ Google Maps 『もっと見る』ボタン {len(expand_buttons)} 個を検出、クリック中...\")\n",
    "        for btn in expand_buttons:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                # time.sleep(0.05) # 短い待機で負荷を減らす\n",
    "            except Exception as e:\n",
    "                pass # 大量に出力される可能性があるのでエラーメッセージは表示しない\n",
    "        print(\"✅ Google Maps 『もっと見る』ボタンクリック完了\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps 『もっと見る』ボタンクリック処理失敗: {e}\")\n",
    "\n",
    "# Google Mapsからレビュー情報を抽出\n",
    "def extract_google_reviews(driver):\n",
    "    ref_date = datetime.now()  # 基準日（現在日時）\n",
    "    reviews = []\n",
    "\n",
    "    # 完全に展開されたレビューブロックを取得\n",
    "    blocks = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "    print(f\"⚙️ Google Maps ページから {len(blocks)} 件のレビューブロックを抽出中...\")\n",
    "\n",
    "    for block in blocks:\n",
    "        unique_key = block.get_attribute(\"data-review-id\")\n",
    "        if not unique_key:\n",
    "            continue  # IDがないレビューはスキップ\n",
    "\n",
    "        soup = BeautifulSoup(block.get_attribute(\"innerHTML\"), \"html.parser\")\n",
    "\n",
    "        review_text_elem = soup.select_one('.MyEned span.wiI7pd')\n",
    "        review_text = review_text_elem.text.strip() if review_text_elem else \"\"\n",
    "        if not review_text:\n",
    "            continue  # 本文なしはスキップ\n",
    "\n",
    "        # 投稿日（相対表現 or 絶対表現）\n",
    "        visit_date = None\n",
    "        visit_month = None\n",
    "        try:\n",
    "            rating_block = soup.select_one(\"div.DU9Pgb\")\n",
    "            if rating_block:\n",
    "                publish_span = rating_block.select_one(\"span.rsqaWe\")\n",
    "                if publish_span:\n",
    "                    txt = publish_span.get_text(strip=True)\n",
    "                    visit_datetime = None\n",
    "\n",
    "                    if \"時間前\" in txt:\n",
    "                        hours = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(hours=hours)\n",
    "                    elif \"日前\" in txt:\n",
    "                        days = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=days)\n",
    "                    elif \"週間前\" in txt:\n",
    "                        weeks = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(weeks=weeks * 7)\n",
    "                    elif \"か月前\" in txt:\n",
    "                        months = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=30 * months)\n",
    "                    elif \"年前\" in txt:\n",
    "                        years = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=365 * years)\n",
    "                    elif re.match(r\"^\\d{4}年\\d{1,2}月\\d{1,2}日$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Y年%m月%d日\")\n",
    "                    elif re.match(r\"^\\d{4}年\\d{1,2}月$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Y年%m月\")\n",
    "\n",
    "                    if visit_datetime:\n",
    "                        visit_date = visit_datetime.date().isoformat()\n",
    "                        visit_month = visit_datetime.replace(day=1).date().isoformat()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Google Maps visit_date 抽出エラー: {e} (元のテキスト: {txt if 'txt' in locals() else 'N/A'})\")\n",
    "\n",
    "        # 総合スコア\n",
    "        total_score = None\n",
    "        score_elem = soup.select_one('span.kvMYJc[aria-label]')\n",
    "        if score_elem and \"つ星\" in score_elem.get(\"aria-label\", \"\"):\n",
    "            match = re.search(r\"(\\d+) つ星\", score_elem['aria-label'])\n",
    "            if match:\n",
    "                total_score = int(match.group(1))\n",
    "\n",
    "        # サブスコア抽出ヘルパー\n",
    "        def extract_google_sub_score(label):\n",
    "            score = None\n",
    "            score_blocks = soup.select(\"div.PBK6be span.RfDO5c\")\n",
    "            for block in score_blocks:\n",
    "                bold = block.find(\"b\")\n",
    "                if bold and label in bold.text:\n",
    "                    text = block.get_text(strip=True)\n",
    "                    match = re.search(rf\"{label}:\\s*(\\d+)\", text)\n",
    "                    if match:\n",
    "                        score = int(match.group(1))\n",
    "                        break\n",
    "            return score\n",
    "\n",
    "        food_score = extract_google_sub_score(\"食事\")\n",
    "        service_score = extract_google_sub_score(\"サービス\")\n",
    "        atmosphere_score = extract_google_sub_score(\"雰囲気\")\n",
    "\n",
    "        lunch = \"ランチ\" in review_text\n",
    "        dinner = \"ディナー\" in review_text\n",
    "\n",
    "        price_range = None\n",
    "        price_elem = soup.find(\"span\", attrs={\"aria-label\": re.compile(r\"￥\")})\n",
    "        if price_elem:\n",
    "            price_range = price_elem['aria-label']\n",
    "\n",
    "        user_button = soup.select_one('button[aria-label*=\"さんのクチコミ\"]')\n",
    "        user_name = user_button['aria-label'].split('さん')[0] if user_button else \"\"\n",
    "        a_tag = soup.select_one('a')\n",
    "        user_url = \"https://www.google.com\" + a_tag['href'] if a_tag else \"\"\n",
    "\n",
    "        reviews.append({\n",
    "            \"store_id\": STORE_ID,\n",
    "            \"channel\": \"googlemaps\",\n",
    "            \"unique_key\": unique_key,\n",
    "            \"review\": review_text,\n",
    "            \"visit_date\": visit_date,\n",
    "            \"visit_month\": visit_month,\n",
    "            \"name\": user_name,\n",
    "            \"user_url\": user_url,\n",
    "            \"total_score\": total_score,\n",
    "            \"food_score\": food_score,\n",
    "            \"service_score\": service_score,\n",
    "            \"atmosphere_score\": atmosphere_score,\n",
    "            \"lunch\": lunch,\n",
    "            \"dinner\": dinner,\n",
    "            \"price_range\": price_range,\n",
    "            \"inserted_at\": jst_now()\n",
    "        })\n",
    "\n",
    "    print(f\"📦 Google Mapsから {len(reviews)} 件のレビューを抽出完了\")\n",
    "    return reviews\n",
    "\n",
    "\n",
    "# ============ 食べログ スクレイピング関数 ============\n",
    "\n",
    "def scrape_tabelog(url, store_id, driver):\n",
    "    print(f\"\\n=== Tabelog ({url})からレビュー取得開始 ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    reviews_data = []\n",
    "    \n",
    "    while True:\n",
    "        items = driver.find_elements(By.CSS_SELECTOR, \"div.rvw-item\")\n",
    "        if not items:\n",
    "            print(\"➡️ Tabelog レビューアイテムが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "\n",
    "        for idx, e in enumerate(items):\n",
    "            try:\n",
    "                # 「もっと見る」ボタンをクリック (アコーディオン、全文表示)\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"button.js-c-accordion-trigger\").click(); time.sleep(0.2)\n",
    "                except: pass\n",
    "                try: e.find_element(By.CSS_SELECTOR, \".rvw-showall-trigger\").click(); time.sleep(0.2)\n",
    "                except: pass\n",
    "\n",
    "                review_text = None\n",
    "                try: review_text = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__rvw-comment--custom p\").text.strip()\n",
    "                except:\n",
    "                    try: review_text = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__rvw-comment p\").text.strip()\n",
    "                    except: pass # レビュー本文がなければNoneのまま\n",
    "\n",
    "                if not review_text: # レビュー本文が空の場合はスキップ\n",
    "                    continue\n",
    "\n",
    "                name_elem = e.find_element(By.CSS_SELECTOR, \".rvw-item__rvwr-name\")\n",
    "                name = name_elem.text.strip() if name_elem else None\n",
    "                user_url_elem = e.find_element(By.CSS_SELECTOR, \".rvw-item__rvwr-info-left a\")\n",
    "                user_url = user_url_elem.get_attribute(\"href\") if user_url_elem else None\n",
    "\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                try:\n",
    "                    date_elem = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__date span\")\n",
    "                    date_text = date_elem.text.strip().split(\"訪問\")[0].strip()\n",
    "                    # YYYY/MM/DD または YYYY/MM 形式に対応\n",
    "                    if re.match(r\"^\\d{4}/\\d{1,2}/\\d{1,2}$\", date_text):\n",
    "                        dt_obj = datetime.strptime(date_text, \"%Y/%m/%d\")\n",
    "                        visit_date = dt_obj.date().isoformat()\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                    elif re.match(r\"^\\d{4}/\\d{1,2}$\", date_text):\n",
    "                        dt_obj = datetime.strptime(date_text, \"%Y/%m\")\n",
    "                        visit_date = dt_obj.replace(day=1).date().isoformat() # 日付は月初\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                except Exception:\n",
    "                    pass # 日付抽出エラーは無視\n",
    "\n",
    "                total_score = None\n",
    "                try: total_score = safe_float(e.find_element(By.CSS_SELECTOR, \"b.c-rating-v3__val\").text)\n",
    "                except: pass\n",
    "\n",
    "                food_score = service_score = atmosphere_score = None\n",
    "                for li in e.find_elements(By.CSS_SELECTOR, \"ul.c-rating-detail li\"):\n",
    "                    try:\n",
    "                        label_elem = li.find_element(By.TAG_NAME, \"span\")\n",
    "                        val_elem = li.find_element(By.TAG_NAME, \"strong\")\n",
    "                        if label_elem and val_elem:\n",
    "                            label = label_elem.text.strip()\n",
    "                            val = safe_float(val_elem.text)\n",
    "                            if \"料理\" in label: food_score = val\n",
    "                            elif \"サービス\" in label: service_score = val\n",
    "                            elif \"雰囲気\" in label: atmosphere_score = val\n",
    "                    except: pass\n",
    "\n",
    "                lunch = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"i.c-rating-v3__time--lunch\"); lunch = True\n",
    "                except: pass\n",
    "                dinner = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"i.c-rating-v3__time--dinner\"); dinner = True\n",
    "                except: pass\n",
    "\n",
    "                price_range = None\n",
    "                try:\n",
    "                    price_range_elem = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__payment-amount span\")\n",
    "                    price_range_text = price_range_elem.text.strip()\n",
    "                    if price_range_text not in [\"－\", \"-\"]: price_range = price_range_text\n",
    "                except: pass\n",
    "\n",
    "                key = safe_generate_unique_key(\"tabelog\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "                \n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"tabelog\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': total_score, 'food_score': food_score, 'service_score': service_score,\n",
    "                    'atmosphere_score': atmosphere_score, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': price_range, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Tabelog 抽出失敗 (要素 {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"a.c-pagination__arrow--next\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"➡️ Tabelog 次ページボタンが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "    print(f\"📦 Tabelogから {len(reviews_data)} 件のレビューを抽出完了\")\n",
    "    return reviews_data\n",
    "\n",
    "\n",
    "# ============ Retty スクレイピング関数 ============\n",
    "\n",
    "def scrape_retty(url, store_id, driver):\n",
    "    print(f\"\\n=== Retty ({url})からレビュー取得開始 ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    reviews_data = []\n",
    "\n",
    "    while True:\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        items = soup.select(\"article.restaurant-report\")\n",
    "        if not items:\n",
    "            print(\"➡️ Retty レビューアイテムが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "\n",
    "        for idx, item in enumerate(items):\n",
    "            try:\n",
    "                name_tag = item.select_one(\".report-user__name\")\n",
    "                name = name_tag.text.strip() if name_tag else None\n",
    "\n",
    "                user_url_tag = item.select_one(\"a.report-user\")\n",
    "                user_url = user_url_tag[\"href\"] if user_url_tag else None\n",
    "\n",
    "                time_tag = item.select_one(\"div.restaurant-report__date time\")\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                if time_tag and \"datetime\" in time_tag.attrs:\n",
    "                    dt_str = time_tag[\"datetime\"][:10] # YYYY-MM-DD 形式\n",
    "                    try:\n",
    "                        dt_obj = datetime.strptime(dt_str, \"%Y-%m-%d\")\n",
    "                        visit_date = dt_obj.date().isoformat()\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                    except ValueError:\n",
    "                        pass # 日付パースエラーは無視\n",
    "\n",
    "                lunch = \"restaurant-report__hours-icon--lunch\" in str(item)\n",
    "                dinner = \"restaurant-report__hours-icon--dinner\" in str(item)\n",
    "\n",
    "                review_elem = item.select_one(\"p.restaurant-report__text\")\n",
    "                review_text = review_elem.text.strip() if review_elem else None\n",
    "                \n",
    "                if not review_text: # レビュー本文が空の場合はスキップ\n",
    "                    continue\n",
    "                    \n",
    "                key = safe_generate_unique_key(\"retty\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "\n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"retty\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': None, 'food_score': None, 'service_score': None,\n",
    "                    'atmosphere_score': None, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': None, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Retty 抽出失敗 (要素 {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"a.pagination__next\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"➡️ Retty 次ページボタンが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "    print(f\"📦 Rettyから {len(reviews_data)} 件のレビューを抽出完了\")\n",
    "    return reviews_data\n",
    "\n",
    "\n",
    "\n",
    "# ============ メイン処理 ============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 各サイトのURLを設定\n",
    "    # Google Maps URLは、直接Google Mapsの店舗ページURLを使用してください\n",
    "    # 例: \"https://www.google.com/maps/place/店舗名/@緯度,経度,ズームレベルz/data=!3m1!4b1!4m8!3m7!1s...\"\n",
    "    # レビュータブが自動で開くURLは、末尾に /reviews を追加すると良い場合があります。\n",
    "    google_maps_url = \"https://www.google.com/maps/place/%E4%B8%AD%E5%B7%9D%E7%99%BA%E6%98%8E%E5%A0%82/@35.0160472,135.6762449,17z/data=!4m8!3m7!1s0x6001a9206bea10b1:0x23acb0a95c6fee37!8m2!3d35.0160428!4d135.6788198!9m1!1b1!16s%2Fg%2F11ss55lvmn?entry=ttu&g_ep=EgoyMDI1MDUyMS4wIKXMDSoASAFQAw%3D%3D\"\n",
    "    tabelog_url = \"https://tabelog.com/kyoto/A2601/A260403/26039266/dtlrvwlst/\"\n",
    "    retty_url = \"https://retty.me/area/PRE26/ARE114/SUB11401/100001723061/reports/\"\n",
    "\n",
    "    driver = None # driverを初期化\n",
    "    all_reviews = [] # 全サイトから取得したレビューを格納するリスト\n",
    "\n",
    "    try:\n",
    "        driver = setup_driver() # WebDriverを一度だけ初期化\n",
    "\n",
    "        # 既存のunique_keyをSupabaseから一度だけ取得\n",
    "        existing_unique_keys = fetch_existing_unique_keys()\n",
    "\n",
    "        # --- 各サイトからのレビュー取得と結合 ---\n",
    "\n",
    "        # Google Maps\n",
    "        print(\"\\n=== Google Maps レビュー取得開始 ===\")\n",
    "        driver.get(google_maps_url)\n",
    "        time.sleep(5) # ページが完全にロードされるのを待つ\n",
    "        click_google_review_tab(driver)\n",
    "        click_google_sort_by_new(driver)\n",
    "        scroll_target = find_google_scrollable_area(driver)\n",
    "        if scroll_target:\n",
    "            scroll_google_reviews(driver, scroll_target, target_reviews=200, max_scrolls=200) # より多くのレビューを試みる\n",
    "            google_reviews = extract_google_reviews(driver)\n",
    "            all_reviews.extend(google_reviews)\n",
    "        else:\n",
    "            print(\"❌ Google Maps レビューエリアが見つからなかったため、スキップします。\")\n",
    "        print(\"=== Google Maps レビュー取得完了 ===\\n\")\n",
    "\n",
    "        # Tabelog\n",
    "        tabelog_reviews = scrape_tabelog(tabelog_url, STORE_ID, driver)\n",
    "        all_reviews.extend(tabelog_reviews)\n",
    "  \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"致命的なエラーが発生しました: {e}\")\n",
    "    finally:\n",
    "        if driver: # driverがNoneでないことを確認してから終了\n",
    "            driver.quit() # 全ての処理が終わったらWebDriverを閉じる\n",
    "\n",
    "    print(f\"\\n--- 全サイト合計取得レビュー数: {len(all_reviews)} ---\\n\")\n",
    "\n",
    "    # --- 取得した全てのレビューをSupabaseに挿入 ---\n",
    "    if all_reviews:\n",
    "        insert_reviews_to_supabase(all_reviews, existing_unique_keys)\n",
    "    else:\n",
    "        print(\"取得したレビューがありませんでした。Supabaseへの挿入はスキップされます。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d87096a-124d-4136-ad20-9d2e17f94f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
