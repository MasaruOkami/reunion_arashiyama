{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d3226-d7a2-48e1-9f94-0f0c966270f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pytz # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å¯¾å¿œã®ãŸã‚\n",
    "\n",
    "# --- ç’°å¢ƒè¨­å®š ---\n",
    "# Supabase URLã¨APIã‚­ãƒ¼ã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ã€æœ¬ç•ªç’°å¢ƒã§ã¯ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚\n",
    "SUPABASE_URL = \"https://oahnmyfalnhdkoihrswh.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9haG5teWZhbG5oZGtvaWhyc3doIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0NDIzNzE0MiwiZXhwIjoyMDU5ODEzMTQyfQ.yPx_tsCwoLmTZ3qRBIdifYfBBxLaElsaVR55P0lWQec\"\n",
    "SUPABASE_TABLE_NAME = \"parking_cafe_reunion_arashiyama\" # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¿å­˜ã™ã‚‹Supabaseãƒ†ãƒ¼ãƒ–ãƒ«å\n",
    "STORE_ID = \"Parking Cafe ReUnion Arashiyama\" # å¯¾è±¡åº—èˆ—ã®ID\n",
    "\n",
    "# Supabase APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®å…±é€šãƒ˜ãƒƒãƒ€ãƒ¼\n",
    "HEADERS = {\n",
    "    \"apikey\": SUPABASE_API_KEY,\n",
    "    \"Authorization\": f\"Bearer {SUPABASE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- è£œåŠ©é–¢æ•° ---\n",
    "\n",
    "# ç¾åœ¨æ™‚åˆ»ã‚’JSTã®ISOå½¢å¼ã§å–å¾— (inserted_atç”¨)\n",
    "def jst_now():\n",
    "    return datetime.now(pytz.timezone(\"Asia/Tokyo\")).isoformat()\n",
    "\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«floatã«å¤‰æ›ã€‚å¤‰æ›ã§ããªã„å ´åˆã¯Noneã‚’è¿”ã™\n",
    "def safe_float(text):\n",
    "    try:\n",
    "        # ç©ºæ–‡å­—åˆ—ã€ãƒã‚¤ãƒ•ãƒ³ã€å…¨è§’ãƒã‚¤ãƒ•ãƒ³ã¯Noneã«\n",
    "        return float(text) if text not in [\"\", \"-\", \"ãƒ¼\"] else None\n",
    "    except (ValueError, TypeError):\n",
    "        # å¤‰æ›ã§ããªã„å ´åˆã¯None\n",
    "        return None\n",
    "\n",
    "# ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ä¸€æ„ãªã‚­ãƒ¼ã‚’ç”Ÿæˆ (SHA256ãƒãƒƒã‚·ãƒ¥)\n",
    "# ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®å†’é ­50æ–‡å­—ã‚’ä½¿ç”¨ã—ã€ã‚¹ãƒšãƒ¼ã‚¹ãªã©ã‚’é™¤å»ã—ã¦ãƒãƒƒã‚·ãƒ¥ã®å®‰å®šæ€§ã‚’é«˜ã‚ã‚‹\n",
    "def safe_generate_unique_key(channel, store_id, visit_date, name, review_text):\n",
    "    cleaned_review = re.sub(r\"\\s+\", \"\", (review_text or \"\").strip().lower())[:50]\n",
    "    cleaned_name = (name or \"\").strip().lower()\n",
    "    cleaned_date = (visit_date or \"\").strip() # visit_dateãŒNoneã®å ´åˆã«ç©ºæ–‡å­—åˆ—ã«ãªã‚‹ã‚ˆã†ã«\n",
    "    \n",
    "    base = f\"{channel}_{store_id}_{cleaned_date}_{cleaned_name}_{cleaned_review}\"\n",
    "    return hashlib.sha256(base.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# --- WebDriverè¨­å®š ---\n",
    "\n",
    "# WebDriverã®åˆæœŸè¨­å®šï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã€è‡ªå‹•åˆ¶å¾¡å›é¿ãªã©ï¼‰\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\") # æœ€æ–°ã®ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\") # è‡ªå‹•åˆ¶å¾¡ã‚’æ¤œçŸ¥ã•ã›ãªã„ã‚ˆã†ã«ã™ã‚‹\n",
    "    options.add_argument(\"--no-sandbox\") # Dockerã‚„CI/CDç’°å¢ƒã§å¿…è¦ã«ãªã‚‹å ´åˆãŒã‚ã‚‹\n",
    "    options.add_argument(\"--disable-dev-shm-usage\") # Dockerã‚„CI/CDç’°å¢ƒã§å¿…è¦ã«ãªã‚‹å ´åˆãŒã‚ã‚‹\n",
    "    options.add_argument(\"--window-size=1920,1080\") # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’è¨­å®š\n",
    "    options.add_argument(\"--incognito\") # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•\n",
    "    \n",
    "    # WebDriverManagerã§ChromeDriverã‚’è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»è¨­å®š\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# --- Supabase é–¢é€£é–¢æ•° ---\n",
    "\n",
    "# æ—¢å­˜ã®unique_keyã‚’Supabaseã‹ã‚‰ä¸€æ‹¬å–å¾—ã—ã€ã‚»ãƒƒãƒˆã§è¿”ã™\n",
    "def fetch_existing_unique_keys():\n",
    "    print(\"ğŸ”„ Supabaseã‹ã‚‰æ—¢å­˜ã®unique_keyã‚’å–å¾—ä¸­...\")\n",
    "    response = requests.get(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}?select=unique_key\", headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        existing_keys = {x[\"unique_key\"] for x in response.json()}\n",
    "        print(f\"âœ… æ—¢å­˜ã®unique_keyã‚’ {len(existing_keys)} ä»¶å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return existing_keys\n",
    "    else:\n",
    "        print(f\"âŒ æ—¢å­˜ã‚­ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}\")\n",
    "        return set() # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®ã‚»ãƒƒãƒˆã‚’è¿”ã™\n",
    "\n",
    "# ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’Supabaseã«æŒ¿å…¥ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰\n",
    "def insert_reviews_to_supabase(reviews_data, existing_keys_set):\n",
    "    inserted_count = 0\n",
    "    if not reviews_data:\n",
    "        print(\"ğŸ’¡ æŒ¿å…¥ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"â˜ï¸ Supabaseã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ä¸­ï¼ˆåˆè¨ˆ {len(reviews_data)} ä»¶ï¼‰...\")\n",
    "    for r in reviews_data:\n",
    "        unique_key = r.get('unique_key')\n",
    "        if not unique_key:\n",
    "            print(f\"âš ï¸ unique_keyãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {r.get('name', 'N/A')}\")\n",
    "            continue\n",
    "\n",
    "        # æ—¢å­˜ã®ã‚­ãƒ¼ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã¦ã„ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—\n",
    "        if unique_key in existing_keys_set:\n",
    "            # print(f\"âš ï¸ é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—: {unique_key} - {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.post(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}\", headers=HEADERS, json=r)\n",
    "            if response.status_code in [200, 201]:\n",
    "                inserted_count += 1\n",
    "                existing_keys_set.add(unique_key) # æ–°ã—ãæŒ¿å…¥ã•ã‚ŒãŸã‚­ãƒ¼ã‚’ãƒ¡ãƒ¢ãƒªä¸Šã®ã‚»ãƒƒãƒˆã«è¿½åŠ \n",
    "                print(f\"âœ… ä¿å­˜æˆåŠŸ: {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            else:\n",
    "                print(f\"âŒ Supabase POSTã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text} - ãƒ‡ãƒ¼ã‚¿unique_key: {unique_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e} - ãƒ‡ãƒ¼ã‚¿unique_key: {unique_key}\")\n",
    "    print(f\"ğŸ“¦ Supabaseã«æ–°è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ {inserted_count} ä»¶ä¿å­˜ã—ã¾ã—ãŸã€‚\")\n",
    "    return inserted_count\n",
    "\n",
    "# --- Google Maps ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•° ---\n",
    "\n",
    "# Google Mapsã®ã‚¯ãƒã‚³ãƒŸã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "def click_google_review_tab(driver):\n",
    "    try:\n",
    "        review_tab = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label,\"ã‚¯ãƒã‚³ãƒŸ\")]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", review_tab) # JavaScriptã§ã‚¯ãƒªãƒƒã‚¯ã‚’è©¦ã¿ã‚‹\n",
    "        time.sleep(2) # ã‚¯ãƒªãƒƒã‚¯å¾Œã®å¾…æ©Ÿæ™‚é–“ã‚’é•·ãã™ã‚‹\n",
    "        print(\"âœ… Google Maps ã‚¯ãƒã‚³ãƒŸã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯å®Œäº†\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Maps ã‚¯ãƒã‚³ãƒŸã‚¿ãƒ–ã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}\")\n",
    "\n",
    "# Google Mapsã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã€Œæ–°ã—ã„é †ã€ã§ä¸¦ã³æ›¿ãˆ\n",
    "def click_google_sort_by_new(driver):\n",
    "    try:\n",
    "        # ã€Œä¸¦ã¹æ›¿ãˆã€ãƒœã‚¿ãƒ³ã®XPathã‚’ã‚ˆã‚Šå…·ä½“çš„ã«\n",
    "        sort_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[.//span[text()=\"ä¸¦ã¹æ›¿ãˆ\"]]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", sort_button)\n",
    "        time.sleep(1) # ã‚¯ãƒªãƒƒã‚¯å¾Œã®å¾…æ©Ÿ\n",
    "\n",
    "        # ã€Œæ–°ã—ã„é †ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ãŸã‚ã®JavaScript\n",
    "        script = '''\n",
    "            const elements = Array.from(document.querySelectorAll('div[role=\"menuitem\"]'));\n",
    "            const target = elements.find(el => el.textContent.trim() === 'æ–°ã—ã„é †');\n",
    "            if (target) { target.click(); return 'clicked'; } else { return 'not found'; }\n",
    "        '''\n",
    "        result = driver.execute_script(script)\n",
    "        print(f\"ğŸ§­ Google Maps ä¸¦ã³æ›¿ãˆã€æ–°ã—ã„é †ã€ã‚¯ãƒªãƒƒã‚¯çµæœ: {result}\")\n",
    "        time.sleep(2) # ä¸¦ã³æ›¿ãˆé©ç”¨å¾Œã®å¾…æ©Ÿæ™‚é–“ã‚’é•·ãã™ã‚‹\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Maps ä¸¦ã³æ›¿ãˆã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}\")\n",
    "\n",
    "# Google Mapsã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒªã‚¢ã‚’è¦‹ã¤ã‘ã‚‹\n",
    "def find_google_scrollable_area(driver):\n",
    "    print(\"ğŸ” Google Maps ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã‚’æ¢ç´¢ä¸­...\")\n",
    "    try:\n",
    "        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ã®æœ€åˆã®è¦ç´ ãŒå­˜åœ¨ã™ã‚‹ã¾ã§å¾…æ©Ÿã—ã€ãã®ç¥–å…ˆè¦ç´ ã‹ã‚‰ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªé ˜åŸŸã‚’æ¢ã™\n",
    "        scrollable_div = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-review-id]:first-of-type'))\n",
    "        ).find_element(By.XPATH, './ancestor::div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]')\n",
    "        print(\"âœ… Google Maps ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç™ºè¦‹\")\n",
    "        return scrollable_div\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Maps ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {e}\")\n",
    "        return None\n",
    "\n",
    "# Google Mapsã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŒ‡å®šä»¶æ•°ã¾ãŸã¯æœ€å¾Œã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«\n",
    "def scroll_google_reviews(driver, scrollable_div, target_reviews=200, max_scrolls=200, patience_scrolls=10):\n",
    "    prev_count = 0\n",
    "    same_count_times = 0\n",
    "    print(f\"â†˜ï¸ Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­ (ç›®æ¨™: {target_reviews}ä»¶)...\")\n",
    "    for i in range(max_scrolls):\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", scrollable_div)\n",
    "        time.sleep(0.5) # çŸ­ã‚ã®å¾…æ©Ÿ\n",
    "        reviews = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "        curr_count = len(reviews)\n",
    "        # print(f\"   ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« {i+1}å›ç›®ï¼šç¾åœ¨ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•° = {curr_count}\") # ãƒ‡ãƒãƒƒã‚°ç”¨\n",
    "\n",
    "        if curr_count >= target_reviews:\n",
    "            print(f\"âœ… Google Maps {target_reviews}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«åˆ°é” â†’ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«çµ‚äº†\")\n",
    "            break\n",
    "        if curr_count == prev_count:\n",
    "            same_count_times += 1\n",
    "            if same_count_times >= patience_scrolls:\n",
    "                print(f\"âš ï¸ Google Maps {patience_scrolls}å›é€£ç¶šã§ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°å¢—åŠ ãªã— â†’ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­æ–­\")\n",
    "                break\n",
    "        else:\n",
    "            same_count_times = 0\n",
    "            prev_count = curr_count\n",
    "    \n",
    "    # å…¨ã¦ã®ã€Œã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å…¨æ–‡ã‚’è¡¨ç¤º\n",
    "    try:\n",
    "        expand_buttons = driver.find_elements(By.CSS_SELECTOR, 'button.w8nwRe')\n",
    "        print(f\"ğŸ‘ï¸â€ğŸ—¨ï¸ Google Maps ã€ã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ {len(expand_buttons)} å€‹ã‚’æ¤œå‡ºã€ã‚¯ãƒªãƒƒã‚¯ä¸­...\")\n",
    "        for btn in expand_buttons:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                # time.sleep(0.05) # çŸ­ã„å¾…æ©Ÿã§è² è·ã‚’æ¸›ã‚‰ã™\n",
    "            except Exception as e:\n",
    "                pass # å¤§é‡ã«å‡ºåŠ›ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯è¡¨ç¤ºã—ãªã„\n",
    "        print(\"âœ… Google Maps ã€ã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å®Œäº†\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Maps ã€ã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å‡¦ç†å¤±æ•—: {e}\")\n",
    "\n",
    "# Google Mapsã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±ã‚’æŠ½å‡º\n",
    "def extract_google_reviews(driver):\n",
    "    ref_date = datetime.now() # åŸºæº–æ—¥ï¼ˆç¾åœ¨æ—¥æ™‚ï¼‰\n",
    "    reviews = []\n",
    "    # å®Œå…¨ã«å±•é–‹ã•ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—\n",
    "    blocks = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "    print(f\"âš™ï¸ Google Maps ãƒšãƒ¼ã‚¸ã‹ã‚‰ {len(blocks)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºä¸­...\")\n",
    "\n",
    "    for block in blocks:\n",
    "        unique_key = block.get_attribute("data-review-id")
    "        if not unique_key:
    "           continue  # IDãŒãªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—
    "\n",
    "        soup = BeautifulSoup(block.get_attribute("innerHTML"), "html.parser")
    "\n",
    "        review_text_elem = soup.select_one('.MyEned span.wiI7pd')\n",
    "        review_text = review_text_elem.text.strip() if review_text_elem else \"\"\n",
    "        if not review_text:
    "           continue  # æœ¬æ–‡ãªã—ã¯ã‚¹ã‚­ãƒƒãƒ—
    "\n",
    "        visit_date = None\n",
    "        visit_month = None\n",
    "        try:\n",
    "            rating_block = soup.select_one(\"div.DU9Pgb\")\n",
    "            if rating_block:\n",
    "                publish_span = rating_block.select_one(\"span.rsqaWe\")\n",
    "                if publish_span:\n",
    "                    txt = publish_span.get_text(strip=True)\n",
    "                    visit_datetime = None\n",
    "\n",
    "                    # ç›¸å¯¾æ—¥ä»˜ï¼ˆä¾‹: 3æ™‚é–“å‰ã€5æ—¥å‰ã€2é€±é–“å‰ã€3ã‹æœˆå‰ã€1å¹´å‰ï¼‰ã®å‡¦ç†\n",
    "                    if \"æ™‚é–“å‰\" in txt:\n",
    "                        hours = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(hours=hours)\n",
    "                    elif \"æ—¥å‰\" in txt:\n",
    "                        days = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=days)\n",
    "                    elif \"é€±é–“å‰\" in txt:\n",
    "                        weeks = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(weeks=weeks * 7) # 1é€±é–“ã¯7æ—¥\n",
    "                    elif \"ã‹æœˆå‰\" in txt:\n",
    "                        months = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        # å³å¯†ãªæœˆã®è¨ˆç®—ã¯timedeltaã§ã¯é›£ã—ã„ãŒã€æ¦‚ç®—ã§å¯¾å¿œ\n",
    "                        visit_datetime = ref_date - timedelta(days=30 * months)\n",
    "                    elif \"å¹´å‰\" in txt:\n",
    "                        years = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=365 * years) # é–å¹´è€ƒæ…®ãªã—ã®æ¦‚ç®—\n",
    "                    # çµ¶å¯¾æ—¥ä»˜ï¼ˆä¾‹: 2023å¹´10æœˆ26æ—¥, 2023å¹´10æœˆï¼‰ã®å‡¦ç†\n",
    "                    elif re.match(r\"^\\d{4}å¹´\\d{1,2}æœˆ\\d{1,2}æ—¥$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Yå¹´%mæœˆ%dæ—¥\")\n",
    "                    elif re.match(r\"^\\d{4}å¹´\\d{1,2}æœˆ$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Yå¹´%mæœˆ\")\n",
    "                    \n",
    "                    if visit_datetime:\n",
    "                        visit_date = visit_datetime.date().isoformat()\n",
    "                        visit_month = visit_datetime.replace(day=1).date().isoformat()\n",
    "                    else:\n",
    "                        # ã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚‚ãƒãƒƒãƒã—ãªã„å ´åˆã€Noneã®ã¾ã¾\n",
    "                        pass\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Google Maps visit_date æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e} (å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: {txt if 'txt' in locals() else 'N/A'})\")\n",
    "\n",
    "        total_score = None\n",
    "        score_elem = soup.select_one('span.kvMYJc[aria-label]')\n",
    "        if score_elem and \"ã¤æ˜Ÿ\" in score_elem.get(\"aria-label\", \"\"):\n",
    "            match = re.search(r\"(\\d+) ã¤æ˜Ÿ\", score_elem['aria-label'])\n",
    "            if match:\n",
    "                total_score = int(match.group(1))\n",
    "\n",
    "        # Google Mapsã®ã‚µãƒ–ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\n",
    "        def extract_google_sub_score(label):\n",
    "            score = None\n",
    "            score_blocks = soup.select(\"div.PBK6be span.RfDO5c\")\n",
    "            for block in score_blocks:\n",
    "                bold = block.find(\"b\")\n",
    "                if bold and label in bold.text:\n",
    "                    text = block.get_text(strip=True)\n",
    "                    match = re.search(rf\"{label}:\\s*(\\d+)\", text)\n",
    "                    if match:\n",
    "                        score = int(match.group(1))\n",
    "                        break\n",
    "            return score\n",
    "\n",
    "        food_score = extract_google_sub_score(\"é£Ÿäº‹\")\n",
    "        service_score = extract_google_sub_score(\"ã‚µãƒ¼ãƒ“ã‚¹\")\n",
    "        atmosphere_score = extract_google_sub_score(\"é›°å›²æ°—\")\n",
    "\n",
    "        # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ã«ã€Œãƒ©ãƒ³ãƒã€ã¾ãŸã¯ã€Œãƒ‡ã‚£ãƒŠãƒ¼ã€ãŒå«ã¾ã‚Œã‚‹ã‹ã§åˆ¤å®š\n",
    "        lunch = \"ãƒ©ãƒ³ãƒ\" in review_text\n",
    "        dinner = \"ãƒ‡ã‚£ãƒŠãƒ¼\" in review_text\n",
    "\n",
    "        price_range = None\n",
    "        price_elem = soup.find(\"span\", attrs={\"aria-label\": re.compile(r\"ï¿¥\")})\n",
    "        if price_elem:\n",
    "            price_range = price_elem['aria-label']\n",
    "\n",
    "        user_button = soup.select_one('button[aria-label*=\"ã•ã‚“ã®ã‚¯ãƒã‚³ãƒŸ\"]')\n",
    "        user_name = user_button['aria-label'].split('ã•ã‚“')[0] if user_button else \"\"\n",
    "        a_tag = soup.select_one('a')\n",
    "        user_url = \"https://www.google.com\" + a_tag['href'] if a_tag else \"\"\n",
    "\n",
    "        unique_key = block.get_attribute("data-review-id")
    "\n", 
    "        reviews.append({\n",
    "            \"store_id\": STORE_ID,\n",
    "            \"channel\": \"googlemaps\",\n",
    "            \"unique_key\": unique_key,\n",
    "            \"review\": review_text,\n",
    "            \"visit_date\": visit_date,\n",
    "            \"visit_month\": visit_month,\n",
    "            \"name\": user_name,\n",
    "            \"user_url\": user_url,\n",
    "            \"total_score\": total_score,\n",
    "            \"food_score\": food_score,\n",
    "            \"service_score\": service_score,\n",
    "            \"atmosphere_score\": atmosphere_score,\n",
    "            \"lunch\": lunch,\n",
    "            \"dinner\": dinner,\n",
    "            \"price_range\": price_range,\n",
    "            \"inserted_at\": jst_now()\n",
    "        })\n",
    "    print(f\"ğŸ“¦ Google Mapsã‹ã‚‰ {len(reviews)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºå®Œäº†\")\n",
    "    return reviews\n",
    "\n",
    "\n",
    "\n",
    "# ============ ãƒ¡ã‚¤ãƒ³å‡¦ç† ============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # å„ã‚µã‚¤ãƒˆã®URLã‚’è¨­å®š\n",
    "    # Google Maps URLã¯ã€ç›´æ¥Google Mapsã®åº—èˆ—ãƒšãƒ¼ã‚¸URLã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„\n",
    "    # ä¾‹: \"https://www.google.com/maps/place/åº—èˆ—å/@ç·¯åº¦,çµŒåº¦,ã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«z/data=!3m1!4b1!4m8!3m7!1s...\"\n",
    "    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ–ãŒè‡ªå‹•ã§é–‹ãURLã¯ã€æœ«å°¾ã« /reviews ã‚’è¿½åŠ ã™ã‚‹ã¨è‰¯ã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚\n",
    "    google_maps_url = \"https://www.google.com/maps/place/Parking+Cafe+ReUnion+Arashiyama/@35.0185282,135.6699421,16z/data=!4m12!1m2!2m1!1sParking+Cafe+ReUnion+Arashiyama!3m8!1s0x6001a97cb260f96d:0x8b89bd9d4be74cbb!8m2!3d35.0185282!4d135.6794693!9m1!1b1!15sCh9QYXJraW5nIENhZmUgUmVVbmlvbiBBcmFzaGl5YW1hWiEiH3BhcmtpbmcgY2FmZSByZXVuaW9uIGFyYXNoaXlhbWGSAQRjYWZlqgFoCg0vZy8xMXZ5d3QxNGcxEAEqECIMcGFya2luZyBjYWZlKAAyHhABIhpdOq0vpJ3wfvgVhz-YkgZsjwej9T-i4uwheTIjEAIiH3BhcmtpbmcgY2FmZSByZXVuaW9uIGFyYXNoaXlhbWHgAQA!16s%2Fg%2F11vywt14g1?entry=ttu&g_ep=EgoyMDI1MDUyMS4wIKXMDSoASAFQAw%3D%3D\"\n",
    "\n",
    "    driver = None # driverã‚’åˆæœŸåŒ–\n",
    "    all_reviews = [] # å…¨ã‚µã‚¤ãƒˆã‹ã‚‰å–å¾—ã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "\n",
    "    try:\n",
    "        driver = setup_driver() # WebDriverã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–\n",
    "\n",
    "        # æ—¢å­˜ã®unique_keyã‚’Supabaseã‹ã‚‰ä¸€åº¦ã ã‘å–å¾—\n",
    "        existing_unique_keys = fetch_existing_unique_keys()\n",
    "\n",
    "        # --- å„ã‚µã‚¤ãƒˆã‹ã‚‰ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ã¨çµåˆ ---\n",
    "\n",
    "        # Google Maps\n",
    "        print(\"\\n=== Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–‹å§‹ ===\")\n",
    "        driver.get(google_maps_url)\n",
    "        time.sleep(5) # ãƒšãƒ¼ã‚¸ãŒå®Œå…¨ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã®ã‚’å¾…ã¤\n",
    "        click_google_review_tab(driver)\n",
    "        click_google_sort_by_new(driver)\n",
    "        scroll_target = find_google_scrollable_area(driver)\n",
    "        if scroll_target:\n",
    "            scroll_google_reviews(driver, scroll_target, target_reviews=200, max_scrolls=200) # ã‚ˆã‚Šå¤šãã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è©¦ã¿ã‚‹\n",
    "            google_reviews = extract_google_reviews(driver)\n",
    "            all_reviews.extend(google_reviews)\n",
    "        else:\n",
    "            print(\"âŒ Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒªã‚¢ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "        print(\"=== Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—å®Œäº† ===\\n\")\n",
    "\n",
    "        # Tabelog\n",
    "        tabelog_reviews = scrape_tabelog(tabelog_url, STORE_ID, driver)\n",
    "        all_reviews.extend(tabelog_reviews)\n",
    "\n",
    "        # Hotpepper\n",
    "        hotpepper_reviews = scrape_hotpepper(hotpepper_url, STORE_ID, driver)\n",
    "        all_reviews.extend(hotpepper_reviews)\n",
    "\n",
    "        # Ozmall\n",
    "        ozmall_reviews = scrape_ozmall(ozmall_url, STORE_ID, driver)\n",
    "        all_reviews.extend(ozmall_reviews)\n",
    "\n",
    "        # Retty\n",
    "        retty_reviews = scrape_retty(retty_url, STORE_ID, driver)\n",
    "        all_reviews.extend(retty_reviews)\n",
    "\n",
    "        # Ikyu\n",
    "        ikyu_reviews = scrape_ikyu(ikyu_url, STORE_ID, driver)\n",
    "        all_reviews.extend(ikyu_reviews)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "    finally:\n",
    "        if driver: # driverãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰çµ‚äº†\n",
    "            driver.quit() # å…¨ã¦ã®å‡¦ç†ãŒçµ‚ã‚ã£ãŸã‚‰WebDriverã‚’é–‰ã˜ã‚‹\n",
    "\n",
    "    print(f\"\\n--- å…¨ã‚µã‚¤ãƒˆåˆè¨ˆå–å¾—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {len(all_reviews)} ---\\n\")\n",
    "\n",
    "    # --- å–å¾—ã—ãŸå…¨ã¦ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’Supabaseã«æŒ¿å…¥ ---\n",
    "    if all_reviews:\n",
    "        insert_reviews_to_supabase(all_reviews, existing_unique_keys)\n",
    "    else:\n",
    "        print(\"å–å¾—ã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚Supabaseã¸ã®æŒ¿å…¥ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
