{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536d3226-d7a2-48e1-9f94-0f0c966270f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Supabaseから既存のunique_keyを取得中...\n",
      "✅ 既存のunique_keyを 747 件取得しました。\n",
      "\n",
      "=== Google Maps レビュー取得開始 ===\n",
      "✅ Google Maps クチコミタブをクリック完了\n",
      "🧭 Google Maps 並び替え『新しい順』クリック結果: not found\n",
      "🔎 Google Maps スクロール対象を探索中...\n",
      "✅ Google Maps スクロール対象のレビューセクションを発見\n",
      "↘️ Google Maps レビューをスクロール中 (目標: 200件)...\n",
      "✅ Google Maps 200件のレビューに到達 → スクロール終了\n",
      "👁️‍🗨️ Google Maps 『もっと見る』ボタン 140 個を検出、クリック中...\n",
      "✅ Google Maps 『もっと見る』ボタンクリック完了\n",
      "⚙️ Google Maps ページから 208 件のレビューブロックを抽出中...\n",
      "📦 Google Mapsから 208 件のレビューを抽出完了\n",
      "=== Google Maps レビュー取得完了 ===\n",
      "\n",
      "\n",
      "=== Tabelog (https://tabelog.com/kyoto/A2601/A260403/26005250/dtlrvwlst/)からレビュー取得開始 ===\n",
      "➡️ Tabelog 次ページボタンが見つかりませんでした。スクレイピング終了。\n",
      "📦 Tabelogから 384 件のレビューを抽出完了\n",
      "\n",
      "=== Hotpepper (https://www.hotpepper.jp/strJ000728780/report/)からレビュー取得開始 ===\n",
      "➡️ Hotpepper 次ページボタンが見つかりませんでした。スクレイピング終了。\n",
      "📦 Hotpepperから 7 件のレビューを抽出完了\n",
      "\n",
      "=== Retty (https://retty.me/area/PRE26/ARE114/SUB11401/100000025475/reports/)からレビュー取得開始 ===\n",
      "➡️ Retty 次ページボタンが見つかりませんでした。スクレイピング終了。\n",
      "📦 Rettyから 20 件のレビューを抽出完了\n",
      "\n",
      "--- 全サイト合計取得レビュー数: 619 ---\n",
      "\n",
      "☁️ Supabaseにレビューデータを挿入中（合計 619 件）...\n",
      "✅ 保存成功: tabelog - kanae.s (2025-05-01)\n",
      "✅ 保存成功: tabelog - oruru2968 (2025-04-01)\n",
      "✅ 保存成功: tabelog - Retreat-7 (2025-04-01)\n",
      "✅ 保存成功: tabelog - ぷりまりん (2025-04-01)\n",
      "✅ 保存成功: tabelog - hinini (2025-03-01)\n",
      "✅ 保存成功: tabelog - たまには贅沢したい。 (2025-03-01)\n",
      "✅ 保存成功: tabelog - mika0652 (2025-02-01)\n",
      "✅ 保存成功: tabelog - すいぐる (2025-02-01)\n",
      "✅ 保存成功: tabelog - 気まぐれトレーニーgirl (2025-02-01)\n",
      "✅ 保存成功: tabelog - koucharapo (2025-02-01)\n",
      "✅ 保存成功: tabelog - ナミヘイ0628 (2025-01-01)\n",
      "✅ 保存成功: tabelog - anchan1989 (2025-01-01)\n",
      "✅ 保存成功: tabelog - 3be76b47652 (2025-01-01)\n",
      "✅ 保存成功: tabelog - 急にラーメン食べたい病 (2025-01-01)\n",
      "✅ 保存成功: tabelog - ruu0141 (2025-01-01)\n",
      "✅ 保存成功: tabelog - ぱぱ補完計画 (2025-01-01)\n",
      "✅ 保存成功: tabelog - 永坂町の健啖家 (2025-01-01)\n",
      "✅ 保存成功: tabelog - さえまるく (2024-12-01)\n",
      "✅ 保存成功: tabelog - せんべい&みかん (2024-12-01)\n",
      "✅ 保存成功: tabelog - ik-46 (2024-12-01)\n",
      "✅ 保存成功: tabelog - 漣07 (2024-12-01)\n",
      "✅ 保存成功: tabelog - 京都市のひと (2024-12-01)\n",
      "✅ 保存成功: tabelog - お肉大好きサラリーマン (2024-12-01)\n",
      "✅ 保存成功: tabelog - かほるんち (2024-12-01)\n",
      "✅ 保存成功: tabelog - 0371アンパンウーマン (2024-11-01)\n",
      "✅ 保存成功: tabelog - short12193 (2024-11-01)\n",
      "✅ 保存成功: tabelog - fuki38 (2024-11-01)\n",
      "✅ 保存成功: tabelog - あみ˙꒳˙ (2024-10-01)\n",
      "✅ 保存成功: tabelog - 3c2c38 (2024-10-01)\n",
      "✅ 保存成功: tabelog - いよっぷ (2024-10-01)\n",
      "✅ 保存成功: tabelog - konyasu0714 (2024-10-01)\n",
      "✅ 保存成功: tabelog - corgibd (2024-09-01)\n",
      "✅ 保存成功: tabelog - cdef4c46224 (2024-09-01)\n",
      "✅ 保存成功: tabelog - 食べるの好きにゃん (2024-09-01)\n",
      "✅ 保存成功: tabelog - おばtea (2024-09-01)\n",
      "✅ 保存成功: tabelog - 激辛大好きマン (2024-08-01)\n",
      "✅ 保存成功: tabelog - 9d76f3 (2024-08-01)\n",
      "✅ 保存成功: tabelog - 73b968 (2024-08-01)\n",
      "✅ 保存成功: tabelog - こままごん (2024-08-01)\n",
      "✅ 保存成功: tabelog - mafu_Walker (2024-08-01)\n",
      "✅ 保存成功: tabelog - bqv00106 (2024-07-01)\n",
      "✅ 保存成功: tabelog - nana11222019 (2024-07-01)\n",
      "✅ 保存成功: tabelog - ゆーみん318 (2024-07-01)\n",
      "✅ 保存成功: tabelog - Shima＊ (2024-07-01)\n",
      "✅ 保存成功: tabelog - あの夏の日 (2024-07-01)\n",
      "✅ 保存成功: tabelog - くいしんbouu (2024-07-01)\n",
      "✅ 保存成功: tabelog - okasam55 (2024-06-01)\n",
      "✅ 保存成功: tabelog - まとぽ (2024-06-01)\n",
      "✅ 保存成功: tabelog - MAKISATI (2024-06-01)\n",
      "✅ 保存成功: tabelog - エッグログ (2024-06-01)\n",
      "✅ 保存成功: tabelog - まゆcafe (2024-06-01)\n",
      "✅ 保存成功: tabelog - obi8t (2024-06-01)\n",
      "✅ 保存成功: tabelog - Rin_rin (2024-06-01)\n",
      "✅ 保存成功: tabelog - らいが (2024-06-01)\n",
      "✅ 保存成功: tabelog - 6ba61659883 (2024-05-01)\n",
      "✅ 保存成功: tabelog - クリン99429 (2024-05-01)\n",
      "✅ 保存成功: tabelog - yuuuu0116 (2024-05-01)\n",
      "✅ 保存成功: tabelog - はすのそら (2024-05-01)\n",
      "✅ 保存成功: tabelog - 嬉しい楽しい美味しい (2024-05-01)\n",
      "✅ 保存成功: tabelog - 8c2a67 (2024-05-01)\n",
      "✅ 保存成功: tabelog - 637061 (2024-04-01)\n",
      "✅ 保存成功: tabelog - almondeyes (2024-04-01)\n",
      "✅ 保存成功: tabelog - koala31495 (2024-04-01)\n",
      "✅ 保存成功: tabelog - r435 (2024-04-01)\n",
      "✅ 保存成功: tabelog - gojuu119 (2024-04-01)\n",
      "✅ 保存成功: tabelog - 19y98k (2024-04-01)\n",
      "✅ 保存成功: tabelog - らんちなんみん (2024-03-01)\n",
      "✅ 保存成功: tabelog - maanx (2024-03-01)\n",
      "✅ 保存成功: tabelog - kimid (2024-03-01)\n",
      "✅ 保存成功: tabelog - 此香 (2024-03-01)\n",
      "✅ 保存成功: tabelog - viehcle (2024-01-01)\n",
      "✅ 保存成功: tabelog - ライチョウ47 (2023-12-01)\n",
      "✅ 保存成功: tabelog - たつたつ77681 (2023-12-01)\n",
      "✅ 保存成功: tabelog - nyan_3656 (2023-12-01)\n",
      "✅ 保存成功: tabelog - fyama13 (2023-12-01)\n",
      "✅ 保存成功: tabelog - manmaruchan (2023-11-01)\n",
      "✅ 保存成功: tabelog - ゆうた1996 (2023-11-01)\n",
      "✅ 保存成功: tabelog - uuu555 (2023-10-01)\n",
      "✅ 保存成功: tabelog - 太っ腹 (2023-10-01)\n",
      "✅ 保存成功: tabelog - SeaZ (2023-10-01)\n",
      "✅ 保存成功: tabelog - ゆっきもち (2023-09-01)\n",
      "✅ 保存成功: tabelog - 36671e20107 (2023-08-01)\n",
      "✅ 保存成功: tabelog - moki-mokichi (2023-07-01)\n",
      "✅ 保存成功: tabelog - 44572316226 (2023-06-01)\n",
      "✅ 保存成功: tabelog - スマイルみぞ (2023-05-01)\n",
      "✅ 保存成功: tabelog - あ、よーちゃん (2023-05-01)\n",
      "✅ 保存成功: tabelog - pikarin0101 (2023-04-01)\n",
      "✅ 保存成功: tabelog - 日常茶番寺 (2023-04-01)\n",
      "✅ 保存成功: tabelog - PigPengu (2023-04-01)\n",
      "✅ 保存成功: tabelog - Ranntama (2023-04-01)\n",
      "✅ 保存成功: tabelog - chima0704 (2023-03-01)\n",
      "✅ 保存成功: tabelog - rai0603 (2023-03-01)\n",
      "✅ 保存成功: tabelog - luna630 (2023-03-01)\n",
      "✅ 保存成功: tabelog - みみかきうさぎ (2023-03-01)\n",
      "✅ 保存成功: tabelog - 9c85e8 (2023-03-01)\n",
      "✅ 保存成功: tabelog - cornk (2023-01-01)\n",
      "✅ 保存成功: tabelog - yuuu_1203 (2023-01-01)\n",
      "✅ 保存成功: tabelog - SANdano青 (2022-12-01)\n",
      "✅ 保存成功: tabelog - haluna0313 (2022-12-01)\n",
      "✅ 保存成功: tabelog - Seabasschan (2022-12-01)\n",
      "✅ 保存成功: tabelog - chino600 (2022-12-01)\n",
      "✅ 保存成功: tabelog - Mr.熊太郎 (2022-11-01)\n",
      "✅ 保存成功: tabelog - masamasa-masa (2022-11-01)\n",
      "✅ 保存成功: tabelog - ボニ丸620103 (2022-11-01)\n",
      "✅ 保存成功: tabelog - WEST315 (2022-11-01)\n",
      "✅ 保存成功: tabelog - ay_ys (2022-11-01)\n",
      "✅ 保存成功: tabelog - penpen0511 (2022-10-01)\n",
      "✅ 保存成功: tabelog - souffle21 (2022-10-01)\n",
      "✅ 保存成功: tabelog - nao.20180304 (2022-10-01)\n",
      "✅ 保存成功: tabelog - sao_ichan (2022-10-01)\n",
      "✅ 保存成功: tabelog - uizakura0923 (2022-10-01)\n",
      "✅ 保存成功: tabelog - なべ0628 (2022-09-01)\n",
      "✅ 保存成功: tabelog - カプチーノさんのグルメ (2022-09-01)\n",
      "✅ 保存成功: tabelog - teru0_0teru (2022-05-01)\n",
      "✅ 保存成功: tabelog - nbctbc (2022-05-01)\n",
      "✅ 保存成功: tabelog - body pit kyoto (2022-02-01)\n",
      "✅ 保存成功: tabelog - comotan (2021-12-01)\n",
      "✅ 保存成功: tabelog - tbzuyeon (2021-12-01)\n",
      "✅ 保存成功: tabelog - おしょうさん (2021-11-01)\n",
      "✅ 保存成功: tabelog - コニー♪ (2021-11-01)\n",
      "✅ 保存成功: tabelog - トニートニーパンダ (2021-11-01)\n",
      "✅ 保存成功: tabelog - あゆログ66 (2021-11-01)\n",
      "✅ 保存成功: tabelog - おしょうさん (2021-11-01)\n",
      "✅ 保存成功: tabelog - kana@かな (2021-10-01)\n",
      "✅ 保存成功: tabelog - myutea. (2021-06-01)\n",
      "✅ 保存成功: tabelog - ナスとトマト (2021-03-01)\n",
      "✅ 保存成功: tabelog - yoshi_3 (2020-12-01)\n",
      "✅ 保存成功: tabelog - momochapi (2020-12-01)\n",
      "✅ 保存成功: tabelog - Monchan- (2020-12-01)\n",
      "✅ 保存成功: tabelog - maru-181 (2020-11-01)\n",
      "✅ 保存成功: tabelog - しししし44 (2020-11-01)\n",
      "✅ 保存成功: tabelog - ひとっちやん (2020-08-01)\n",
      "✅ 保存成功: tabelog - ほわわんこねずみ (2020-08-01)\n",
      "✅ 保存成功: tabelog - maru-181 (2020-06-01)\n",
      "✅ 保存成功: tabelog - まむう (2020-06-01)\n",
      "✅ 保存成功: tabelog - 鳴滝翔月 (2020-03-01)\n",
      "✅ 保存成功: tabelog - 30過ぎの道草王 (2020-03-01)\n",
      "✅ 保存成功: tabelog - まっつう1204 (2020-03-01)\n",
      "✅ 保存成功: tabelog - リカ0308 (2020-02-01)\n",
      "✅ 保存成功: tabelog - テンパリコ (2019-09-01)\n",
      "✅ 保存成功: tabelog - sa732 (2019-08-01)\n",
      "✅ 保存成功: tabelog - Miii4 (2019-07-01)\n",
      "✅ 保存成功: tabelog - もへまる (2018-11-01)\n",
      "✅ 保存成功: tabelog - カカオの子 (2018-03-01)\n",
      "✅ 保存成功: tabelog - むむ後期 (None)\n",
      "✅ 保存成功: tabelog - happy-ly (None)\n",
      "✅ 保存成功: tabelog - こつぐるめ (None)\n",
      "✅ 保存成功: tabelog - 23d654 (2025-05-01)\n",
      "✅ 保存成功: tabelog - きみゃこ (2025-02-01)\n",
      "✅ 保存成功: tabelog - d277f358043 (2025-01-01)\n",
      "✅ 保存成功: tabelog - chi-k108 (2024-11-01)\n",
      "✅ 保存成功: tabelog - 玉野のまっちゃん (2024-11-01)\n",
      "✅ 保存成功: tabelog - sakuraringo (2024-09-01)\n",
      "✅ 保存成功: tabelog - えりたま13 (2024-08-01)\n",
      "✅ 保存成功: tabelog - mamocchi (2024-06-01)\n",
      "✅ 保存成功: tabelog - Mar_ry_8 (2024-05-01)\n",
      "✅ 保存成功: tabelog - ilovedmh (2024-05-01)\n",
      "✅ 保存成功: tabelog - ななおなおなお (2024-04-01)\n",
      "✅ 保存成功: tabelog - maruo1111 (2024-03-01)\n",
      "✅ 保存成功: tabelog - nanocafe (2024-02-01)\n",
      "✅ 保存成功: tabelog - エミP (2023-07-01)\n",
      "✅ 保存成功: tabelog - rispecincceoakkey (2023-01-01)\n",
      "✅ 保存成功: tabelog - 八の字おかめ (2022-12-01)\n",
      "✅ 保存成功: tabelog - とまとまともも (2022-08-01)\n",
      "✅ 保存成功: tabelog - 014 しろごはん (2022-05-01)\n",
      "✅ 保存成功: tabelog - 6b4857 (2021-12-01)\n",
      "✅ 保存成功: tabelog - 果汁99% (2021-01-01)\n",
      "✅ 保存成功: tabelog - ねるねる ねるね (2020-10-01)\n",
      "✅ 保存成功: tabelog - kanaminomama (2020-07-01)\n",
      "✅ 保存成功: tabelog - Ai0305 (2020-02-01)\n",
      "✅ 保存成功: tabelog - 果汁99% (2020-02-01)\n",
      "✅ 保存成功: tabelog - h_a_n_a_ (2019-10-01)\n",
      "✅ 保存成功: tabelog - jasper9453 (2019-07-01)\n",
      "✅ 保存成功: tabelog - pino890 (2019-07-01)\n",
      "✅ 保存成功: tabelog - 満腹小娘 (2018-12-01)\n",
      "✅ 保存成功: tabelog - エロくそチキン (2018-11-01)\n",
      "✅ 保存成功: tabelog - dd.bb (2018-09-01)\n",
      "✅ 保存成功: tabelog - ばうワンコ (2017-12-01)\n",
      "✅ 保存成功: tabelog - ぴょんまさ (2017-08-01)\n",
      "✅ 保存成功: tabelog - 干瓢巻き星人 (2016-11-01)\n",
      "✅ 保存成功: tabelog - Hi-Fi CAMP (2016-10-01)\n",
      "✅ 保存成功: tabelog - SWMOON (None)\n",
      "✅ 保存成功: tabelog - pa0 (None)\n",
      "✅ 保存成功: tabelog - のりのりりこ (None)\n",
      "✅ 保存成功: tabelog - 44683772240 (2025-03-01)\n",
      "✅ 保存成功: tabelog - taepyon 0807 (2019-08-01)\n",
      "✅ 保存成功: tabelog - み‪ꪔ̤̮ (2018-06-01)\n",
      "✅ 保存成功: tabelog - みっちゃん⭐︎830 (2025-05-01)\n",
      "✅ 保存成功: tabelog - 5710a3 (2025-04-01)\n",
      "✅ 保存成功: tabelog - 舩津 寛至 (2024-08-01)\n",
      "✅ 保存成功: tabelog - nokagaku (2024-04-01)\n",
      "✅ 保存成功: tabelog - ゆゆみ6068 (2022-11-01)\n",
      "✅ 保存成功: tabelog - makom487 (2019-03-01)\n",
      "✅ 保存成功: tabelog - ついてるンルン (2018-02-01)\n",
      "✅ 保存成功: tabelog - ついてるンルン (2015-08-01)\n",
      "✅ 保存成功: tabelog - のんけろ (None)\n",
      "✅ 保存成功: tabelog - ぱらし (None)\n",
      "✅ 保存成功: tabelog - tsu bou (None)\n",
      "✅ 保存成功: tabelog - yusukenanfre (None)\n",
      "✅ 保存成功: tabelog - mary1115 (None)\n",
      "✅ 保存成功: tabelog - さわばやし (None)\n",
      "✅ 保存成功: tabelog - juras205 (2023-06-01)\n",
      "✅ 保存成功: tabelog - まえだマエ (None)\n",
      "✅ 保存成功: tabelog - うちだゆみ (None)\n",
      "✅ 保存成功: tabelog - ☆食べるくん☆ (2020-03-01)\n",
      "✅ 保存成功: tabelog - sK (2020-02-01)\n",
      "✅ 保存成功: tabelog - mnk1612 (2020-01-01)\n",
      "✅ 保存成功: tabelog - rojixx (2020-01-01)\n",
      "✅ 保存成功: tabelog - トイプードルしろちゃん (2020-01-01)\n",
      "✅ 保存成功: tabelog - まぁちん1234 (2020-01-01)\n",
      "✅ 保存成功: tabelog - シュガー08 (2019-12-01)\n",
      "✅ 保存成功: tabelog - mu_i_ka (2019-11-01)\n",
      "✅ 保存成功: tabelog - こばみつ (2019-11-01)\n",
      "✅ 保存成功: tabelog - さか まきこ (2019-11-01)\n",
      "✅ 保存成功: tabelog - てつみど (2019-09-01)\n",
      "✅ 保存成功: tabelog - umaimono-daisuki (2019-06-01)\n",
      "✅ 保存成功: tabelog - まろんママ (2019-05-01)\n",
      "✅ 保存成功: tabelog - momomegu (2019-05-01)\n",
      "✅ 保存成功: tabelog - トイプードルしろちゃん (2018-12-01)\n",
      "✅ 保存成功: tabelog - asari❤︎ (2018-11-01)\n",
      "✅ 保存成功: tabelog - ankodayo (2018-11-01)\n",
      "✅ 保存成功: tabelog - yaoyama8 (2018-11-01)\n",
      "✅ 保存成功: tabelog - 美食忍者 (2018-10-01)\n",
      "✅ 保存成功: tabelog - hrs0925 (2018-10-01)\n",
      "✅ 保存成功: tabelog - humptydumpty3 (2018-09-01)\n",
      "✅ 保存成功: tabelog - チャッピーチャンス (2018-07-01)\n",
      "✅ 保存成功: tabelog - mayulog014 (2018-05-01)\n",
      "✅ 保存成功: tabelog - エリンギ畑 (2018-04-01)\n",
      "✅ 保存成功: tabelog - xxはんぺんxx (2018-03-01)\n",
      "✅ 保存成功: tabelog - h umemi∞ (2018-03-01)\n",
      "✅ 保存成功: tabelog - 栗太郎★ (2018-03-01)\n",
      "✅ 保存成功: tabelog - たうぼー (2018-01-01)\n",
      "✅ 保存成功: tabelog - てつ925 (2018-01-01)\n",
      "✅ 保存成功: tabelog - アベレージ (2017-12-01)\n",
      "✅ 保存成功: tabelog - 喘息男 (2017-12-01)\n",
      "✅ 保存成功: tabelog - Mei13398 (2017-11-01)\n",
      "✅ 保存成功: tabelog - ちひろ(0v0) (2017-09-01)\n",
      "✅ 保存成功: tabelog - 紫陽花の朝 (2017-09-01)\n",
      "✅ 保存成功: tabelog - ひやじるんるん (2017-08-01)\n",
      "✅ 保存成功: tabelog - happy eater (2017-06-01)\n",
      "✅ 保存成功: tabelog - 気ままに旅人 (2017-06-01)\n",
      "✅ 保存成功: tabelog - アオチップ (2017-05-01)\n",
      "✅ 保存成功: tabelog - マイケル　ジャクソン (2017-04-01)\n",
      "✅ 保存成功: tabelog - genkiman99 (2017-04-01)\n",
      "✅ 保存成功: tabelog - 食と焙煎豆と。 (2017-03-01)\n",
      "✅ 保存成功: tabelog - tabitito (2017-02-01)\n",
      "✅ 保存成功: tabelog - みさみさ2041 (2017-01-01)\n",
      "✅ 保存成功: tabelog - 美味しい林檎 (2016-12-01)\n",
      "✅ 保存成功: tabelog - shutterbug (2016-12-01)\n",
      "✅ 保存成功: tabelog - セシモテレビ (2016-10-01)\n",
      "✅ 保存成功: tabelog - うさこっち (2016-08-01)\n",
      "✅ 保存成功: tabelog - ヒョンビンおばちゃん (2016-08-01)\n",
      "✅ 保存成功: tabelog - humptydumpty3 (2016-08-01)\n",
      "✅ 保存成功: tabelog - とまとプリン (2016-07-01)\n",
      "✅ 保存成功: tabelog - そんじょそこら (2016-07-01)\n",
      "✅ 保存成功: tabelog - Mりん1964 (2016-06-01)\n",
      "✅ 保存成功: tabelog - 咲ぽん (2016-06-01)\n",
      "✅ 保存成功: tabelog - BEAT MR (2016-06-01)\n",
      "✅ 保存成功: tabelog - えみえみぱん (2016-04-01)\n",
      "✅ 保存成功: tabelog - こじょる (2016-03-01)\n",
      "✅ 保存成功: tabelog - tony1961 (2016-03-01)\n",
      "✅ 保存成功: tabelog - 大哉心乎 (2016-01-01)\n",
      "✅ 保存成功: tabelog - 桜ねね (2015-12-01)\n",
      "✅ 保存成功: tabelog - アツシ0422 (2015-11-01)\n",
      "✅ 保存成功: tabelog - ipolani (2015-11-01)\n",
      "✅ 保存成功: tabelog - c-chan＊ (2015-11-01)\n",
      "✅ 保存成功: tabelog - Soul. (2015-10-01)\n",
      "✅ 保存成功: tabelog - ろくでなしの賽 (2015-10-01)\n",
      "✅ 保存成功: tabelog - キティ(ﾐ･｡･ﾐ)♡ (2015-09-01)\n",
      "✅ 保存成功: tabelog - angelｓ (2015-06-01)\n",
      "✅ 保存成功: tabelog - 日暮かごめ (2015-05-01)\n",
      "✅ 保存成功: tabelog - sillybubly (2015-05-01)\n",
      "✅ 保存成功: tabelog - 月灯 小夜子 (2015-04-01)\n",
      "✅ 保存成功: tabelog - aboちゃん (2015-04-01)\n",
      "✅ 保存成功: tabelog - まりも0311 (2015-02-01)\n",
      "✅ 保存成功: tabelog - sakaki0214 (2015-02-01)\n",
      "✅ 保存成功: tabelog - salsiccia (2015-01-01)\n",
      "✅ 保存成功: tabelog - 「まっすん」 (2015-01-01)\n",
      "✅ 保存成功: tabelog - しろくまCafe (2014-11-01)\n",
      "✅ 保存成功: tabelog - きゃんず (2014-11-01)\n",
      "✅ 保存成功: tabelog - soravish (2014-11-01)\n",
      "✅ 保存成功: tabelog - ナパっち (2014-10-01)\n",
      "✅ 保存成功: tabelog - さすらい講師 (2014-09-01)\n",
      "✅ 保存成功: tabelog - satochin0212 (2014-09-01)\n",
      "✅ 保存成功: tabelog - ゆきえゆきえ (2014-09-01)\n",
      "✅ 保存成功: tabelog - carmona (2014-08-01)\n",
      "✅ 保存成功: tabelog - コロンなお (2014-08-01)\n",
      "✅ 保存成功: tabelog - 座敷童子ちゃん (2014-08-01)\n",
      "✅ 保存成功: tabelog - ぬるβ (2014-07-01)\n",
      "✅ 保存成功: tabelog - カミュcamus (2014-06-01)\n",
      "✅ 保存成功: tabelog - クーベル (2014-05-01)\n",
      "✅ 保存成功: tabelog - oomimi (2014-04-01)\n",
      "✅ 保存成功: tabelog - ｋ－じゅん (2014-04-01)\n",
      "✅ 保存成功: tabelog - kyocafe (2014-03-01)\n",
      "✅ 保存成功: tabelog - kyotozuki (2014-03-01)\n",
      "✅ 保存成功: tabelog - えりんぎタモ (2013-12-01)\n",
      "✅ 保存成功: tabelog - らんらん☻ (2013-11-01)\n",
      "✅ 保存成功: tabelog - アイランドジロウ (2013-11-01)\n",
      "✅ 保存成功: tabelog - ＊kana＊ (2013-11-01)\n",
      "✅ 保存成功: tabelog - 溝ねずみ (2013-10-01)\n",
      "✅ 保存成功: tabelog - P-Chan (2013-09-01)\n",
      "✅ 保存成功: tabelog - やんやんこ (2013-08-01)\n",
      "✅ 保存成功: tabelog - ちゃ～こ (2013-07-01)\n",
      "✅ 保存成功: tabelog - hiro5er8 (2013-05-01)\n",
      "✅ 保存成功: tabelog - ミルコ24 (2013-01-01)\n",
      "✅ 保存成功: tabelog - Eva Gold (2013-01-01)\n",
      "✅ 保存成功: tabelog - のりたま1226 (2013-01-01)\n",
      "✅ 保存成功: tabelog - とまとら (2012-12-01)\n",
      "✅ 保存成功: tabelog - はすっこ (2012-10-01)\n",
      "✅ 保存成功: tabelog - 月ウサギ☆ (2012-10-01)\n",
      "✅ 保存成功: tabelog - 珈琲のんべぇ (2012-08-01)\n",
      "✅ 保存成功: tabelog - たかひろ072 (2012-05-01)\n",
      "✅ 保存成功: tabelog - つよつよつよぽん (2012-04-01)\n",
      "✅ 保存成功: tabelog - 薫美 (2012-04-01)\n",
      "✅ 保存成功: tabelog - 神戸の金庫屋のバカ息子 (2012-03-01)\n",
      "✅ 保存成功: tabelog - タムタン (2012-03-01)\n",
      "✅ 保存成功: tabelog - フェリー (2011-11-01)\n",
      "✅ 保存成功: tabelog - りりン (2011-11-01)\n",
      "✅ 保存成功: tabelog - シンザン (2011-10-01)\n",
      "✅ 保存成功: tabelog - keitai (2011-08-01)\n",
      "✅ 保存成功: tabelog - ひー太郎 (2011-04-01)\n",
      "✅ 保存成功: tabelog - 楽しい毎日 (2010-11-01)\n",
      "✅ 保存成功: tabelog - ジンゴズンゴ (2010-11-01)\n",
      "✅ 保存成功: tabelog - マイごん (2010-10-01)\n",
      "✅ 保存成功: tabelog - hanna梨 (2010-09-01)\n",
      "✅ 保存成功: tabelog - あさぴー1 (2010-08-01)\n",
      "✅ 保存成功: tabelog - 極楽とんぼ姫 (2010-07-01)\n",
      "✅ 保存成功: tabelog - relax-kou (2010-06-01)\n",
      "✅ 保存成功: tabelog - tiare (2010-06-01)\n",
      "✅ 保存成功: tabelog - ai-amu-mama (2010-06-01)\n",
      "✅ 保存成功: tabelog - まぁ〜るい (2010-02-01)\n",
      "✅ 保存成功: tabelog - ののちん (2010-01-01)\n",
      "✅ 保存成功: tabelog - S&R (2009-11-01)\n",
      "✅ 保存成功: tabelog - tu-tu-tu (2009-11-01)\n",
      "✅ 保存成功: tabelog - youringo (2009-10-01)\n",
      "✅ 保存成功: tabelog - ぴるず族 (2009-10-01)\n",
      "✅ 保存成功: tabelog - わこ0419 (2009-10-01)\n",
      "✅ 保存成功: tabelog - よるへい (2009-09-01)\n",
      "✅ 保存成功: tabelog - めいぷる (2009-05-01)\n",
      "✅ 保存成功: tabelog - 6i9poppa (2009-03-01)\n",
      "✅ 保存成功: tabelog - おとなりのトトロ (2008-11-01)\n",
      "✅ 保存成功: tabelog - palog (2008-09-01)\n",
      "✅ 保存成功: tabelog - まりぃ (2008-07-01)\n",
      "✅ 保存成功: tabelog - Kate (2008-01-01)\n",
      "✅ 保存成功: tabelog - modeerf (2007-11-01)\n",
      "✅ 保存成功: tabelog - hyakumanbeeeen (2016-12-01)\n",
      "✅ 保存成功: tabelog - 神大寺のかず坊２ (2015-11-01)\n",
      "✅ 保存成功: tabelog - yokko3329 (2015-10-01)\n",
      "✅ 保存成功: tabelog - Masa1234 (2014-10-01)\n",
      "✅ 保存成功: tabelog - らりらりら～♪ (2013-12-01)\n",
      "✅ 保存成功: tabelog - ちどりこ (2013-11-01)\n",
      "✅ 保存成功: tabelog - あおととろ (2013-09-01)\n",
      "✅ 保存成功: tabelog - にのみや なな (2013-07-01)\n",
      "✅ 保存成功: tabelog - 裸あざらし (2013-07-01)\n",
      "✅ 保存成功: tabelog - キッシュが食べたい (2013-05-01)\n",
      "✅ 保存成功: tabelog - みのぽんぽん (2013-02-01)\n",
      "✅ 保存成功: tabelog - なみか8 (2013-02-01)\n",
      "✅ 保存成功: tabelog - choichan (2012-12-01)\n",
      "✅ 保存成功: tabelog - ☆★。女子大生ミホ。★☆ (2012-10-01)\n",
      "✅ 保存成功: tabelog - tamako2011 (2012-10-01)\n",
      "✅ 保存成功: tabelog - わんわんきんた (2012-03-01)\n",
      "✅ 保存成功: tabelog - TM273 (2012-03-01)\n",
      "✅ 保存成功: tabelog - popococoa (2012-02-01)\n",
      "✅ 保存成功: tabelog - ReaL K (2011-11-01)\n",
      "✅ 保存成功: tabelog - パインナップル (2011-06-01)\n",
      "✅ 保存成功: tabelog - Honey Roasted (2011-02-01)\n",
      "✅ 保存成功: tabelog - ヤスキチ (2010-05-01)\n",
      "✅ 保存成功: tabelog - ☆チャコ☆ (2009-11-01)\n",
      "✅ 保存成功: tabelog - しずる63 (2009-09-01)\n",
      "✅ 保存成功: tabelog - みんぐ (2009-08-01)\n",
      "✅ 保存成功: tabelog - 湘南のりょう (2009-03-01)\n",
      "✅ 保存成功: tabelog - 腹へったゾウ (2009-02-01)\n",
      "✅ 保存成功: tabelog - てるちきん (2008-10-01)\n",
      "✅ 保存成功: tabelog - むーしゃん (2008-06-01)\n",
      "✅ 保存成功: tabelog - adaya (2007-12-01)\n",
      "✅ 保存成功: tabelog - kenji04152004 (2007-10-01)\n",
      "✅ 保存成功: tabelog - Sana125034 (None)\n",
      "✅ 保存成功: tabelog - pigmo932 (2014-05-01)\n",
      "✅ 保存成功: tabelog - きったんじん (None)\n",
      "✅ 保存成功: tabelog - mokariace (2025-05-01)\n",
      "✅ 保存成功: tabelog - motoyukin (2021-05-01)\n",
      "✅ 保存成功: tabelog - yamaccceee (2016-05-01)\n",
      "✅ 保存成功: tabelog - (๑･̑◡･̑๑)(๑･̑◡･̑๑) (2020-11-01)\n",
      "✅ 保存成功: tabelog - mp_y8 (None)\n",
      "✅ 保存成功: hotpepper - まるんさん (None)\n",
      "✅ 保存成功: hotpepper - Takuさん (None)\n",
      "✅ 保存成功: hotpepper - Takuさん (None)\n",
      "✅ 保存成功: hotpepper - Takuさん (None)\n",
      "✅ 保存成功: hotpepper - Takuさん (None)\n",
      "✅ 保存成功: hotpepper - Takuさん (None)\n",
      "✅ 保存成功: hotpepper - あこママさん (None)\n",
      "✅ 保存成功: retty - Kumiko  Taoka (2024-09-17)\n",
      "✅ 保存成功: retty - ume のりじ (2024-07-27)\n",
      "✅ 保存成功: retty - sachi.o (2023-05-16)\n",
      "✅ 保存成功: retty - kyoko.k (2023-02-06)\n",
      "✅ 保存成功: retty - K-eiko.w (2022-09-03)\n",
      "✅ 保存成功: retty - m.Yoshida (2022-04-25)\n",
      "✅ 保存成功: retty - T.Okazaki (2021-12-20)\n",
      "✅ 保存成功: retty - K.Kenei (2021-11-26)\n",
      "✅ 保存成功: retty - K.Kenei (2021-11-18)\n",
      "✅ 保存成功: retty - Ayaka.T (2021-10-07)\n",
      "✅ 保存成功: retty - N.りな (2021-08-17)\n",
      "✅ 保存成功: retty - Yukiko Hirota (2020-12-27)\n",
      "✅ 保存成功: retty - KYOKO.N (2020-11-19)\n",
      "✅ 保存成功: retty - Michiomi Kanematsu (2020-10-17)\n",
      "✅ 保存成功: retty - Mao Sumita (2020-07-11)\n",
      "✅ 保存成功: retty - konishi kanta (2020-01-08)\n",
      "✅ 保存成功: retty - yumi inoue (2019-12-06)\n",
      "✅ 保存成功: retty - 小林　みつよし (2019-11-23)\n",
      "✅ 保存成功: retty - Ｎ.Terada (2019-11-11)\n",
      "✅ 保存成功: retty - 小島友香 (2019-08-30)\n",
      "📦 Supabaseに新規レビューを 411 件保存しました。\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pytz # タイムゾーン対応のため\n",
    "\n",
    "# --- 環境設定 ---\n",
    "# Supabase URLとAPIキー。セキュリティのため、本番環境では環境変数を使用することを強く推奨します。\n",
    "SUPABASE_URL = \"https://oahnmyfalnhdkoihrswh.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9haG5teWZhbG5oZGtvaWhyc3doIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0NDIzNzE0MiwiZXhwIjoyMDU5ODEzMTQyfQ.yPx_tsCwoLmTZ3qRBIdifYfBBxLaElsaVR55P0lWQec\"\n",
    "SUPABASE_TABLE_NAME = \"parking_cafe_reunion_arashiyama_saganoyu\" # レビューを保存するSupabaseテーブル名\n",
    "STORE_ID = \"嵯峨野湯\" # 対象店舗のID\n",
    "\n",
    "# Supabase APIリクエスト用の共通ヘッダー\n",
    "HEADERS = {\n",
    "    \"apikey\": SUPABASE_API_KEY,\n",
    "    \"Authorization\": f\"Bearer {SUPABASE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- 補助関数 ---\n",
    "\n",
    "# 現在時刻をJSTのISO形式で取得 (inserted_at用)\n",
    "def jst_now():\n",
    "    return datetime.now(pytz.timezone(\"Asia/Tokyo\")).isoformat()\n",
    "\n",
    "# テキストを安全にfloatに変換。変換できない場合はNoneを返す\n",
    "def safe_float(text):\n",
    "    try:\n",
    "        # 空文字列、ハイフン、全角ハイフンはNoneに\n",
    "        return float(text) if text not in [\"\", \"-\", \"ー\"] else None\n",
    "    except (ValueError, TypeError):\n",
    "        # 変換できない場合はNone\n",
    "        return None\n",
    "\n",
    "# レビューの一意なキーを生成 (SHA256ハッシュ)\n",
    "# レビューテキストの冒頭50文字を使用し、スペースなどを除去してハッシュの安定性を高める\n",
    "def safe_generate_unique_key(channel, store_id, visit_date, name, review_text):\n",
    "    cleaned_review = re.sub(r\"\\s+\", \"\", (review_text or \"\").strip().lower())[:50]\n",
    "    cleaned_name = (name or \"\").strip().lower()\n",
    "    cleaned_date = (visit_date or \"\").strip() # visit_dateがNoneの場合に空文字列になるように\n",
    "    \n",
    "    base = f\"{channel}_{store_id}_{cleaned_date}_{cleaned_name}_{cleaned_review}\"\n",
    "    return hashlib.sha256(base.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# --- WebDriver設定 ---\n",
    "\n",
    "# WebDriverの初期設定（ヘッドレスモード、自動制御回避など）\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\") # 最新のヘッドレスモードを使用\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\") # 自動制御を検知させないようにする\n",
    "    options.add_argument(\"--no-sandbox\") # DockerやCI/CD環境で必要になる場合がある\n",
    "    options.add_argument(\"--disable-dev-shm-usage\") # DockerやCI/CD環境で必要になる場合がある\n",
    "    options.add_argument(\"--window-size=1920,1080\") # ウィンドウサイズを設定\n",
    "    options.add_argument(\"--incognito\") # シークレットモードで起動\n",
    "    \n",
    "    # WebDriverManagerでChromeDriverを自動ダウンロード・設定\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# --- Supabase 関連関数 ---\n",
    "\n",
    "# 既存のunique_keyをSupabaseから一括取得し、セットで返す\n",
    "def fetch_existing_unique_keys():\n",
    "    print(\"🔄 Supabaseから既存のunique_keyを取得中...\")\n",
    "    response = requests.get(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}?select=unique_key\", headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        existing_keys = {x[\"unique_key\"] for x in response.json()}\n",
    "        print(f\"✅ 既存のunique_keyを {len(existing_keys)} 件取得しました。\")\n",
    "        return existing_keys\n",
    "    else:\n",
    "        print(f\"❌ 既存キー取得エラー: {response.status_code} - {response.text}\")\n",
    "        return set() # エラー時は空のセットを返す\n",
    "\n",
    "# レビューデータをSupabaseに挿入（重複チェック付き）\n",
    "def insert_reviews_to_supabase(reviews_data, existing_keys_set):\n",
    "    inserted_count = 0\n",
    "    if not reviews_data:\n",
    "        print(\"💡 挿入するレビューデータがありません。\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"☁️ Supabaseにレビューデータを挿入中（合計 {len(reviews_data)} 件）...\")\n",
    "    for r in reviews_data:\n",
    "        unique_key = r.get('unique_key')\n",
    "        if not unique_key:\n",
    "            print(f\"⚠️ unique_keyがありません。スキップします: {r.get('name', 'N/A')}\")\n",
    "            continue\n",
    "\n",
    "        # 既存のキーセットに含まれていればスキップ\n",
    "        if unique_key in existing_keys_set:\n",
    "            # print(f\"⚠️ 重複スキップ: {unique_key} - {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.post(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}\", headers=HEADERS, json=r)\n",
    "            if response.status_code in [200, 201]:\n",
    "                inserted_count += 1\n",
    "                existing_keys_set.add(unique_key) # 新しく挿入されたキーをメモリ上のセットに追加\n",
    "                print(f\"✅ 保存成功: {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            else:\n",
    "                print(f\"❌ Supabase POSTエラー: {response.status_code} - {response.text} - データunique_key: {unique_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 保存エラー: {e} - データunique_key: {unique_key}\")\n",
    "    print(f\"📦 Supabaseに新規レビューを {inserted_count} 件保存しました。\")\n",
    "    return inserted_count\n",
    "\n",
    "# --- Google Maps スクレイピング関数 ---\n",
    "\n",
    "# Google Mapsのクチコミタブをクリック\n",
    "def click_google_review_tab(driver):\n",
    "    try:\n",
    "        review_tab = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label,\"クチコミ\")]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", review_tab) # JavaScriptでクリックを試みる\n",
    "        time.sleep(2) # クリック後の待機時間を長くする\n",
    "        print(\"✅ Google Maps クチコミタブをクリック完了\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps クチコミタブクリック失敗: {e}\")\n",
    "\n",
    "# Google Mapsのレビューを「新しい順」で並び替え\n",
    "def click_google_sort_by_new(driver):\n",
    "    try:\n",
    "        # 「並べ替え」ボタンのXPathをより具体的に\n",
    "        sort_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[.//span[text()=\"並べ替え\"]]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", sort_button)\n",
    "        time.sleep(1) # クリック後の待機\n",
    "\n",
    "        # 「新しい順」をクリックするためのJavaScript\n",
    "        script = '''\n",
    "            const elements = Array.from(document.querySelectorAll('div[role=\"menuitem\"]'));\n",
    "            const target = elements.find(el => el.textContent.trim() === '新しい順');\n",
    "            if (target) { target.click(); return 'clicked'; } else { return 'not found'; }\n",
    "        '''\n",
    "        result = driver.execute_script(script)\n",
    "        print(f\"🧭 Google Maps 並び替え『新しい順』クリック結果: {result}\")\n",
    "        time.sleep(2) # 並び替え適用後の待機時間を長くする\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps 並び替えクリック失敗: {e}\")\n",
    "\n",
    "# Google Mapsのスクロール可能なレビューエリアを見つける\n",
    "def find_google_scrollable_area(driver):\n",
    "    print(\"🔎 Google Maps スクロール対象を探索中...\")\n",
    "    try:\n",
    "        # レビューブロックの最初の要素が存在するまで待機し、その祖先要素からスクロール可能な領域を探す\n",
    "        scrollable_div = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-review-id]:first-of-type'))\n",
    "        ).find_element(By.XPATH, './ancestor::div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]')\n",
    "        print(\"✅ Google Maps スクロール対象のレビューセクションを発見\")\n",
    "        return scrollable_div\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps スクロール対象が見つかりませんでした: {e}\")\n",
    "        return None\n",
    "\n",
    "# Google Mapsのレビューを指定件数または最後までスクロール\n",
    "def scroll_google_reviews(driver, scrollable_div, target_reviews=200, max_scrolls=200, patience_scrolls=10):\n",
    "    prev_count = 0\n",
    "    same_count_times = 0\n",
    "    print(f\"↘️ Google Maps レビューをスクロール中 (目標: {target_reviews}件)...\")\n",
    "    for i in range(max_scrolls):\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", scrollable_div)\n",
    "        time.sleep(0.5) # 短めの待機\n",
    "        reviews = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "        curr_count = len(reviews)\n",
    "        # print(f\"   スクロール {i+1}回目：現在のレビュー数 = {curr_count}\") # デバッグ用\n",
    "\n",
    "        if curr_count >= target_reviews:\n",
    "            print(f\"✅ Google Maps {target_reviews}件のレビューに到達 → スクロール終了\")\n",
    "            break\n",
    "        if curr_count == prev_count:\n",
    "            same_count_times += 1\n",
    "            if same_count_times >= patience_scrolls:\n",
    "                print(f\"⚠️ Google Maps {patience_scrolls}回連続でレビュー数増加なし → スクロール中断\")\n",
    "                break\n",
    "        else:\n",
    "            same_count_times = 0\n",
    "            prev_count = curr_count\n",
    "    \n",
    "    # 全ての「もっと見る」ボタンをクリックして全文を表示\n",
    "    try:\n",
    "        expand_buttons = driver.find_elements(By.CSS_SELECTOR, 'button.w8nwRe')\n",
    "        print(f\"👁️‍🗨️ Google Maps 『もっと見る』ボタン {len(expand_buttons)} 個を検出、クリック中...\")\n",
    "        for btn in expand_buttons:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                # time.sleep(0.05) # 短い待機で負荷を減らす\n",
    "            except Exception as e:\n",
    "                pass # 大量に出力される可能性があるのでエラーメッセージは表示しない\n",
    "        print(\"✅ Google Maps 『もっと見る』ボタンクリック完了\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google Maps 『もっと見る』ボタンクリック処理失敗: {e}\")\n",
    "\n",
    "# Google Mapsからレビュー情報を抽出\n",
    "def extract_google_reviews(driver):\n",
    "    ref_date = datetime.now()  # 基準日（現在日時）\n",
    "    reviews = []\n",
    "\n",
    "    # 完全に展開されたレビューブロックを取得\n",
    "    blocks = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "    print(f\"⚙️ Google Maps ページから {len(blocks)} 件のレビューブロックを抽出中...\")\n",
    "\n",
    "    for block in blocks:\n",
    "        unique_key = block.get_attribute(\"data-review-id\")\n",
    "        if not unique_key:\n",
    "            continue  # IDがないレビューはスキップ\n",
    "\n",
    "        soup = BeautifulSoup(block.get_attribute(\"innerHTML\"), \"html.parser\")\n",
    "\n",
    "        review_text_elem = soup.select_one('.MyEned span.wiI7pd')\n",
    "        review_text = review_text_elem.text.strip() if review_text_elem else \"\"\n",
    "        if not review_text:\n",
    "            continue  # 本文なしはスキップ\n",
    "\n",
    "        # 投稿日（相対表現 or 絶対表現）\n",
    "        visit_date = None\n",
    "        visit_month = None\n",
    "        try:\n",
    "            rating_block = soup.select_one(\"div.DU9Pgb\")\n",
    "            if rating_block:\n",
    "                publish_span = rating_block.select_one(\"span.rsqaWe\")\n",
    "                if publish_span:\n",
    "                    txt = publish_span.get_text(strip=True)\n",
    "                    visit_datetime = None\n",
    "\n",
    "                    if \"時間前\" in txt:\n",
    "                        hours = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(hours=hours)\n",
    "                    elif \"日前\" in txt:\n",
    "                        days = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=days)\n",
    "                    elif \"週間前\" in txt:\n",
    "                        weeks = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(weeks=weeks * 7)\n",
    "                    elif \"か月前\" in txt:\n",
    "                        months = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=30 * months)\n",
    "                    elif \"年前\" in txt:\n",
    "                        years = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=365 * years)\n",
    "                    elif re.match(r\"^\\d{4}年\\d{1,2}月\\d{1,2}日$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Y年%m月%d日\")\n",
    "                    elif re.match(r\"^\\d{4}年\\d{1,2}月$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Y年%m月\")\n",
    "\n",
    "                    if visit_datetime:\n",
    "                        visit_date = visit_datetime.date().isoformat()\n",
    "                        visit_month = visit_datetime.replace(day=1).date().isoformat()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Google Maps visit_date 抽出エラー: {e} (元のテキスト: {txt if 'txt' in locals() else 'N/A'})\")\n",
    "\n",
    "        # 総合スコア\n",
    "        total_score = None\n",
    "        score_elem = soup.select_one('span.kvMYJc[aria-label]')\n",
    "        if score_elem and \"つ星\" in score_elem.get(\"aria-label\", \"\"):\n",
    "            match = re.search(r\"(\\d+) つ星\", score_elem['aria-label'])\n",
    "            if match:\n",
    "                total_score = int(match.group(1))\n",
    "\n",
    "        # サブスコア抽出ヘルパー\n",
    "        def extract_google_sub_score(label):\n",
    "            score = None\n",
    "            score_blocks = soup.select(\"div.PBK6be span.RfDO5c\")\n",
    "            for block in score_blocks:\n",
    "                bold = block.find(\"b\")\n",
    "                if bold and label in bold.text:\n",
    "                    text = block.get_text(strip=True)\n",
    "                    match = re.search(rf\"{label}:\\s*(\\d+)\", text)\n",
    "                    if match:\n",
    "                        score = int(match.group(1))\n",
    "                        break\n",
    "            return score\n",
    "\n",
    "        food_score = extract_google_sub_score(\"食事\")\n",
    "        service_score = extract_google_sub_score(\"サービス\")\n",
    "        atmosphere_score = extract_google_sub_score(\"雰囲気\")\n",
    "\n",
    "        lunch = \"ランチ\" in review_text\n",
    "        dinner = \"ディナー\" in review_text\n",
    "\n",
    "        price_range = None\n",
    "        price_elem = soup.find(\"span\", attrs={\"aria-label\": re.compile(r\"￥\")})\n",
    "        if price_elem:\n",
    "            price_range = price_elem['aria-label']\n",
    "\n",
    "        user_button = soup.select_one('button[aria-label*=\"さんのクチコミ\"]')\n",
    "        user_name = user_button['aria-label'].split('さん')[0] if user_button else \"\"\n",
    "        a_tag = soup.select_one('a')\n",
    "        user_url = \"https://www.google.com\" + a_tag['href'] if a_tag else \"\"\n",
    "\n",
    "        reviews.append({\n",
    "            \"store_id\": STORE_ID,\n",
    "            \"channel\": \"googlemaps\",\n",
    "            \"unique_key\": unique_key,\n",
    "            \"review\": review_text,\n",
    "            \"visit_date\": visit_date,\n",
    "            \"visit_month\": visit_month,\n",
    "            \"name\": user_name,\n",
    "            \"user_url\": user_url,\n",
    "            \"total_score\": total_score,\n",
    "            \"food_score\": food_score,\n",
    "            \"service_score\": service_score,\n",
    "            \"atmosphere_score\": atmosphere_score,\n",
    "            \"lunch\": lunch,\n",
    "            \"dinner\": dinner,\n",
    "            \"price_range\": price_range,\n",
    "            \"inserted_at\": jst_now()\n",
    "        })\n",
    "\n",
    "    print(f\"📦 Google Mapsから {len(reviews)} 件のレビューを抽出完了\")\n",
    "    return reviews\n",
    "\n",
    "\n",
    "# ============ 食べログ スクレイピング関数 ============\n",
    "\n",
    "def scrape_tabelog(url, store_id, driver):\n",
    "    print(f\"\\n=== Tabelog ({url})からレビュー取得開始 ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    reviews_data = []\n",
    "    \n",
    "    while True:\n",
    "        items = driver.find_elements(By.CSS_SELECTOR, \"div.rvw-item\")\n",
    "        if not items:\n",
    "            print(\"➡️ Tabelog レビューアイテムが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "\n",
    "        for idx, e in enumerate(items):\n",
    "            try:\n",
    "                # 「もっと見る」ボタンをクリック (アコーディオン、全文表示)\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"button.js-c-accordion-trigger\").click(); time.sleep(0.2)\n",
    "                except: pass\n",
    "                try: e.find_element(By.CSS_SELECTOR, \".rvw-showall-trigger\").click(); time.sleep(0.2)\n",
    "                except: pass\n",
    "\n",
    "                review_text = None\n",
    "                try: review_text = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__rvw-comment--custom p\").text.strip()\n",
    "                except:\n",
    "                    try: review_text = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__rvw-comment p\").text.strip()\n",
    "                    except: pass # レビュー本文がなければNoneのまま\n",
    "\n",
    "                if not review_text: # レビュー本文が空の場合はスキップ\n",
    "                    continue\n",
    "\n",
    "                name_elem = e.find_element(By.CSS_SELECTOR, \".rvw-item__rvwr-name\")\n",
    "                name = name_elem.text.strip() if name_elem else None\n",
    "                user_url_elem = e.find_element(By.CSS_SELECTOR, \".rvw-item__rvwr-info-left a\")\n",
    "                user_url = user_url_elem.get_attribute(\"href\") if user_url_elem else None\n",
    "\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                try:\n",
    "                    date_elem = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__date span\")\n",
    "                    date_text = date_elem.text.strip().split(\"訪問\")[0].strip()\n",
    "                    # YYYY/MM/DD または YYYY/MM 形式に対応\n",
    "                    if re.match(r\"^\\d{4}/\\d{1,2}/\\d{1,2}$\", date_text):\n",
    "                        dt_obj = datetime.strptime(date_text, \"%Y/%m/%d\")\n",
    "                        visit_date = dt_obj.date().isoformat()\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                    elif re.match(r\"^\\d{4}/\\d{1,2}$\", date_text):\n",
    "                        dt_obj = datetime.strptime(date_text, \"%Y/%m\")\n",
    "                        visit_date = dt_obj.replace(day=1).date().isoformat() # 日付は月初\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                except Exception:\n",
    "                    pass # 日付抽出エラーは無視\n",
    "\n",
    "                total_score = None\n",
    "                try: total_score = safe_float(e.find_element(By.CSS_SELECTOR, \"b.c-rating-v3__val\").text)\n",
    "                except: pass\n",
    "\n",
    "                food_score = service_score = atmosphere_score = None\n",
    "                for li in e.find_elements(By.CSS_SELECTOR, \"ul.c-rating-detail li\"):\n",
    "                    try:\n",
    "                        label_elem = li.find_element(By.TAG_NAME, \"span\")\n",
    "                        val_elem = li.find_element(By.TAG_NAME, \"strong\")\n",
    "                        if label_elem and val_elem:\n",
    "                            label = label_elem.text.strip()\n",
    "                            val = safe_float(val_elem.text)\n",
    "                            if \"料理\" in label: food_score = val\n",
    "                            elif \"サービス\" in label: service_score = val\n",
    "                            elif \"雰囲気\" in label: atmosphere_score = val\n",
    "                    except: pass\n",
    "\n",
    "                lunch = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"i.c-rating-v3__time--lunch\"); lunch = True\n",
    "                except: pass\n",
    "                dinner = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"i.c-rating-v3__time--dinner\"); dinner = True\n",
    "                except: pass\n",
    "\n",
    "                price_range = None\n",
    "                try:\n",
    "                    price_range_elem = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__payment-amount span\")\n",
    "                    price_range_text = price_range_elem.text.strip()\n",
    "                    if price_range_text not in [\"－\", \"-\"]: price_range = price_range_text\n",
    "                except: pass\n",
    "\n",
    "                key = safe_generate_unique_key(\"tabelog\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "                \n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"tabelog\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': total_score, 'food_score': food_score, 'service_score': service_score,\n",
    "                    'atmosphere_score': atmosphere_score, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': price_range, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Tabelog 抽出失敗 (要素 {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"a.c-pagination__arrow--next[rel='next']\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"➡️ Tabelog 次ページボタンが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "    print(f\"📦 Tabelogから {len(reviews_data)} 件のレビューを抽出完了\")\n",
    "    return reviews_data\n",
    "\n",
    "# ============ Hotpepper スクレイピング関数 ============\n",
    "\n",
    "def scrape_hotpepper(url, store_id, driver):\n",
    "    print(f\"\\n=== Hotpepper ({url})からレビュー取得開始 ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    reviews_data = []\n",
    "\n",
    "    while True:\n",
    "        items = driver.find_elements(By.CSS_SELECTOR, \"div.reportCassette\")\n",
    "        if not items:\n",
    "            print(\"➡️ Hotpepper レビューアイテムが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "\n",
    "        for idx, e in enumerate(items):\n",
    "            try:\n",
    "                review_text_elem = e.find_element(By.CSS_SELECTOR, \"div.reportText span.text\")\n",
    "                review_text = review_text_elem.text.strip() if review_text_elem else None\n",
    "\n",
    "                if not review_text: # レビュー本文が空の場合はスキップ\n",
    "                    continue\n",
    "\n",
    "                name = None\n",
    "                try: name = e.find_element(By.CSS_SELECTOR, \"p.name\").text.strip()\n",
    "                except: pass\n",
    "\n",
    "                user_url = None # HotpepperにはユーザーURLがないことが多い\n",
    "\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                try:\n",
    "                    info_elem = e.find_element(By.CSS_SELECTOR, \"p.individualInfo\")\n",
    "                    info = info_elem.text if info_elem else \"\"\n",
    "                    if \"来店日：\" in info:\n",
    "                        visit_str = info.split(\"来店日：\")[-1].strip()\n",
    "                        # YYYY/MM/DD または YYYY/MM 形式に対応\n",
    "                        if re.match(r\"^\\d{4}/\\d{1,2}/\\d{1,2}$\", visit_str):\n",
    "                            dt_obj = datetime.strptime(visit_str, \"%Y/%m/%d\")\n",
    "                            visit_date = dt_obj.date().isoformat()\n",
    "                            visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                        elif re.match(r\"^\\d{4}/\\d{1,2}$\", visit_str):\n",
    "                            dt_obj = datetime.strptime(visit_str, \"%Y/%m\")\n",
    "                            visit_date = dt_obj.replace(day=1).date().isoformat() # 日付は月初\n",
    "                            visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                except Exception:\n",
    "                    pass # 日付抽出エラーは無視\n",
    "\n",
    "                lunch = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"div.visitStatusWrap div.icnLunch\"); lunch = True\n",
    "                except: pass\n",
    "                dinner = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"div.visitStatusWrap div.icnDinner\"); dinner = True\n",
    "                except: pass\n",
    "\n",
    "                key = safe_generate_unique_key(\"hotpepper\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "\n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"hotpepper\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': None, 'food_score': None, 'service_score': None,\n",
    "                    'atmosphere_score': None, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': None, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Hotpepper 抽出失敗 (要素 {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"ul.pagePrevAndNextBtn li.lastChild a\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"➡️ Hotpepper 次ページボタンが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "    print(f\"📦 Hotpepperから {len(reviews_data)} 件のレビューを抽出完了\")\n",
    "    return reviews_data\n",
    "\n",
    "# ============ Retty スクレイピング関数 ============\n",
    "\n",
    "def scrape_retty(url, store_id, driver):\n",
    "    print(f\"\\n=== Retty ({url})からレビュー取得開始 ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    reviews_data = []\n",
    "\n",
    "    while True:\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        items = soup.select(\"article.restaurant-report\")\n",
    "        if not items:\n",
    "            print(\"➡️ Retty レビューアイテムが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "\n",
    "        for idx, item in enumerate(items):\n",
    "            try:\n",
    "                name_tag = item.select_one(\".report-user__name\")\n",
    "                name = name_tag.text.strip() if name_tag else None\n",
    "\n",
    "                user_url_tag = item.select_one(\"a.report-user\")\n",
    "                user_url = user_url_tag[\"href\"] if user_url_tag else None\n",
    "\n",
    "                time_tag = item.select_one(\"div.restaurant-report__date time\")\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                if time_tag and \"datetime\" in time_tag.attrs:\n",
    "                    dt_str = time_tag[\"datetime\"][:10] # YYYY-MM-DD 形式\n",
    "                    try:\n",
    "                        dt_obj = datetime.strptime(dt_str, \"%Y-%m-%d\")\n",
    "                        visit_date = dt_obj.date().isoformat()\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                    except ValueError:\n",
    "                        pass # 日付パースエラーは無視\n",
    "\n",
    "                lunch = \"restaurant-report__hours-icon--lunch\" in str(item)\n",
    "                dinner = \"restaurant-report__hours-icon--dinner\" in str(item)\n",
    "\n",
    "                review_elem = item.select_one(\"p.restaurant-report__text\")\n",
    "                review_text = review_elem.text.strip() if review_elem else None\n",
    "                \n",
    "                if not review_text: # レビュー本文が空の場合はスキップ\n",
    "                    continue\n",
    "                    \n",
    "                key = safe_generate_unique_key(\"retty\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "\n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"retty\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': None, 'food_score': None, 'service_score': None,\n",
    "                    'atmosphere_score': None, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': None, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Retty 抽出失敗 (要素 {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"a.pagination__next\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"➡️ Retty 次ページボタンが見つかりませんでした。スクレイピング終了。\")\n",
    "            break\n",
    "    print(f\"📦 Rettyから {len(reviews_data)} 件のレビューを抽出完了\")\n",
    "    return reviews_data\n",
    "\n",
    "\n",
    "# ============ メイン処理 ============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 各サイトのURLを設定\n",
    "    # Google Maps URLは、直接Google Mapsの店舗ページURLを使用してください\n",
    "    # 例: \"https://www.google.com/maps/place/店舗名/@緯度,経度,ズームレベルz/data=!3m1!4b1!4m8!3m7!1s...\"\n",
    "    # レビュータブが自動で開くURLは、末尾に /reviews を追加すると良い場合があります。\n",
    "    google_maps_url = \"https://www.google.com/maps/place/嵯峨野湯/@35.0170032,135.6813273,16z/data=!4m8!3m7!1s0x6001a9fdde5aa3d3:0xe6f6389a9a6f8382!8m2!3d35.0170032!4d135.6813273!9m1!1b1!16s%2Fg%2F1w0h7f18?entry=ttu&g_ep=EgoyMDI1MDUyMS4wIKXMDSoJLDEwMjExNDU1SAFQAw%3D%3D\"\n",
    "    tabelog_url = \"https://tabelog.com/kyoto/A2601/A260403/26005250/dtlrvwlst/\"\n",
    "    hotpepper_url = \"https://www.hotpepper.jp/strJ000728780/report/\"\n",
    "    retty_url = \"https://retty.me/area/PRE26/ARE114/SUB11401/100000025475/reports/\"\n",
    "\n",
    "    driver = None # driverを初期化\n",
    "    all_reviews = [] # 全サイトから取得したレビューを格納するリスト\n",
    "\n",
    "    try:\n",
    "        driver = setup_driver() # WebDriverを一度だけ初期化\n",
    "\n",
    "        # 既存のunique_keyをSupabaseから一度だけ取得\n",
    "        existing_unique_keys = fetch_existing_unique_keys()\n",
    "\n",
    "        # --- 各サイトからのレビュー取得と結合 ---\n",
    "\n",
    "        # Google Maps\n",
    "        print(\"\\n=== Google Maps レビュー取得開始 ===\")\n",
    "        driver.get(google_maps_url)\n",
    "        time.sleep(5) # ページが完全にロードされるのを待つ\n",
    "        click_google_review_tab(driver)\n",
    "        click_google_sort_by_new(driver)\n",
    "        scroll_target = find_google_scrollable_area(driver)\n",
    "        if scroll_target:\n",
    "            scroll_google_reviews(driver, scroll_target, target_reviews=200, max_scrolls=200) # より多くのレビューを試みる\n",
    "            google_reviews = extract_google_reviews(driver)\n",
    "            all_reviews.extend(google_reviews)\n",
    "        else:\n",
    "            print(\"❌ Google Maps レビューエリアが見つからなかったため、スキップします。\")\n",
    "        print(\"=== Google Maps レビュー取得完了 ===\\n\")\n",
    "\n",
    "        # Tabelog\n",
    "        tabelog_reviews = scrape_tabelog(tabelog_url, STORE_ID, driver)\n",
    "        all_reviews.extend(tabelog_reviews)\n",
    "\n",
    "        # Hotpepper\n",
    "        hotpepper_reviews = scrape_hotpepper(hotpepper_url, STORE_ID, driver)\n",
    "        all_reviews.extend(hotpepper_reviews)\n",
    "\n",
    "        # Retty\n",
    "        retty_reviews = scrape_retty(retty_url, STORE_ID, driver)\n",
    "        all_reviews.extend(retty_reviews)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"致命的なエラーが発生しました: {e}\")\n",
    "    finally:\n",
    "        if driver: # driverがNoneでないことを確認してから終了\n",
    "            driver.quit() # 全ての処理が終わったらWebDriverを閉じる\n",
    "\n",
    "    print(f\"\\n--- 全サイト合計取得レビュー数: {len(all_reviews)} ---\\n\")\n",
    "\n",
    "    # --- 取得した全てのレビューをSupabaseに挿入 ---\n",
    "    if all_reviews:\n",
    "        insert_reviews_to_supabase(all_reviews, existing_unique_keys)\n",
    "    else:\n",
    "        print(\"取得したレビューがありませんでした。Supabaseへの挿入はスキップされます。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8216d0-d727-4b28-bd18-3709e5c1d804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
