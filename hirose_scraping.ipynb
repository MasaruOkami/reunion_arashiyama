{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536d3226-d7a2-48e1-9f94-0f0c966270f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Supabaseã‹ã‚‰æ—¢å­˜ã®unique_keyã‚’å–å¾—ä¸­...\n",
      "âœ… æ—¢å­˜ã®unique_keyã‚’ 287 ä»¶å–å¾—ã—ã¾ã—ãŸã€‚\n",
      "\n",
      "=== Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–‹å§‹ ===\n",
      "âœ… Google Maps ã‚¯ãƒã‚³ãƒŸã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯å®Œäº†\n",
      "ğŸ§­ Google Maps ä¸¦ã³æ›¿ãˆã€æ–°ã—ã„é †ã€ã‚¯ãƒªãƒƒã‚¯çµæœ: not found\n",
      "ğŸ” Google Maps ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã‚’æ¢ç´¢ä¸­...\n",
      "âœ… Google Maps ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç™ºè¦‹\n",
      "â†˜ï¸ Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­ (ç›®æ¨™: 200ä»¶)...\n",
      "âœ… Google Maps 200ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«åˆ°é” â†’ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«çµ‚äº†\n",
      "ğŸ‘ï¸â€ğŸ—¨ï¸ Google Maps ã€ã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ 122 å€‹ã‚’æ¤œå‡ºã€ã‚¯ãƒªãƒƒã‚¯ä¸­...\n",
      "âœ… Google Maps ã€ã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å®Œäº†\n",
      "âš™ï¸ Google Maps ãƒšãƒ¼ã‚¸ã‹ã‚‰ 208 ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºä¸­...\n",
      "ğŸ“¦ Google Mapsã‹ã‚‰ 203 ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºå®Œäº†\n",
      "=== Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—å®Œäº† ===\n",
      "\n",
      "\n",
      "=== Tabelog (https://tabelog.com/kyoto/A2601/A260403/26001303/dtlrvwlst/)ã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–‹å§‹ ===\n",
      "â¡ï¸ Tabelog æ¬¡ãƒšãƒ¼ã‚¸ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ‚äº†ã€‚\n",
      "ğŸ“¦ Tabelogã‹ã‚‰ 20 ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºå®Œäº†\n",
      "\n",
      "=== Retty (https://retty.me/area/PRE26/ARE114/SUB11401/100000295754/reports/)ã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–‹å§‹ ===\n",
      "â¡ï¸ Retty æ¬¡ãƒšãƒ¼ã‚¸ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ‚äº†ã€‚\n",
      "ğŸ“¦ Rettyã‹ã‚‰ 2 ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºå®Œäº†\n",
      "\n",
      "--- å…¨ã‚µã‚¤ãƒˆåˆè¨ˆå–å¾—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: 225 ---\n",
      "\n",
      "â˜ï¸ Supabaseã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ä¸­ï¼ˆåˆè¨ˆ 225 ä»¶ï¼‰...\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã‚±ã‚¤ã‚†ã†ã™ã‘  (2025-02-26)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã¨ã†ãµã¡ã‚ƒã‚“  (2024-09-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Sasaki george  (2025-04-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - å¤©é‡ä¸€  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Shiho Horie (ç´«)  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ãºã‚‹ã—ã‚ƒã­ã“  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - TAKASHI OKUNO  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - rin rin  (2024-07-31)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - mitsutaka minami  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ä¸ƒé¢é³¥æ”¾æµªè¨˜  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã­ã“  (2022-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - å…ƒæ¾  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã‚¤ã‚±ãƒ€â€œã­ã“ã¨ (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - babs  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ä¸­æ´¥ä½³ä¹‹  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Jun Sakai  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã«ã¨ã†ã¸ã„  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ãã‚ˆ (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - å®‰è—¤ã„ã¥ã¿  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã™ã‘  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ãªãƒ¼ãŠãŠ  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Yu mi  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã‚„ã¾ã‹ã‚  (2021-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Keai ymd  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ãŸã‹ã—ã‚ªãƒ‡ãƒƒã‚»ã‚¤  (2021-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - K H  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Yeh Annie  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - åœ’ç”°å“²éƒ  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - tominger official  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ãƒ¬ãƒƒã‚µãƒ¼é¢¨å¤ª  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - å‰ç”°ç¾å¥ˆå­  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - koyatama tamago  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - æ¾å°¾æ˜ç¾  (2021-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Daiki Aminaka  (2021-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã¿ã‹ã•  (2022-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - katsumi onitsuka  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ãƒ‘ãƒ¯ãƒ¼ã‚ºâ€œã‚ªãƒ¼ã‚¹ãƒ†ã‚£ãƒ³â€ã‚ªãƒ¼ã‚¹ãƒ†ã‚£ãƒ³  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ãã‚€ã‚‰ã•ã¨ã—  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - å¤§ç²’ã¾ã‚ã‚“  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - N S  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - æ²³é‡å–œæ˜  (2022-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - K K  (2021-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - luna tan (ã‚‚ã¡ã¯ã‚“)  (2021-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - RX78NORIRIN  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - i  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - æµ…ç”°åšä¸€  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - - pon  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - tabi 874  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - toshiaki  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ã‚  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - èŠ±æ‘å‹‡å¤ªæœ—  (2025-05-26)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Er Hauzhi  (2024-12-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Maggie Wang  (2025-02-18)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - å³éœèŠ¬  (2025-04-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Edoardo Toffano  (2024-11-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Gi Pal  (2024-11-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Monica NA  (2025-03-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - nu gu  (2025-01-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Ariane  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Michael Watts  (2024-11-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ì„œí˜œë¦°  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Ts T  (2025-01-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - æ¢å˜‰è±  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Brooks n Jasmine  (2024-07-31)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Philip Wolfe  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Borriraks Rattanawangcharoen (å³å­ç‰™)  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - pauli  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Yanisa Ratanakosit  (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ë°±ì§€ìˆ™  (2025-02-26)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Melissa  (2024-08-30)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Ken Graham  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Chris  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Spencer Kok  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Mike Lee  (2025-04-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Skye Cai  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Vibhu Dhawan  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - MF MF  (2025-02-18)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Min Li  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Shreyamsa Manjunath  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Trisha Pereira  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Alan Tang  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Antonio Cutrona  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - SEO  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - è¨±æ›¸å«š  (2025-01-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Tracey Buskes  (2025-02-26)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ë´‰ë¯¸ì„ ë§ˆìš”  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Wayne See  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - William Huang  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Tom Chien  (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - H Park  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Bob Slob  (2025-04-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Juei-En Su  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Nhi Nguyen  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Yuval Gorchover  (2024-11-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Safa YavuzdoÄŸan  (2024-07-31)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - YNWA LIVE  (2024-09-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Tom Werner  (2025-03-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Rory Mannion  (2024-08-30)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Katie Tung  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Masa Wu  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Stijn Floren  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - èŠè‚²å©·  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - è¨±ç¥ç‘„  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Diogo Santo  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Jihun Kim  (2024-12-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Daniel Kestenholz  (2024-11-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Shaochen T  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Elif Ã‡.  (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Romane Laurent  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Gracey Gowler  (2025-03-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Victor Fernandez  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - krista Elem  (2024-09-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Tina Lam  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Love Wise  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Borja TP  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Shani Cohen Shitrit  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - May Hsia Ng  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Eu  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Sunil Gill  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Sam Wong  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Yiduo Xiao  (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Tim Lo  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Kourtney Elbag  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Alex MC  (2025-04-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - í•œì¬í™  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - K Kang  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - lu an  (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - é™ˆä¸€ä¸€  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Roshan Lakmal  (2024-11-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Shawn Clifford  (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - vivi su  (2017-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - èŒƒåšå‚‘  (2025-01-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Konrad Swierblewski  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Vittoria S  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Aidan Ferguson  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Grace Ding  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Robert Beal  (2014-05-30)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Abbie Baggett  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Iulia Andreea Marcu  (2025-03-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Hee Hee  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - doktorfred  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Amanda McCalla  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ling Yu  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - S Duan  (2024-08-30)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - å¤©ç¾½äº®  (2017-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - dancer huge  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Zula Stricker  (2024-07-31)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ERIN SLAGERMAN  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Yuki  (2024-09-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Allison Lemke  (2017-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Wiam Hanania  (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Carolyn S.  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Giwrrhs theos  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Samantha Taylor  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Danica Mitchell  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Sunkyung Park  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Warren Bitner  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - V  (2024-07-31)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - kristina wulandari  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Fernando BurgÃ©s  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Respina Vaezian  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Kiyono Gray  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Siang Chin Lim  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Kasia Daniec  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Andrew Staheli  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Julia Bowry  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Rafael Alvarez  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Jake Prior  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Rui Shi  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Best Nittayapron  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - N CHIN  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Kurt Jensen  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Lori Lewis  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - å³å¯  (2017-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ë°•ì˜ìˆ˜  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Andrea Lattanzio  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - George Chu  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Justyna S  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Nathan  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Cate Chang  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - jay malby  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Hameed Chughtai  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - ì†êµ­ì§„  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Watcher Sky  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - L  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Natalie  (2024-09-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Yvette Chang  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Lauren Lysko  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - fireytale  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Ginny LU  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Eylem Akyurek  (2024-11-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Water Loco  (2023-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Gabriel Gabe  (2024-10-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Moneer M  (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Matteo Zambon  (2025-02-18)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Chia Keegan  (2018-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Bob BinÃ¤rfeld  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Esteban Beltran  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Kevin Lee  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Victor Inocentes  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Benjamin Ferrara  (2020-05-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - doodoo00166 Liu  (2024-05-27)\n",
      "âœ… ä¿å­˜æˆåŠŸ: googlemaps - Susan E  (2019-05-29)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - Mm39 (2025-02-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - 84d5653082 (2024-11-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - ã‚°ãƒ«ãƒ¡ã‚†ã†ã¡ã‚ƒã‚“ (2024-10-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - ãŸã¡ã“4153 (2024-06-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - äº¬ãã®ã“ (2024-05-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - jboy0927 (2024-05-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - fyama13 (2023-12-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - mashirokun (2020-11-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - ã‚­ãƒ£ãƒ©ãƒ¡ãƒªã‚¼ç¢§ (2019-03-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - opall (2016-12-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - ã‚‚ã—ã‚‚ã—çœ ã„ (2015-11-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - è•¨ã‚‚ã¡ (2015-05-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - ä¸‹ç”ºã‚°ãƒ«ãƒ¡ã®é”ã¡ã‚ƒã‚“ (2014-10-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - nao&ã‚·ã‚¨ãƒ« (2014-01-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - KAãƒãƒ (2011-10-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - ã²ã„ãµã†ã¿ã„ (2009-09-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - å¤§è‡£ã€‚ (2007-04-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - ã„ã­ã‚‹ (2018-11-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - aozora0007 (2017-11-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: tabelog - ãã„ã—ã‚“bouu (2024-07-01)\n",
      "âœ… ä¿å­˜æˆåŠŸ: retty - ã‹ã¤ã‚‰ã—ã‚‡ã† (2019-12-28)\n",
      "âœ… ä¿å­˜æˆåŠŸ: retty - imai s (2017-07-18)\n",
      "ğŸ“¦ Supabaseã«æ–°è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ 225 ä»¶ä¿å­˜ã—ã¾ã—ãŸã€‚\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pytz # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å¯¾å¿œã®ãŸã‚\n",
    "\n",
    "# --- ç’°å¢ƒè¨­å®š ---\n",
    "# Supabase URLã¨APIã‚­ãƒ¼ã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ã€æœ¬ç•ªç’°å¢ƒã§ã¯ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚\n",
    "SUPABASE_URL = \"https://oahnmyfalnhdkoihrswh.supabase.co\"\n",
    "SUPABASE_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9haG5teWZhbG5oZGtvaWhyc3doIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0NDIzNzE0MiwiZXhwIjoyMDU5ODEzMTQyfQ.yPx_tsCwoLmTZ3qRBIdifYfBBxLaElsaVR55P0lWQec\"\n",
    "SUPABASE_TABLE_NAME = \"parking_cafe_reunion_arashiyama_hirose_coffee\" # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä¿å­˜ã™ã‚‹Supabaseãƒ†ãƒ¼ãƒ–ãƒ«å\n",
    "STORE_ID = \"å»£ç€¬çˆç²åº—\" # å¯¾è±¡åº—èˆ—ã®ID\n",
    "\n",
    "# Supabase APIãƒªã‚¯ã‚¨ã‚¹ãƒˆç”¨ã®å…±é€šãƒ˜ãƒƒãƒ€ãƒ¼\n",
    "HEADERS = {\n",
    "    \"apikey\": SUPABASE_API_KEY,\n",
    "    \"Authorization\": f\"Bearer {SUPABASE_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# --- è£œåŠ©é–¢æ•° ---\n",
    "\n",
    "# ç¾åœ¨æ™‚åˆ»ã‚’JSTã®ISOå½¢å¼ã§å–å¾— (inserted_atç”¨)\n",
    "def jst_now():\n",
    "    return datetime.now(pytz.timezone(\"Asia/Tokyo\")).isoformat()\n",
    "\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å®‰å…¨ã«floatã«å¤‰æ›ã€‚å¤‰æ›ã§ããªã„å ´åˆã¯Noneã‚’è¿”ã™\n",
    "def safe_float(text):\n",
    "    try:\n",
    "        # ç©ºæ–‡å­—åˆ—ã€ãƒã‚¤ãƒ•ãƒ³ã€å…¨è§’ãƒã‚¤ãƒ•ãƒ³ã¯Noneã«\n",
    "        return float(text) if text not in [\"\", \"-\", \"ãƒ¼\"] else None\n",
    "    except (ValueError, TypeError):\n",
    "        # å¤‰æ›ã§ããªã„å ´åˆã¯None\n",
    "        return None\n",
    "\n",
    "# ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ä¸€æ„ãªã‚­ãƒ¼ã‚’ç”Ÿæˆ (SHA256ãƒãƒƒã‚·ãƒ¥)\n",
    "# ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®å†’é ­50æ–‡å­—ã‚’ä½¿ç”¨ã—ã€ã‚¹ãƒšãƒ¼ã‚¹ãªã©ã‚’é™¤å»ã—ã¦ãƒãƒƒã‚·ãƒ¥ã®å®‰å®šæ€§ã‚’é«˜ã‚ã‚‹\n",
    "def safe_generate_unique_key(channel, store_id, visit_date, name, review_text):\n",
    "    cleaned_review = re.sub(r\"\\s+\", \"\", (review_text or \"\").strip().lower())[:50]\n",
    "    cleaned_name = (name or \"\").strip().lower()\n",
    "    cleaned_date = (visit_date or \"\").strip() # visit_dateãŒNoneã®å ´åˆã«ç©ºæ–‡å­—åˆ—ã«ãªã‚‹ã‚ˆã†ã«\n",
    "    \n",
    "    base = f\"{channel}_{store_id}_{cleaned_date}_{cleaned_name}_{cleaned_review}\"\n",
    "    return hashlib.sha256(base.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "# --- WebDriverè¨­å®š ---\n",
    "\n",
    "# WebDriverã®åˆæœŸè¨­å®šï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã€è‡ªå‹•åˆ¶å¾¡å›é¿ãªã©ï¼‰\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\") # æœ€æ–°ã®ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\") # è‡ªå‹•åˆ¶å¾¡ã‚’æ¤œçŸ¥ã•ã›ãªã„ã‚ˆã†ã«ã™ã‚‹\n",
    "    options.add_argument(\"--no-sandbox\") # Dockerã‚„CI/CDç’°å¢ƒã§å¿…è¦ã«ãªã‚‹å ´åˆãŒã‚ã‚‹\n",
    "    options.add_argument(\"--disable-dev-shm-usage\") # Dockerã‚„CI/CDç’°å¢ƒã§å¿…è¦ã«ãªã‚‹å ´åˆãŒã‚ã‚‹\n",
    "    options.add_argument(\"--window-size=1920,1080\") # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’è¨­å®š\n",
    "    options.add_argument(\"--incognito\") # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•\n",
    "    \n",
    "    # WebDriverManagerã§ChromeDriverã‚’è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»è¨­å®š\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# --- Supabase é–¢é€£é–¢æ•° ---\n",
    "\n",
    "# æ—¢å­˜ã®unique_keyã‚’Supabaseã‹ã‚‰ä¸€æ‹¬å–å¾—ã—ã€ã‚»ãƒƒãƒˆã§è¿”ã™\n",
    "def fetch_existing_unique_keys():\n",
    "    print(\"ğŸ”„ Supabaseã‹ã‚‰æ—¢å­˜ã®unique_keyã‚’å–å¾—ä¸­...\")\n",
    "    response = requests.get(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}?select=unique_key\", headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        existing_keys = {x[\"unique_key\"] for x in response.json()}\n",
    "        print(f\"âœ… æ—¢å­˜ã®unique_keyã‚’ {len(existing_keys)} ä»¶å–å¾—ã—ã¾ã—ãŸã€‚\")\n",
    "        return existing_keys\n",
    "    else:\n",
    "        print(f\"âŒ æ—¢å­˜ã‚­ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}\")\n",
    "        return set() # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºã®ã‚»ãƒƒãƒˆã‚’è¿”ã™\n",
    "\n",
    "# ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’Supabaseã«æŒ¿å…¥ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰\n",
    "def insert_reviews_to_supabase(reviews_data, existing_keys_set):\n",
    "    inserted_count = 0\n",
    "    if not reviews_data:\n",
    "        print(\"ğŸ’¡ æŒ¿å…¥ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return 0\n",
    "\n",
    "    print(f\"â˜ï¸ Supabaseã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ä¸­ï¼ˆåˆè¨ˆ {len(reviews_data)} ä»¶ï¼‰...\")\n",
    "    for r in reviews_data:\n",
    "        unique_key = r.get('unique_key')\n",
    "        if not unique_key:\n",
    "            print(f\"âš ï¸ unique_keyãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {r.get('name', 'N/A')}\")\n",
    "            continue\n",
    "\n",
    "        # æ—¢å­˜ã®ã‚­ãƒ¼ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã¦ã„ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—\n",
    "        if unique_key in existing_keys_set:\n",
    "            # print(f\"âš ï¸ é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—: {unique_key} - {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = requests.post(f\"{SUPABASE_URL}/rest/v1/{SUPABASE_TABLE_NAME}\", headers=HEADERS, json=r)\n",
    "            if response.status_code in [200, 201]:\n",
    "                inserted_count += 1\n",
    "                existing_keys_set.add(unique_key) # æ–°ã—ãæŒ¿å…¥ã•ã‚ŒãŸã‚­ãƒ¼ã‚’ãƒ¡ãƒ¢ãƒªä¸Šã®ã‚»ãƒƒãƒˆã«è¿½åŠ \n",
    "                print(f\"âœ… ä¿å­˜æˆåŠŸ: {r.get('channel', 'N/A')} - {r.get('name', '')} ({r.get('visit_date', '')})\")\n",
    "            else:\n",
    "                print(f\"âŒ Supabase POSTã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text} - ãƒ‡ãƒ¼ã‚¿unique_key: {unique_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e} - ãƒ‡ãƒ¼ã‚¿unique_key: {unique_key}\")\n",
    "    print(f\"ğŸ“¦ Supabaseã«æ–°è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ {inserted_count} ä»¶ä¿å­˜ã—ã¾ã—ãŸã€‚\")\n",
    "    return inserted_count\n",
    "\n",
    "# --- Google Maps ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•° ---\n",
    "\n",
    "# Google Mapsã®ã‚¯ãƒã‚³ãƒŸã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
    "def click_google_review_tab(driver):\n",
    "    try:\n",
    "        review_tab = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[contains(@aria-label,\"ã‚¯ãƒã‚³ãƒŸ\")]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", review_tab) # JavaScriptã§ã‚¯ãƒªãƒƒã‚¯ã‚’è©¦ã¿ã‚‹\n",
    "        time.sleep(2) # ã‚¯ãƒªãƒƒã‚¯å¾Œã®å¾…æ©Ÿæ™‚é–“ã‚’é•·ãã™ã‚‹\n",
    "        print(\"âœ… Google Maps ã‚¯ãƒã‚³ãƒŸã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯å®Œäº†\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Maps ã‚¯ãƒã‚³ãƒŸã‚¿ãƒ–ã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}\")\n",
    "\n",
    "# Google Mapsã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã€Œæ–°ã—ã„é †ã€ã§ä¸¦ã³æ›¿ãˆ\n",
    "def click_google_sort_by_new(driver):\n",
    "    try:\n",
    "        # ã€Œä¸¦ã¹æ›¿ãˆã€ãƒœã‚¿ãƒ³ã®XPathã‚’ã‚ˆã‚Šå…·ä½“çš„ã«\n",
    "        sort_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[.//span[text()=\"ä¸¦ã¹æ›¿ãˆ\"]]'))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", sort_button)\n",
    "        time.sleep(1) # ã‚¯ãƒªãƒƒã‚¯å¾Œã®å¾…æ©Ÿ\n",
    "\n",
    "        # ã€Œæ–°ã—ã„é †ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ãŸã‚ã®JavaScript\n",
    "        script = '''\n",
    "            const elements = Array.from(document.querySelectorAll('div[role=\"menuitem\"]'));\n",
    "            const target = elements.find(el => el.textContent.trim() === 'æ–°ã—ã„é †');\n",
    "            if (target) { target.click(); return 'clicked'; } else { return 'not found'; }\n",
    "        '''\n",
    "        result = driver.execute_script(script)\n",
    "        print(f\"ğŸ§­ Google Maps ä¸¦ã³æ›¿ãˆã€æ–°ã—ã„é †ã€ã‚¯ãƒªãƒƒã‚¯çµæœ: {result}\")\n",
    "        time.sleep(2) # ä¸¦ã³æ›¿ãˆé©ç”¨å¾Œã®å¾…æ©Ÿæ™‚é–“ã‚’é•·ãã™ã‚‹\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Maps ä¸¦ã³æ›¿ãˆã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}\")\n",
    "\n",
    "# Google Mapsã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒªã‚¢ã‚’è¦‹ã¤ã‘ã‚‹\n",
    "def find_google_scrollable_area(driver):\n",
    "    print(\"ğŸ” Google Maps ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã‚’æ¢ç´¢ä¸­...\")\n",
    "    try:\n",
    "        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ã®æœ€åˆã®è¦ç´ ãŒå­˜åœ¨ã™ã‚‹ã¾ã§å¾…æ©Ÿã—ã€ãã®ç¥–å…ˆè¦ç´ ã‹ã‚‰ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªé ˜åŸŸã‚’æ¢ã™\n",
    "        scrollable_div = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-review-id]:first-of-type'))\n",
    "        ).find_element(By.XPATH, './ancestor::div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\")]')\n",
    "        print(\"âœ… Google Maps ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç™ºè¦‹\")\n",
    "        return scrollable_div\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Maps ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {e}\")\n",
    "        return None\n",
    "\n",
    "# Google Mapsã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŒ‡å®šä»¶æ•°ã¾ãŸã¯æœ€å¾Œã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«\n",
    "def scroll_google_reviews(driver, scrollable_div, target_reviews=200, max_scrolls=200, patience_scrolls=10):\n",
    "    prev_count = 0\n",
    "    same_count_times = 0\n",
    "    print(f\"â†˜ï¸ Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­ (ç›®æ¨™: {target_reviews}ä»¶)...\")\n",
    "    for i in range(max_scrolls):\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", scrollable_div)\n",
    "        time.sleep(0.5) # çŸ­ã‚ã®å¾…æ©Ÿ\n",
    "        reviews = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "        curr_count = len(reviews)\n",
    "        # print(f\"   ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« {i+1}å›ç›®ï¼šç¾åœ¨ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•° = {curr_count}\") # ãƒ‡ãƒãƒƒã‚°ç”¨\n",
    "\n",
    "        if curr_count >= target_reviews:\n",
    "            print(f\"âœ… Google Maps {target_reviews}ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«åˆ°é” â†’ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«çµ‚äº†\")\n",
    "            break\n",
    "        if curr_count == prev_count:\n",
    "            same_count_times += 1\n",
    "            if same_count_times >= patience_scrolls:\n",
    "                print(f\"âš ï¸ Google Maps {patience_scrolls}å›é€£ç¶šã§ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°å¢—åŠ ãªã— â†’ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­æ–­\")\n",
    "                break\n",
    "        else:\n",
    "            same_count_times = 0\n",
    "            prev_count = curr_count\n",
    "    \n",
    "    # å…¨ã¦ã®ã€Œã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å…¨æ–‡ã‚’è¡¨ç¤º\n",
    "    try:\n",
    "        expand_buttons = driver.find_elements(By.CSS_SELECTOR, 'button.w8nwRe')\n",
    "        print(f\"ğŸ‘ï¸â€ğŸ—¨ï¸ Google Maps ã€ã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ {len(expand_buttons)} å€‹ã‚’æ¤œå‡ºã€ã‚¯ãƒªãƒƒã‚¯ä¸­...\")\n",
    "        for btn in expand_buttons:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                # time.sleep(0.05) # çŸ­ã„å¾…æ©Ÿã§è² è·ã‚’æ¸›ã‚‰ã™\n",
    "            except Exception as e:\n",
    "                pass # å¤§é‡ã«å‡ºåŠ›ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯è¡¨ç¤ºã—ãªã„\n",
    "        print(\"âœ… Google Maps ã€ã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å®Œäº†\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Google Maps ã€ã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å‡¦ç†å¤±æ•—: {e}\")\n",
    "\n",
    "# Google Mapsã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±ã‚’æŠ½å‡º\n",
    "def extract_google_reviews(driver):\n",
    "    ref_date = datetime.now()  # åŸºæº–æ—¥ï¼ˆç¾åœ¨æ—¥æ™‚ï¼‰\n",
    "    reviews = []\n",
    "\n",
    "    # å®Œå…¨ã«å±•é–‹ã•ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—\n",
    "    blocks = driver.find_elements(By.CSS_SELECTOR, 'div.jftiEf')\n",
    "    print(f\"âš™ï¸ Google Maps ãƒšãƒ¼ã‚¸ã‹ã‚‰ {len(blocks)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºä¸­...\")\n",
    "\n",
    "    for block in blocks:\n",
    "        unique_key = block.get_attribute(\"data-review-id\")\n",
    "        if not unique_key:\n",
    "            continue  # IDãŒãªã„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "\n",
    "        soup = BeautifulSoup(block.get_attribute(\"innerHTML\"), \"html.parser\")\n",
    "\n",
    "        review_text_elem = soup.select_one('.MyEned span.wiI7pd')\n",
    "        review_text = review_text_elem.text.strip() if review_text_elem else \"\"\n",
    "        if not review_text:\n",
    "            continue  # æœ¬æ–‡ãªã—ã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "\n",
    "        # æŠ•ç¨¿æ—¥ï¼ˆç›¸å¯¾è¡¨ç¾ or çµ¶å¯¾è¡¨ç¾ï¼‰\n",
    "        visit_date = None\n",
    "        visit_month = None\n",
    "        try:\n",
    "            rating_block = soup.select_one(\"div.DU9Pgb\")\n",
    "            if rating_block:\n",
    "                publish_span = rating_block.select_one(\"span.rsqaWe\")\n",
    "                if publish_span:\n",
    "                    txt = publish_span.get_text(strip=True)\n",
    "                    visit_datetime = None\n",
    "\n",
    "                    if \"æ™‚é–“å‰\" in txt:\n",
    "                        hours = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(hours=hours)\n",
    "                    elif \"æ—¥å‰\" in txt:\n",
    "                        days = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=days)\n",
    "                    elif \"é€±é–“å‰\" in txt:\n",
    "                        weeks = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(weeks=weeks * 7)\n",
    "                    elif \"ã‹æœˆå‰\" in txt:\n",
    "                        months = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=30 * months)\n",
    "                    elif \"å¹´å‰\" in txt:\n",
    "                        years = int(re.search(r\"\\d+\", txt).group(0))\n",
    "                        visit_datetime = ref_date - timedelta(days=365 * years)\n",
    "                    elif re.match(r\"^\\d{4}å¹´\\d{1,2}æœˆ\\d{1,2}æ—¥$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Yå¹´%mæœˆ%dæ—¥\")\n",
    "                    elif re.match(r\"^\\d{4}å¹´\\d{1,2}æœˆ$\", txt):\n",
    "                        visit_datetime = datetime.strptime(txt, \"%Yå¹´%mæœˆ\")\n",
    "\n",
    "                    if visit_datetime:\n",
    "                        visit_date = visit_datetime.date().isoformat()\n",
    "                        visit_month = visit_datetime.replace(day=1).date().isoformat()\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Google Maps visit_date æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e} (å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: {txt if 'txt' in locals() else 'N/A'})\")\n",
    "\n",
    "        # ç·åˆã‚¹ã‚³ã‚¢\n",
    "        total_score = None\n",
    "        score_elem = soup.select_one('span.kvMYJc[aria-label]')\n",
    "        if score_elem and \"ã¤æ˜Ÿ\" in score_elem.get(\"aria-label\", \"\"):\n",
    "            match = re.search(r\"(\\d+) ã¤æ˜Ÿ\", score_elem['aria-label'])\n",
    "            if match:\n",
    "                total_score = int(match.group(1))\n",
    "\n",
    "        # ã‚µãƒ–ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ˜ãƒ«ãƒ‘ãƒ¼\n",
    "        def extract_google_sub_score(label):\n",
    "            score = None\n",
    "            score_blocks = soup.select(\"div.PBK6be span.RfDO5c\")\n",
    "            for block in score_blocks:\n",
    "                bold = block.find(\"b\")\n",
    "                if bold and label in bold.text:\n",
    "                    text = block.get_text(strip=True)\n",
    "                    match = re.search(rf\"{label}:\\s*(\\d+)\", text)\n",
    "                    if match:\n",
    "                        score = int(match.group(1))\n",
    "                        break\n",
    "            return score\n",
    "\n",
    "        food_score = extract_google_sub_score(\"é£Ÿäº‹\")\n",
    "        service_score = extract_google_sub_score(\"ã‚µãƒ¼ãƒ“ã‚¹\")\n",
    "        atmosphere_score = extract_google_sub_score(\"é›°å›²æ°—\")\n",
    "\n",
    "        lunch = \"ãƒ©ãƒ³ãƒ\" in review_text\n",
    "        dinner = \"ãƒ‡ã‚£ãƒŠãƒ¼\" in review_text\n",
    "\n",
    "        price_range = None\n",
    "        price_elem = soup.find(\"span\", attrs={\"aria-label\": re.compile(r\"ï¿¥\")})\n",
    "        if price_elem:\n",
    "            price_range = price_elem['aria-label']\n",
    "\n",
    "        user_button = soup.select_one('button[aria-label*=\"ã•ã‚“ã®ã‚¯ãƒã‚³ãƒŸ\"]')\n",
    "        user_name = user_button['aria-label'].split('ã•ã‚“')[0] if user_button else \"\"\n",
    "        a_tag = soup.select_one('a')\n",
    "        user_url = \"https://www.google.com\" + a_tag['href'] if a_tag else \"\"\n",
    "\n",
    "        reviews.append({\n",
    "            \"store_id\": STORE_ID,\n",
    "            \"channel\": \"googlemaps\",\n",
    "            \"unique_key\": unique_key,\n",
    "            \"review\": review_text,\n",
    "            \"visit_date\": visit_date,\n",
    "            \"visit_month\": visit_month,\n",
    "            \"name\": user_name,\n",
    "            \"user_url\": user_url,\n",
    "            \"total_score\": total_score,\n",
    "            \"food_score\": food_score,\n",
    "            \"service_score\": service_score,\n",
    "            \"atmosphere_score\": atmosphere_score,\n",
    "            \"lunch\": lunch,\n",
    "            \"dinner\": dinner,\n",
    "            \"price_range\": price_range,\n",
    "            \"inserted_at\": jst_now()\n",
    "        })\n",
    "\n",
    "    print(f\"ğŸ“¦ Google Mapsã‹ã‚‰ {len(reviews)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºå®Œäº†\")\n",
    "    return reviews\n",
    "\n",
    "# ============ é£Ÿã¹ãƒ­ã‚° ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•° ============\n",
    "\n",
    "def scrape_tabelog(url, store_id, driver):\n",
    "    print(f\"\\n=== Tabelog ({url})ã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–‹å§‹ ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    reviews_data = []\n",
    "    \n",
    "    while True:\n",
    "        items = driver.find_elements(By.CSS_SELECTOR, \"div.rvw-item\")\n",
    "        if not items:\n",
    "            print(\"â¡ï¸ Tabelog ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ‚äº†ã€‚\")\n",
    "            break\n",
    "\n",
    "        for idx, e in enumerate(items):\n",
    "            try:\n",
    "                # ã€Œã‚‚ã£ã¨è¦‹ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ (ã‚¢ã‚³ãƒ¼ãƒ‡ã‚£ã‚ªãƒ³ã€å…¨æ–‡è¡¨ç¤º)\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"button.js-c-accordion-trigger\").click(); time.sleep(0.2)\n",
    "                except: pass\n",
    "                try: e.find_element(By.CSS_SELECTOR, \".rvw-showall-trigger\").click(); time.sleep(0.2)\n",
    "                except: pass\n",
    "\n",
    "                review_text = None\n",
    "                try: review_text = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__rvw-comment--custom p\").text.strip()\n",
    "                except:\n",
    "                    try: review_text = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__rvw-comment p\").text.strip()\n",
    "                    except: pass # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ãŒãªã‘ã‚Œã°Noneã®ã¾ã¾\n",
    "\n",
    "                if not review_text: # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ãŒç©ºã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "                    continue\n",
    "\n",
    "                name_elem = e.find_element(By.CSS_SELECTOR, \".rvw-item__rvwr-name\")\n",
    "                name = name_elem.text.strip() if name_elem else None\n",
    "                user_url_elem = e.find_element(By.CSS_SELECTOR, \".rvw-item__rvwr-info-left a\")\n",
    "                user_url = user_url_elem.get_attribute(\"href\") if user_url_elem else None\n",
    "\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                try:\n",
    "                    date_elem = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__date span\")\n",
    "                    date_text = date_elem.text.strip().split(\"è¨ªå•\")[0].strip()\n",
    "                    # YYYY/MM/DD ã¾ãŸã¯ YYYY/MM å½¢å¼ã«å¯¾å¿œ\n",
    "                    if re.match(r\"^\\d{4}/\\d{1,2}/\\d{1,2}$\", date_text):\n",
    "                        dt_obj = datetime.strptime(date_text, \"%Y/%m/%d\")\n",
    "                        visit_date = dt_obj.date().isoformat()\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                    elif re.match(r\"^\\d{4}/\\d{1,2}$\", date_text):\n",
    "                        dt_obj = datetime.strptime(date_text, \"%Y/%m\")\n",
    "                        visit_date = dt_obj.replace(day=1).date().isoformat() # æ—¥ä»˜ã¯æœˆåˆ\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                except Exception:\n",
    "                    pass # æ—¥ä»˜æŠ½å‡ºã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–\n",
    "\n",
    "                total_score = None\n",
    "                try: total_score = safe_float(e.find_element(By.CSS_SELECTOR, \"b.c-rating-v3__val\").text)\n",
    "                except: pass\n",
    "\n",
    "                food_score = service_score = atmosphere_score = None\n",
    "                for li in e.find_elements(By.CSS_SELECTOR, \"ul.c-rating-detail li\"):\n",
    "                    try:\n",
    "                        label_elem = li.find_element(By.TAG_NAME, \"span\")\n",
    "                        val_elem = li.find_element(By.TAG_NAME, \"strong\")\n",
    "                        if label_elem and val_elem:\n",
    "                            label = label_elem.text.strip()\n",
    "                            val = safe_float(val_elem.text)\n",
    "                            if \"æ–™ç†\" in label: food_score = val\n",
    "                            elif \"ã‚µãƒ¼ãƒ“ã‚¹\" in label: service_score = val\n",
    "                            elif \"é›°å›²æ°—\" in label: atmosphere_score = val\n",
    "                    except: pass\n",
    "\n",
    "                lunch = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"i.c-rating-v3__time--lunch\"); lunch = True\n",
    "                except: pass\n",
    "                dinner = False\n",
    "                try: e.find_element(By.CSS_SELECTOR, \"i.c-rating-v3__time--dinner\"); dinner = True\n",
    "                except: pass\n",
    "\n",
    "                price_range = None\n",
    "                try:\n",
    "                    price_range_elem = e.find_element(By.CSS_SELECTOR, \"div.rvw-item__payment-amount span\")\n",
    "                    price_range_text = price_range_elem.text.strip()\n",
    "                    if price_range_text not in [\"ï¼\", \"-\"]: price_range = price_range_text\n",
    "                except: pass\n",
    "\n",
    "                key = safe_generate_unique_key(\"tabelog\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "                \n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"tabelog\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': total_score, 'food_score': food_score, 'service_score': service_score,\n",
    "                    'atmosphere_score': atmosphere_score, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': price_range, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Tabelog æŠ½å‡ºå¤±æ•— (è¦ç´  {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"a.c-pagination__arrow--next\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"â¡ï¸ Tabelog æ¬¡ãƒšãƒ¼ã‚¸ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ‚äº†ã€‚\")\n",
    "            break\n",
    "    print(f\"ğŸ“¦ Tabelogã‹ã‚‰ {len(reviews_data)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºå®Œäº†\")\n",
    "    return reviews_data\n",
    "\n",
    "# ============ Retty ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•° ============\n",
    "\n",
    "def scrape_retty(url, store_id, driver):\n",
    "    print(f\"\\n=== Retty ({url})ã‹ã‚‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–‹å§‹ ===\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    reviews_data = []\n",
    "\n",
    "    while True:\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        items = soup.select(\"article.restaurant-report\")\n",
    "        if not items:\n",
    "            print(\"â¡ï¸ Retty ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ‚äº†ã€‚\")\n",
    "            break\n",
    "\n",
    "        for idx, item in enumerate(items):\n",
    "            try:\n",
    "                name_tag = item.select_one(\".report-user__name\")\n",
    "                name = name_tag.text.strip() if name_tag else None\n",
    "\n",
    "                user_url_tag = item.select_one(\"a.report-user\")\n",
    "                user_url = user_url_tag[\"href\"] if user_url_tag else None\n",
    "\n",
    "                time_tag = item.select_one(\"div.restaurant-report__date time\")\n",
    "                visit_date = None\n",
    "                visit_month = None\n",
    "                if time_tag and \"datetime\" in time_tag.attrs:\n",
    "                    dt_str = time_tag[\"datetime\"][:10] # YYYY-MM-DD å½¢å¼\n",
    "                    try:\n",
    "                        dt_obj = datetime.strptime(dt_str, \"%Y-%m-%d\")\n",
    "                        visit_date = dt_obj.date().isoformat()\n",
    "                        visit_month = dt_obj.replace(day=1).date().isoformat()\n",
    "                    except ValueError:\n",
    "                        pass # æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–\n",
    "\n",
    "                lunch = \"restaurant-report__hours-icon--lunch\" in str(item)\n",
    "                dinner = \"restaurant-report__hours-icon--dinner\" in str(item)\n",
    "\n",
    "                review_elem = item.select_one(\"p.restaurant-report__text\")\n",
    "                review_text = review_elem.text.strip() if review_elem else None\n",
    "                \n",
    "                if not review_text: # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ãŒç©ºã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—\n",
    "                    continue\n",
    "                    \n",
    "                key = safe_generate_unique_key(\"retty\", store_id, visit_date or \"\", name or \"\", review_text or \"\")\n",
    "\n",
    "                reviews_data.append({\n",
    "                    'store_id': store_id, 'channel': \"retty\", 'review': review_text, 'user_url': user_url,\n",
    "                    'name': name, 'visit_date': visit_date, 'visit_month': visit_month,\n",
    "                    'total_score': None, 'food_score': None, 'service_score': None,\n",
    "                    'atmosphere_score': None, 'lunch': lunch, 'dinner': dinner,\n",
    "                    'price_range': None, 'unique_key': key,\n",
    "                    'inserted_at': jst_now()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Retty æŠ½å‡ºå¤±æ•— (è¦ç´  {idx}): {e}\")\n",
    "\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, \"a.pagination__next\")\n",
    "            driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"â¡ï¸ Retty æ¬¡ãƒšãƒ¼ã‚¸ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ‚äº†ã€‚\")\n",
    "            break\n",
    "    print(f\"ğŸ“¦ Rettyã‹ã‚‰ {len(reviews_data)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºå®Œäº†\")\n",
    "    return reviews_data\n",
    "\n",
    "\n",
    "# ============ ãƒ¡ã‚¤ãƒ³å‡¦ç† ============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # å„ã‚µã‚¤ãƒˆã®URLã‚’è¨­å®š\n",
    "    # Google Maps URLã¯ã€ç›´æ¥Google Mapsã®åº—èˆ—ãƒšãƒ¼ã‚¸URLã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„\n",
    "    # ä¾‹: \"https://www.google.com/maps/place/åº—èˆ—å/@ç·¯åº¦,çµŒåº¦,ã‚ºãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«z/data=!3m1!4b1!4m8!3m7!1s...\"\n",
    "    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ–ãŒè‡ªå‹•ã§é–‹ãURLã¯ã€æœ«å°¾ã« /reviews ã‚’è¿½åŠ ã™ã‚‹ã¨è‰¯ã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚\n",
    "    google_maps_url = \"https://www.google.com/maps/place/%E5%BB%A3%E7%80%AC%E7%8F%88%E7%90%B2%E5%BA%97/@35.0171104,135.6810545,17z/data=!4m8!3m7!1s0x6001a9fe7616d74d:0xc5e2178eaff9044d!8m2!3d35.0171104!4d135.6810545!9m1!1b1!16s%2Fg%2F1wnf0zg2?entry=ttu&g_ep=EgoyMDI1MDUyMS4wIKXMDSoASAFQAw%3D%3D\"\n",
    "    tabelog_url = \"https://tabelog.com/kyoto/A2601/A260403/26001303/dtlrvwlst/\"\n",
    "    retty_url = \"https://retty.me/area/PRE26/ARE114/SUB11401/100000295754/reports/\"\n",
    "\n",
    "    driver = None # driverã‚’åˆæœŸåŒ–\n",
    "    all_reviews = [] # å…¨ã‚µã‚¤ãƒˆã‹ã‚‰å–å¾—ã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "\n",
    "    try:\n",
    "        driver = setup_driver() # WebDriverã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–\n",
    "\n",
    "        # æ—¢å­˜ã®unique_keyã‚’Supabaseã‹ã‚‰ä¸€åº¦ã ã‘å–å¾—\n",
    "        existing_unique_keys = fetch_existing_unique_keys()\n",
    "\n",
    "        # --- å„ã‚µã‚¤ãƒˆã‹ã‚‰ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ã¨çµåˆ ---\n",
    "\n",
    "        # Google Maps\n",
    "        print(\"\\n=== Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–‹å§‹ ===\")\n",
    "        driver.get(google_maps_url)\n",
    "        time.sleep(5) # ãƒšãƒ¼ã‚¸ãŒå®Œå…¨ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã®ã‚’å¾…ã¤\n",
    "        click_google_review_tab(driver)\n",
    "        click_google_sort_by_new(driver)\n",
    "        scroll_target = find_google_scrollable_area(driver)\n",
    "        if scroll_target:\n",
    "            scroll_google_reviews(driver, scroll_target, target_reviews=200, max_scrolls=200) # ã‚ˆã‚Šå¤šãã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è©¦ã¿ã‚‹\n",
    "            google_reviews = extract_google_reviews(driver)\n",
    "            all_reviews.extend(google_reviews)\n",
    "        else:\n",
    "            print(\"âŒ Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒªã‚¢ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "        print(\"=== Google Maps ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—å®Œäº† ===\\n\")\n",
    "\n",
    "        # Tabelog\n",
    "        tabelog_reviews = scrape_tabelog(tabelog_url, STORE_ID, driver)\n",
    "        all_reviews.extend(tabelog_reviews)\n",
    "\n",
    "        # Retty\n",
    "        retty_reviews = scrape_retty(retty_url, STORE_ID, driver)\n",
    "        all_reviews.extend(retty_reviews)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "    finally:\n",
    "        if driver: # driverãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã‹ã‚‰çµ‚äº†\n",
    "            driver.quit() # å…¨ã¦ã®å‡¦ç†ãŒçµ‚ã‚ã£ãŸã‚‰WebDriverã‚’é–‰ã˜ã‚‹\n",
    "\n",
    "    print(f\"\\n--- å…¨ã‚µã‚¤ãƒˆåˆè¨ˆå–å¾—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°: {len(all_reviews)} ---\\n\")\n",
    "\n",
    "    # --- å–å¾—ã—ãŸå…¨ã¦ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’Supabaseã«æŒ¿å…¥ ---\n",
    "    if all_reviews:\n",
    "        insert_reviews_to_supabase(all_reviews, existing_unique_keys)\n",
    "    else:\n",
    "        print(\"å–å¾—ã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚Supabaseã¸ã®æŒ¿å…¥ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7af5ab-33b2-4ef7-84ae-c90d4a208abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
